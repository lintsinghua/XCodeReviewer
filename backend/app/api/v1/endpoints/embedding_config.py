"""
åµŒå…¥æ¨¡å‹é…ç½® API
ç‹¬ç«‹äº LLM é…ç½®ï¼Œä¸“é—¨ç”¨äº RAG ç³»ç»Ÿçš„åµŒå…¥æ¨¡å‹
ä½¿ç”¨ UserConfig.other_config æŒä¹…åŒ–å­˜å‚¨
"""

import json
import uuid
from typing import Any, Optional, List
from fastapi import APIRouter, Depends, HTTPException
from pydantic import BaseModel, Field
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm.attributes import flag_modified

from app.api import deps
from app.models.user import User
from app.models.user_config import UserConfig
from app.core.config import settings

router = APIRouter()


# ============ Schemas ============

class EmbeddingProvider(BaseModel):
    """åµŒå…¥æ¨¡å‹æä¾›å•†"""
    id: str
    name: str
    description: str
    models: List[str]
    requires_api_key: bool
    default_model: str


class EmbeddingConfig(BaseModel):
    """åµŒå…¥æ¨¡å‹é…ç½®"""
    provider: str = Field(description="æä¾›å•†: openai, ollama, azure, cohere, huggingface, jina, qwen")
    model: str = Field(description="æ¨¡å‹åç§°")
    api_key: Optional[str] = Field(default=None, description="API Key (å¦‚éœ€è¦)")
    base_url: Optional[str] = Field(default=None, description="è‡ªå®šä¹‰ API ç«¯ç‚¹")
    dimensions: Optional[int] = Field(default=None, description="å‘é‡ç»´åº¦ (æŸäº›æ¨¡å‹æ”¯æŒ)")
    batch_size: int = Field(default=100, description="æ‰¹å¤„ç†å¤§å°")


class EmbeddingConfigResponse(BaseModel):
    """é…ç½®å“åº”"""
    provider: str
    model: str
    api_key: Optional[str] = None  # è¿”å› API Key
    base_url: Optional[str]
    dimensions: int
    batch_size: int


class TestEmbeddingRequest(BaseModel):
    """æµ‹è¯•åµŒå…¥è¯·æ±‚"""
    provider: str
    model: str
    api_key: Optional[str] = None
    base_url: Optional[str] = None
    test_text: str = "è¿™æ˜¯ä¸€æ®µæµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºéªŒè¯åµŒå…¥æ¨¡å‹æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚"


class TestEmbeddingResponse(BaseModel):
    """æµ‹è¯•åµŒå…¥å“åº”"""
    success: bool
    message: str
    dimensions: Optional[int] = None
    sample_embedding: Optional[List[float]] = None  # å‰ 5 ä¸ªç»´åº¦
    latency_ms: Optional[int] = None


# ============ æä¾›å•†é…ç½® ============

EMBEDDING_PROVIDERS: List[EmbeddingProvider] = [
    EmbeddingProvider(
        id="openai",
        name="OpenAI (å…¼å®¹ DeepSeek/Moonshot/æ™ºè°± ç­‰)",
        description="OpenAI å®˜æ–¹æˆ–å…¼å®¹ APIï¼Œå¡«å†™è‡ªå®šä¹‰ç«¯ç‚¹å¯æ¥å…¥å…¶ä»–æœåŠ¡å•†",
        models=[
            "text-embedding-3-small",
            "text-embedding-3-large",
            "text-embedding-ada-002",
        ],
        requires_api_key=True,
        default_model="text-embedding-3-small",
    ),
    EmbeddingProvider(
        id="azure",
        name="Azure OpenAI",
        description="Azure æ‰˜ç®¡çš„ OpenAI åµŒå…¥æ¨¡å‹",
        models=[
            "text-embedding-3-small",
            "text-embedding-3-large",
            "text-embedding-ada-002",
        ],
        requires_api_key=True,
        default_model="text-embedding-3-small",
    ),
    EmbeddingProvider(
        id="ollama",
        name="Ollama (æœ¬åœ°)",
        description="æœ¬åœ°è¿è¡Œçš„å¼€æºåµŒå…¥æ¨¡å‹ (ä½¿ç”¨ /api/embed ç«¯ç‚¹)",
        models=[
            "nomic-embed-text",
            "mxbai-embed-large",
            "all-minilm",
            "snowflake-arctic-embed",
            "bge-m3",
            "qwen3-embedding",
        ],
        requires_api_key=False,
        default_model="nomic-embed-text",
    ),
    EmbeddingProvider(
        id="cohere",
        name="Cohere",
        description="Cohere Embed v2 API (api.cohere.com/v2)",
        models=[
            "embed-english-v3.0",
            "embed-multilingual-v3.0",
            "embed-english-light-v3.0",
            "embed-multilingual-light-v3.0",
            "embed-v4.0",
        ],
        requires_api_key=True,
        default_model="embed-multilingual-v3.0",
    ),
    EmbeddingProvider(
        id="huggingface",
        name="HuggingFace",
        description="HuggingFace Inference Providers (router.huggingface.co)",
        models=[
            "sentence-transformers/all-MiniLM-L6-v2",
            "sentence-transformers/all-mpnet-base-v2",
            "BAAI/bge-large-zh-v1.5",
            "BAAI/bge-m3",
        ],
        requires_api_key=True,
        default_model="BAAI/bge-m3",
    ),
    EmbeddingProvider(
        id="jina",
        name="Jina AI",
        description="Jina AI åµŒå…¥æ¨¡å‹ï¼Œä»£ç åµŒå…¥æ•ˆæœå¥½",
        models=[
            "jina-embeddings-v2-base-code",
            "jina-embeddings-v2-base-en",
            "jina-embeddings-v2-base-zh",
        ],
        requires_api_key=True,
        default_model="jina-embeddings-v2-base-code",
    ),
    EmbeddingProvider(
        id="qwen",
        name="Qwen (DashScope)",
        description="é˜¿é‡Œäº‘ DashScope Qwen åµŒå…¥æ¨¡å‹ï¼Œå…¼å®¹ OpenAI embeddings æ¥å£",
        models=[
            "text-embedding-v4",
            "text-embedding-v3",
            "text-embedding-v2",
        ],
        requires_api_key=True,
        default_model="text-embedding-v4",
    ),
]


# ============ æ•°æ®åº“æŒä¹…åŒ–å­˜å‚¨ (å¼‚æ­¥) ============

EMBEDDING_CONFIG_KEY = "embedding_config"


async def get_embedding_config_from_db(db: AsyncSession, user_id: str) -> EmbeddingConfig:
    """ä»æ•°æ®åº“è·å–åµŒå…¥é…ç½®ï¼ˆå¼‚æ­¥ï¼‰"""
    result = await db.execute(
        select(UserConfig).where(UserConfig.user_id == user_id)
    )
    user_config = result.scalar_one_or_none()

    if user_config and user_config.other_config:
        try:
            other_config = json.loads(user_config.other_config) if isinstance(user_config.other_config, str) else user_config.other_config
            embedding_data = other_config.get(EMBEDDING_CONFIG_KEY)

            if embedding_data:
                config = EmbeddingConfig(
                    provider=embedding_data.get("provider", settings.EMBEDDING_PROVIDER),
                    model=embedding_data.get("model", settings.EMBEDDING_MODEL),
                    api_key=embedding_data.get("api_key"),
                    base_url=embedding_data.get("base_url"),
                    dimensions=embedding_data.get("dimensions"),
                    batch_size=embedding_data.get("batch_size", 100),
                )
                print(f"[EmbeddingConfig] è¯»å–ç”¨æˆ· {user_id} çš„åµŒå…¥é…ç½®: provider={config.provider}, model={config.model}")
                return config
        except (json.JSONDecodeError, AttributeError) as e:
            print(f"[EmbeddingConfig] è§£æç”¨æˆ· {user_id} é…ç½®å¤±è´¥: {e}")

    # è¿”å›é»˜è®¤é…ç½®
    print(f"[EmbeddingConfig] ç”¨æˆ· {user_id} æ— ä¿å­˜é…ç½®ï¼Œè¿”å›é»˜è®¤å€¼")
    return EmbeddingConfig(
        provider=settings.EMBEDDING_PROVIDER,
        model=settings.EMBEDDING_MODEL,
        api_key=settings.LLM_API_KEY,
        base_url=settings.LLM_BASE_URL,
        batch_size=100,
    )


async def save_embedding_config_to_db(db: AsyncSession, user_id: str, config: EmbeddingConfig) -> None:
    """ä¿å­˜åµŒå…¥é…ç½®åˆ°æ•°æ®åº“ï¼ˆå¼‚æ­¥ï¼‰"""
    result = await db.execute(
        select(UserConfig).where(UserConfig.user_id == user_id)
    )
    user_config = result.scalar_one_or_none()

    # å‡†å¤‡åµŒå…¥é…ç½®æ•°æ®
    embedding_data = {
        "provider": config.provider,
        "model": config.model,
        "api_key": config.api_key,
        "base_url": config.base_url,
        "dimensions": config.dimensions,
        "batch_size": config.batch_size,
    }

    if user_config:
        # æ›´æ–°ç°æœ‰é…ç½®
        try:
            other_config = json.loads(user_config.other_config) if user_config.other_config else {}
        except (json.JSONDecodeError, TypeError):
            other_config = {}

        other_config[EMBEDDING_CONFIG_KEY] = embedding_data
        user_config.other_config = json.dumps(other_config)
        # ğŸ”¥ æ˜¾å¼æ ‡è®° other_config å­—æ®µå·²ä¿®æ”¹ï¼Œç¡®ä¿ SQLAlchemy æ£€æµ‹åˆ°å˜åŒ–
        flag_modified(user_config, "other_config")
    else:
        # åˆ›å»ºæ–°é…ç½®
        user_config = UserConfig(
            id=str(uuid.uuid4()),
            user_id=user_id,
            llm_config="{}",
            other_config=json.dumps({EMBEDDING_CONFIG_KEY: embedding_data}),
        )
        db.add(user_config)

    await db.commit()
    print(f"[EmbeddingConfig] å·²ä¿å­˜ç”¨æˆ· {user_id} çš„åµŒå…¥é…ç½®: provider={config.provider}, model={config.model}")


# ============ API Endpoints ============

@router.get("/providers", response_model=List[EmbeddingProvider])
async def list_embedding_providers(
    current_user: User = Depends(deps.get_current_user),
) -> Any:
    """
    è·å–å¯ç”¨çš„åµŒå…¥æ¨¡å‹æä¾›å•†åˆ—è¡¨
    """
    return EMBEDDING_PROVIDERS


@router.get("/config", response_model=EmbeddingConfigResponse)
async def get_current_config(
    db: AsyncSession = Depends(deps.get_db),
    current_user: User = Depends(deps.get_current_user),
) -> Any:
    """
    è·å–å½“å‰åµŒå…¥æ¨¡å‹é…ç½®ï¼ˆä»æ•°æ®åº“è¯»å–ï¼‰
    """
    config = await get_embedding_config_from_db(db, current_user.id)

    # è·å–ç»´åº¦
    dimensions = _get_model_dimensions(config.provider, config.model)

    return EmbeddingConfigResponse(
        provider=config.provider,
        model=config.model,
        api_key=config.api_key,
        base_url=config.base_url,
        dimensions=dimensions,
        batch_size=config.batch_size,
    )


@router.put("/config")
async def update_config(
    config: EmbeddingConfig,
    db: AsyncSession = Depends(deps.get_db),
    current_user: User = Depends(deps.get_current_user),
) -> Any:
    """
    æ›´æ–°åµŒå…¥æ¨¡å‹é…ç½®ï¼ˆæŒä¹…åŒ–åˆ°æ•°æ®åº“ï¼‰
    """
    # éªŒè¯æä¾›å•†
    provider_ids = [p.id for p in EMBEDDING_PROVIDERS]
    if config.provider not in provider_ids:
        raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„æä¾›å•†: {config.provider}")

    # è·å–æä¾›å•†ä¿¡æ¯ï¼ˆç”¨äºæ£€æŸ¥ API Key è¦æ±‚ï¼‰
    provider = next((p for p in EMBEDDING_PROVIDERS if p.id == config.provider), None)
    # æ³¨æ„ï¼šä¸å†å¼ºåˆ¶éªŒè¯æ¨¡å‹åç§°ï¼Œå…è®¸ç”¨æˆ·è¾“å…¥è‡ªå®šä¹‰æ¨¡å‹

    # æ£€æŸ¥ API Key
    if provider and provider.requires_api_key and not config.api_key:
        raise HTTPException(status_code=400, detail=f"{config.provider} éœ€è¦ API Key")

    # ä¿å­˜åˆ°æ•°æ®åº“
    await save_embedding_config_to_db(db, current_user.id, config)

    return {"message": "é…ç½®å·²ä¿å­˜", "provider": config.provider, "model": config.model}


@router.post("/test", response_model=TestEmbeddingResponse)
async def test_embedding(
    request: TestEmbeddingRequest,
    current_user: User = Depends(deps.get_current_user),
) -> Any:
    """
    æµ‹è¯•åµŒå…¥æ¨¡å‹é…ç½®
    """
    import time
    
    try:
        start_time = time.time()
        
        # åˆ›å»ºä¸´æ—¶åµŒå…¥æœåŠ¡
        from app.services.rag.embeddings import EmbeddingService
        
        service = EmbeddingService(
            provider=request.provider,
            model=request.model,
            api_key=request.api_key,
            base_url=request.base_url,
            cache_enabled=False,
        )
        
        # æ‰§è¡ŒåµŒå…¥
        embedding = await service.embed(request.test_text)
        
        latency_ms = int((time.time() - start_time) * 1000)
        
        return TestEmbeddingResponse(
            success=True,
            message=f"åµŒå…¥æˆåŠŸ! ç»´åº¦: {len(embedding)}",
            dimensions=len(embedding),
            sample_embedding=embedding[:5],  # è¿”å›å‰ 5 ç»´
            latency_ms=latency_ms,
        )
        
    except Exception as e:
        return TestEmbeddingResponse(
            success=False,
            message=f"åµŒå…¥å¤±è´¥: {str(e)}",
        )


@router.get("/models/{provider}")
async def get_provider_models(
    provider: str,
    current_user: User = Depends(deps.get_current_user),
) -> Any:
    """
    è·å–æŒ‡å®šæä¾›å•†çš„æ¨¡å‹åˆ—è¡¨
    """
    provider_info = next((p for p in EMBEDDING_PROVIDERS if p.id == provider), None)
    
    if not provider_info:
        raise HTTPException(status_code=404, detail=f"æä¾›å•†ä¸å­˜åœ¨: {provider}")
    
    return {
        "provider": provider,
        "models": provider_info.models,
        "default_model": provider_info.default_model,
        "requires_api_key": provider_info.requires_api_key,
    }


def _get_model_dimensions(provider: str, model: str) -> int:
    """è·å–æ¨¡å‹ç»´åº¦"""
    dimensions_map = {
        # OpenAI
        "text-embedding-3-small": 1536,
        "text-embedding-3-large": 3072,
        "text-embedding-ada-002": 1536,
        
        # Ollama
        "nomic-embed-text": 768,
        "mxbai-embed-large": 1024,
        "all-minilm": 384,
        "snowflake-arctic-embed": 1024,
        
        # Cohere
        "embed-english-v3.0": 1024,
        "embed-multilingual-v3.0": 1024,
        "embed-english-light-v3.0": 384,
        "embed-multilingual-light-v3.0": 384,
        
        # HuggingFace
        "sentence-transformers/all-MiniLM-L6-v2": 384,
        "sentence-transformers/all-mpnet-base-v2": 768,
        "BAAI/bge-large-zh-v1.5": 1024,
        "BAAI/bge-m3": 1024,
        
        # Jina
        "jina-embeddings-v2-base-code": 768,
        "jina-embeddings-v2-base-en": 768,
        "jina-embeddings-v2-base-zh": 768,
        
        # Qwen (DashScope)
        "text-embedding-v4": 1024,  # æ”¯æŒç»´åº¦: 2048, 1536, 1024(é»˜è®¤), 768, 512, 256, 128, 64
        "text-embedding-v3": 1024,  # æ”¯æŒç»´åº¦: 1024(é»˜è®¤), 768, 512, 256, 128, 64
        "text-embedding-v2": 1536,  # æ”¯æŒç»´åº¦: 1536
    }
    
    return dimensions_map.get(model, 768)

