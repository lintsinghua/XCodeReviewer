"""
ÂµåÂÖ•Ê®°ÂûãÈÖçÁΩÆ API
Áã¨Á´ã‰∫é LLM ÈÖçÁΩÆÔºå‰∏ìÈó®Áî®‰∫é RAG Á≥ªÁªüÁöÑÂµåÂÖ•Ê®°Âûã
‰ΩøÁî® UserConfig.other_config ÊåÅ‰πÖÂåñÂ≠òÂÇ®
"""

import json
import uuid
from typing import Any, Optional, List
from fastapi import APIRouter, Depends, HTTPException
from pydantic import BaseModel, Field
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm.attributes import flag_modified

from app.api import deps
from app.models.user import User
from app.models.user_config import UserConfig
from app.core.config import settings

router = APIRouter()


# ============ Schemas ============

class EmbeddingProvider(BaseModel):
    """ÂµåÂÖ•Ê®°ÂûãÊèê‰æõÂïÜ"""
    id: str
    name: str
    description: str
    models: List[str]
    requires_api_key: bool
    default_model: str


class EmbeddingConfig(BaseModel):
    """ÂµåÂÖ•Ê®°ÂûãÈÖçÁΩÆ"""
    provider: str = Field(description="Êèê‰æõÂïÜ: openai, ollama, azure, cohere, huggingface")
    model: str = Field(description="Ê®°ÂûãÂêçÁß∞")
    api_key: Optional[str] = Field(default=None, description="API Key (Â¶ÇÈúÄË¶Å)")
    base_url: Optional[str] = Field(default=None, description="Ëá™ÂÆö‰πâ API Á´ØÁÇπ")
    dimensions: Optional[int] = Field(default=None, description="ÂêëÈáèÁª¥Â∫¶ (Êüê‰∫õÊ®°ÂûãÊîØÊåÅ)")
    batch_size: int = Field(default=100, description="ÊâπÂ§ÑÁêÜÂ§ßÂ∞è")


class EmbeddingConfigResponse(BaseModel):
    """ÈÖçÁΩÆÂìçÂ∫î"""
    provider: str
    model: str
    api_key: Optional[str] = None  # ËøîÂõû API Key
    base_url: Optional[str]
    dimensions: int
    batch_size: int


class TestEmbeddingRequest(BaseModel):
    """ÊµãËØïÂµåÂÖ•ËØ∑Ê±Ç"""
    provider: str
    model: str
    api_key: Optional[str] = None
    base_url: Optional[str] = None
    test_text: str = "ËøôÊòØ‰∏ÄÊÆµÊµãËØïÊñáÊú¨ÔºåÁî®‰∫éÈ™åËØÅÂµåÂÖ•Ê®°ÂûãÊòØÂê¶Ê≠£Â∏∏Â∑•‰Ωú„ÄÇ"


class TestEmbeddingResponse(BaseModel):
    """ÊµãËØïÂµåÂÖ•ÂìçÂ∫î"""
    success: bool
    message: str
    dimensions: Optional[int] = None
    sample_embedding: Optional[List[float]] = None  # Ââç 5 ‰∏™Áª¥Â∫¶
    latency_ms: Optional[int] = None


# ============ Êèê‰æõÂïÜÈÖçÁΩÆ ============

EMBEDDING_PROVIDERS: List[EmbeddingProvider] = [
    EmbeddingProvider(
        id="openai",
        name="OpenAI",
        description="OpenAI ÂÆòÊñπÂµåÂÖ•Ê®°ÂûãÔºåÈ´òË¥®Èáè„ÄÅÁ®≥ÂÆö",
        models=[
            "text-embedding-3-small",
            "text-embedding-3-large",
            "text-embedding-ada-002",
        ],
        requires_api_key=True,
        default_model="text-embedding-3-small",
    ),
    EmbeddingProvider(
        id="azure",
        name="Azure OpenAI",
        description="Azure ÊâòÁÆ°ÁöÑ OpenAI ÂµåÂÖ•Ê®°Âûã",
        models=[
            "text-embedding-3-small",
            "text-embedding-3-large",
            "text-embedding-ada-002",
        ],
        requires_api_key=True,
        default_model="text-embedding-3-small",
    ),
    EmbeddingProvider(
        id="ollama",
        name="Ollama (Êú¨Âú∞)",
        description="Êú¨Âú∞ËøêË°åÁöÑÂºÄÊ∫êÂµåÂÖ•Ê®°Âûã (‰ΩøÁî® /api/embed Á´ØÁÇπ)",
        models=[
            "nomic-embed-text",
            "mxbai-embed-large",
            "all-minilm",
            "snowflake-arctic-embed",
            "bge-m3",
            "qwen3-embedding",
        ],
        requires_api_key=False,
        default_model="nomic-embed-text",
    ),
    EmbeddingProvider(
        id="cohere",
        name="Cohere",
        description="Cohere Embed v2 API (api.cohere.com/v2)",
        models=[
            "embed-english-v3.0",
            "embed-multilingual-v3.0",
            "embed-english-light-v3.0",
            "embed-multilingual-light-v3.0",
            "embed-v4.0",
        ],
        requires_api_key=True,
        default_model="embed-multilingual-v3.0",
    ),
    EmbeddingProvider(
        id="huggingface",
        name="HuggingFace",
        description="HuggingFace Inference Providers (router.huggingface.co)",
        models=[
            "sentence-transformers/all-MiniLM-L6-v2",
            "sentence-transformers/all-mpnet-base-v2",
            "BAAI/bge-large-zh-v1.5",
            "BAAI/bge-m3",
        ],
        requires_api_key=True,
        default_model="BAAI/bge-m3",
    ),
    EmbeddingProvider(
        id="jina",
        name="Jina AI",
        description="Jina AI ÂµåÂÖ•Ê®°ÂûãÔºå‰ª£Á†ÅÂµåÂÖ•ÊïàÊûúÂ•Ω",
        models=[
            "jina-embeddings-v2-base-code",
            "jina-embeddings-v2-base-en",
            "jina-embeddings-v2-base-zh",
        ],
        requires_api_key=True,
        default_model="jina-embeddings-v2-base-code",
    ),
]


# ============ Êï∞ÊçÆÂ∫ìÊåÅ‰πÖÂåñÂ≠òÂÇ® (ÂºÇÊ≠•) ============

EMBEDDING_CONFIG_KEY = "embedding_config"


async def get_embedding_config_from_db(db: AsyncSession, user_id: str) -> EmbeddingConfig:
    """‰ªéÊï∞ÊçÆÂ∫ìËé∑ÂèñÂµåÂÖ•ÈÖçÁΩÆÔºàÂºÇÊ≠•Ôºâ"""
    result = await db.execute(
        select(UserConfig).where(UserConfig.user_id == user_id)
    )
    user_config = result.scalar_one_or_none()

    if user_config and user_config.other_config:
        try:
            other_config = json.loads(user_config.other_config) if isinstance(user_config.other_config, str) else user_config.other_config
            embedding_data = other_config.get(EMBEDDING_CONFIG_KEY)

            if embedding_data:
                config = EmbeddingConfig(
                    provider=embedding_data.get("provider", settings.EMBEDDING_PROVIDER),
                    model=embedding_data.get("model", settings.EMBEDDING_MODEL),
                    api_key=embedding_data.get("api_key"),
                    base_url=embedding_data.get("base_url"),
                    dimensions=embedding_data.get("dimensions"),
                    batch_size=embedding_data.get("batch_size", 100),
                )
                print(f"[EmbeddingConfig] ËØªÂèñÁî®Êà∑ {user_id} ÁöÑÂµåÂÖ•ÈÖçÁΩÆ: provider={config.provider}, model={config.model}")
                return config
        except (json.JSONDecodeError, AttributeError) as e:
            print(f"[EmbeddingConfig] Ëß£ÊûêÁî®Êà∑ {user_id} ÈÖçÁΩÆÂ§±Ë¥•: {e}")

    # ËøîÂõûÈªòËÆ§ÈÖçÁΩÆ
    print(f"[EmbeddingConfig] Áî®Êà∑ {user_id} Êó†‰øùÂ≠òÈÖçÁΩÆÔºåËøîÂõûÈªòËÆ§ÂÄº")
    return EmbeddingConfig(
        provider=settings.EMBEDDING_PROVIDER,
        model=settings.EMBEDDING_MODEL,
        api_key=settings.LLM_API_KEY,
        base_url=settings.LLM_BASE_URL,
        batch_size=100,
    )


async def save_embedding_config_to_db(db: AsyncSession, user_id: str, config: EmbeddingConfig) -> None:
    """‰øùÂ≠òÂµåÂÖ•ÈÖçÁΩÆÂà∞Êï∞ÊçÆÂ∫ìÔºàÂºÇÊ≠•Ôºâ"""
    result = await db.execute(
        select(UserConfig).where(UserConfig.user_id == user_id)
    )
    user_config = result.scalar_one_or_none()

    # ÂáÜÂ§áÂµåÂÖ•ÈÖçÁΩÆÊï∞ÊçÆ
    embedding_data = {
        "provider": config.provider,
        "model": config.model,
        "api_key": config.api_key,
        "base_url": config.base_url,
        "dimensions": config.dimensions,
        "batch_size": config.batch_size,
    }

    if user_config:
        # Êõ¥Êñ∞Áé∞ÊúâÈÖçÁΩÆ
        try:
            other_config = json.loads(user_config.other_config) if user_config.other_config else {}
        except (json.JSONDecodeError, TypeError):
            other_config = {}

        other_config[EMBEDDING_CONFIG_KEY] = embedding_data
        user_config.other_config = json.dumps(other_config)
        # üî• ÊòæÂºèÊ†áËÆ∞ other_config Â≠óÊÆµÂ∑≤‰øÆÊîπÔºåÁ°Æ‰øù SQLAlchemy Ê£ÄÊµãÂà∞ÂèòÂåñ
        flag_modified(user_config, "other_config")
    else:
        # ÂàõÂª∫Êñ∞ÈÖçÁΩÆ
        user_config = UserConfig(
            id=str(uuid.uuid4()),
            user_id=user_id,
            llm_config="{}",
            other_config=json.dumps({EMBEDDING_CONFIG_KEY: embedding_data}),
        )
        db.add(user_config)

    await db.commit()
    print(f"[EmbeddingConfig] Â∑≤‰øùÂ≠òÁî®Êà∑ {user_id} ÁöÑÂµåÂÖ•ÈÖçÁΩÆ: provider={config.provider}, model={config.model}")


# ============ API Endpoints ============

@router.get("/providers", response_model=List[EmbeddingProvider])
async def list_embedding_providers(
    current_user: User = Depends(deps.get_current_user),
) -> Any:
    """
    Ëé∑ÂèñÂèØÁî®ÁöÑÂµåÂÖ•Ê®°ÂûãÊèê‰æõÂïÜÂàóË°®
    """
    return EMBEDDING_PROVIDERS


@router.get("/config", response_model=EmbeddingConfigResponse)
async def get_current_config(
    db: AsyncSession = Depends(deps.get_db),
    current_user: User = Depends(deps.get_current_user),
) -> Any:
    """
    Ëé∑ÂèñÂΩìÂâçÂµåÂÖ•Ê®°ÂûãÈÖçÁΩÆÔºà‰ªéÊï∞ÊçÆÂ∫ìËØªÂèñÔºâ
    """
    config = await get_embedding_config_from_db(db, current_user.id)

    # Ëé∑ÂèñÁª¥Â∫¶
    dimensions = _get_model_dimensions(config.provider, config.model)

    return EmbeddingConfigResponse(
        provider=config.provider,
        model=config.model,
        api_key=config.api_key,
        base_url=config.base_url,
        dimensions=dimensions,
        batch_size=config.batch_size,
    )


@router.put("/config")
async def update_config(
    config: EmbeddingConfig,
    db: AsyncSession = Depends(deps.get_db),
    current_user: User = Depends(deps.get_current_user),
) -> Any:
    """
    Êõ¥Êñ∞ÂµåÂÖ•Ê®°ÂûãÈÖçÁΩÆÔºàÊåÅ‰πÖÂåñÂà∞Êï∞ÊçÆÂ∫ìÔºâ
    """
    # È™åËØÅÊèê‰æõÂïÜ
    provider_ids = [p.id for p in EMBEDDING_PROVIDERS]
    if config.provider not in provider_ids:
        raise HTTPException(status_code=400, detail=f"‰∏çÊîØÊåÅÁöÑÊèê‰æõÂïÜ: {config.provider}")

    # Ëé∑ÂèñÊèê‰æõÂïÜ‰ø°ÊÅØÔºàÁî®‰∫éÊ£ÄÊü• API Key Ë¶ÅÊ±ÇÔºâ
    provider = next((p for p in EMBEDDING_PROVIDERS if p.id == config.provider), None)
    # Ê≥®ÊÑèÔºö‰∏çÂÜçÂº∫Âà∂È™åËØÅÊ®°ÂûãÂêçÁß∞ÔºåÂÖÅËÆ∏Áî®Êà∑ËæìÂÖ•Ëá™ÂÆö‰πâÊ®°Âûã

    # Ê£ÄÊü• API Key
    if provider and provider.requires_api_key and not config.api_key:
        raise HTTPException(status_code=400, detail=f"{config.provider} ÈúÄË¶Å API Key")

    # ‰øùÂ≠òÂà∞Êï∞ÊçÆÂ∫ì
    await save_embedding_config_to_db(db, current_user.id, config)

    return {"message": "ÈÖçÁΩÆÂ∑≤‰øùÂ≠ò", "provider": config.provider, "model": config.model}


@router.post("/test", response_model=TestEmbeddingResponse)
async def test_embedding(
    request: TestEmbeddingRequest,
    current_user: User = Depends(deps.get_current_user),
) -> Any:
    """
    ÊµãËØïÂµåÂÖ•Ê®°ÂûãÈÖçÁΩÆ
    """
    import time
    
    try:
        start_time = time.time()
        
        # ÂàõÂª∫‰∏¥Êó∂ÂµåÂÖ•ÊúçÂä°
        from app.services.rag.embeddings import EmbeddingService
        
        service = EmbeddingService(
            provider=request.provider,
            model=request.model,
            api_key=request.api_key,
            base_url=request.base_url,
            cache_enabled=False,
        )
        
        # ÊâßË°åÂµåÂÖ•
        embedding = await service.embed(request.test_text)
        
        latency_ms = int((time.time() - start_time) * 1000)
        
        return TestEmbeddingResponse(
            success=True,
            message=f"ÂµåÂÖ•ÊàêÂäü! Áª¥Â∫¶: {len(embedding)}",
            dimensions=len(embedding),
            sample_embedding=embedding[:5],  # ËøîÂõûÂâç 5 Áª¥
            latency_ms=latency_ms,
        )
        
    except Exception as e:
        return TestEmbeddingResponse(
            success=False,
            message=f"ÂµåÂÖ•Â§±Ë¥•: {str(e)}",
        )


@router.get("/models/{provider}")
async def get_provider_models(
    provider: str,
    current_user: User = Depends(deps.get_current_user),
) -> Any:
    """
    Ëé∑ÂèñÊåáÂÆöÊèê‰æõÂïÜÁöÑÊ®°ÂûãÂàóË°®
    """
    provider_info = next((p for p in EMBEDDING_PROVIDERS if p.id == provider), None)
    
    if not provider_info:
        raise HTTPException(status_code=404, detail=f"Êèê‰æõÂïÜ‰∏çÂ≠òÂú®: {provider}")
    
    return {
        "provider": provider,
        "models": provider_info.models,
        "default_model": provider_info.default_model,
        "requires_api_key": provider_info.requires_api_key,
    }


def _get_model_dimensions(provider: str, model: str) -> int:
    """Ëé∑ÂèñÊ®°ÂûãÁª¥Â∫¶"""
    dimensions_map = {
        # OpenAI
        "text-embedding-3-small": 1536,
        "text-embedding-3-large": 3072,
        "text-embedding-ada-002": 1536,
        
        # Ollama
        "nomic-embed-text": 768,
        "mxbai-embed-large": 1024,
        "all-minilm": 384,
        "snowflake-arctic-embed": 1024,
        
        # Cohere
        "embed-english-v3.0": 1024,
        "embed-multilingual-v3.0": 1024,
        "embed-english-light-v3.0": 384,
        "embed-multilingual-light-v3.0": 384,
        
        # HuggingFace
        "sentence-transformers/all-MiniLM-L6-v2": 384,
        "sentence-transformers/all-mpnet-base-v2": 768,
        "BAAI/bge-large-zh-v1.5": 1024,
        "BAAI/bge-m3": 1024,
        
        # Jina
        "jina-embeddings-v2-base-code": 768,
        "jina-embeddings-v2-base-en": 768,
        "jina-embeddings-v2-base-zh": 768,
    }
    
    return dimensions_map.get(model, 768)

