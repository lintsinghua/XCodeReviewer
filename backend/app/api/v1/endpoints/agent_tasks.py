"""
DeepAudit Agent å®¡è®¡ä»»åŠ¡ API
åŸºäºŽ LangGraph çš„ Agent å®¡è®¡
"""

import asyncio
import json
import logging
import os
import shutil
from typing import Any, List, Optional, Dict
from datetime import datetime, timezone
from uuid import uuid4

from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks, Query
from fastapi.responses import StreamingResponse
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from sqlalchemy.orm import selectinload
from pydantic import BaseModel, Field

from app.api import deps
from app.db.session import get_db, async_session_factory
from app.models.agent_task import (
    AgentTask, AgentEvent, AgentFinding,
    AgentTaskStatus, AgentTaskPhase, AgentEventType,
    VulnerabilitySeverity, FindingStatus,
)
from app.models.project import Project
from app.models.user import User
from app.models.user_config import UserConfig
from app.services.agent.event_manager import EventManager
from app.services.agent.streaming import StreamHandler, StreamEvent, StreamEventType

logger = logging.getLogger(__name__)
router = APIRouter()

# è¿è¡Œä¸­çš„ä»»åŠ¡ï¼ˆå…¼å®¹æ—§æŽ¥å£ï¼‰
_running_tasks: Dict[str, Any] = {}

# ðŸ”¥ è¿è¡Œä¸­çš„ asyncio Tasksï¼ˆç”¨äºŽå¼ºåˆ¶å–æ¶ˆï¼‰
_running_asyncio_tasks: Dict[str, asyncio.Task] = {}


# ============ Schemas ============

class AgentTaskCreate(BaseModel):
    """åˆ›å»º Agent ä»»åŠ¡è¯·æ±‚"""
    project_id: str = Field(..., description="é¡¹ç›® ID")
    name: Optional[str] = Field(None, description="ä»»åŠ¡åç§°")
    description: Optional[str] = Field(None, description="ä»»åŠ¡æè¿°")
    
    # å®¡è®¡é…ç½®
    audit_scope: Optional[dict] = Field(None, description="å®¡è®¡èŒƒå›´")
    target_vulnerabilities: Optional[List[str]] = Field(
        default=["sql_injection", "xss", "command_injection", "path_traversal", "ssrf"],
        description="ç›®æ ‡æ¼æ´žç±»åž‹"
    )
    verification_level: str = Field(
        "sandbox", 
        description="éªŒè¯çº§åˆ«: analysis_only, sandbox, generate_poc"
    )
    
    # åˆ†æ”¯
    branch_name: Optional[str] = Field(None, description="åˆ†æ”¯åç§°")
    
    # æŽ’é™¤æ¨¡å¼
    exclude_patterns: Optional[List[str]] = Field(
        default=["node_modules", "__pycache__", ".git", "*.min.js"],
        description="æŽ’é™¤æ¨¡å¼"
    )
    
    # æ–‡ä»¶èŒƒå›´
    target_files: Optional[List[str]] = Field(None, description="æŒ‡å®šæ‰«æçš„æ–‡ä»¶")
    
    # Agent é…ç½®
    max_iterations: int = Field(50, ge=1, le=200, description="æœ€å¤§è¿­ä»£æ¬¡æ•°")
    timeout_seconds: int = Field(1800, ge=60, le=7200, description="è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰")


class AgentTaskResponse(BaseModel):
    """Agent ä»»åŠ¡å“åº” - åŒ…å«æ‰€æœ‰å‰ç«¯éœ€è¦çš„å­—æ®µ"""
    id: str
    project_id: str
    name: Optional[str]
    description: Optional[str]
    task_type: str = "agent_audit"
    status: str
    current_phase: Optional[str]
    current_step: Optional[str] = None
    
    # è¿›åº¦ç»Ÿè®¡
    total_files: int = 0
    indexed_files: int = 0
    analyzed_files: int = 0
    total_chunks: int = 0
    
    # Agent ç»Ÿè®¡
    total_iterations: int = 0
    tool_calls_count: int = 0
    tokens_used: int = 0
    
    # å‘çŽ°ç»Ÿè®¡ï¼ˆå…¼å®¹ä¸¤ç§å‘½åï¼‰
    findings_count: int = 0
    total_findings: int = 0  # å…¼å®¹å­—æ®µ
    verified_count: int = 0
    verified_findings: int = 0  # å…¼å®¹å­—æ®µ
    false_positive_count: int = 0
    
    # ä¸¥é‡ç¨‹åº¦ç»Ÿè®¡
    critical_count: int = 0
    high_count: int = 0
    medium_count: int = 0
    low_count: int = 0
    
    # è¯„åˆ†
    quality_score: float = 0.0
    security_score: Optional[float] = None
    
    # è¿›åº¦ç™¾åˆ†æ¯”
    progress_percentage: float = 0.0
    
    # æ—¶é—´
    created_at: datetime
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    
    # é…ç½®
    audit_scope: Optional[dict] = None
    target_vulnerabilities: Optional[List[str]] = None
    verification_level: Optional[str] = None
    exclude_patterns: Optional[List[str]] = None
    target_files: Optional[List[str]] = None
    
    # é”™è¯¯ä¿¡æ¯
    error_message: Optional[str] = None
    
    class Config:
        from_attributes = True


class AgentEventResponse(BaseModel):
    """Agent äº‹ä»¶å“åº”"""
    id: str
    task_id: str
    event_type: str
    phase: Optional[str]
    message: str
    sequence: int
    created_at: datetime
    
    # å¯é€‰å­—æ®µ
    tool_name: Optional[str] = None
    tool_duration_ms: Optional[int] = None
    progress_percent: Optional[float] = None
    finding_id: Optional[str] = None
    
    class Config:
        from_attributes = True


class AgentFindingResponse(BaseModel):
    """Agent å‘çŽ°å“åº”"""
    id: str
    task_id: str
    vulnerability_type: str
    severity: str
    title: str
    description: Optional[str]
    file_path: Optional[str]
    line_start: Optional[int]
    line_end: Optional[int]
    code_snippet: Optional[str]
    
    is_verified: bool
    confidence: float
    status: str
    
    suggestion: Optional[str] = None
    poc: Optional[dict] = None
    
    created_at: datetime
    
    class Config:
        from_attributes = True


class TaskSummaryResponse(BaseModel):
    """ä»»åŠ¡æ‘˜è¦å“åº”"""
    task_id: str
    status: str
    security_score: Optional[int]
    
    total_findings: int
    verified_findings: int
    
    severity_distribution: Dict[str, int]
    vulnerability_types: Dict[str, int]
    
    duration_seconds: Optional[int]
    phases_completed: List[str]


# ============ åŽå°ä»»åŠ¡æ‰§è¡Œ ============

# è¿è¡Œä¸­çš„åŠ¨æ€æ‰§è¡Œå™¨
_running_orchestrators: Dict[str, Any] = {}
# è¿è¡Œä¸­çš„äº‹ä»¶ç®¡ç†å™¨ï¼ˆç”¨äºŽ SSE æµï¼‰
_running_event_managers: Dict[str, EventManager] = {}


async def _execute_agent_task(task_id: str):
    """
    åœ¨åŽå°æ‰§è¡Œ Agent ä»»åŠ¡ - ä½¿ç”¨åŠ¨æ€ Agent æ ‘æž¶æž„
    
    æž¶æž„ï¼šOrchestratorAgent ä½œä¸ºå¤§è„‘ï¼ŒåŠ¨æ€è°ƒåº¦å­ Agent
    """
    from app.services.agent.agents import OrchestratorAgent, ReconAgent, AnalysisAgent, VerificationAgent
    from app.services.agent.event_manager import EventManager, AgentEventEmitter
    from app.services.llm.service import LLMService
    from app.services.agent.core import agent_registry
    from app.core.config import settings
    import time
    
    async with async_session_factory() as db:
        orchestrator = None
        start_time = time.time()
        
        try:
            # èŽ·å–ä»»åŠ¡
            task = await db.get(AgentTask, task_id, options=[selectinload(AgentTask.project)])
            if not task:
                logger.error(f"Task {task_id} not found")
                return
            
            # èŽ·å–é¡¹ç›®
            project = task.project
            if not project:
                logger.error(f"Project not found for task {task_id}")
                return
            
            # èŽ·å–é¡¹ç›®æ ¹ç›®å½•
            project_root = await _get_project_root(project, task_id)
            
            # èŽ·å–ç”¨æˆ·é…ç½®
            user_config = await _get_user_config(db, task.created_by)
            
            # æ›´æ–°çŠ¶æ€ä¸ºè¿è¡Œä¸­
            task.status = AgentTaskStatus.RUNNING
            task.started_at = datetime.now(timezone.utc)
            task.current_phase = AgentTaskPhase.PLANNING
            await db.commit()
            logger.info(f"ðŸš€ Task {task_id} started with Dynamic Agent Tree architecture")
            
            # åˆ›å»ºäº‹ä»¶ç®¡ç†å™¨
            event_manager = EventManager(db_session_factory=async_session_factory)
            event_manager.create_queue(task_id)
            event_emitter = AgentEventEmitter(task_id, event_manager)
            
            # åˆ›å»º LLM æœåŠ¡
            llm_service = LLMService(user_config=user_config)
            
            # åˆå§‹åŒ–å·¥å…·é›† - ä¼ é€’æŽ’é™¤æ¨¡å¼å’Œç›®æ ‡æ–‡ä»¶
            tools = await _initialize_tools(
                project_root, 
                llm_service, 
                user_config,
                exclude_patterns=task.exclude_patterns,
                target_files=task.target_files,
            )
            
            # åˆ›å»ºå­ Agent
            recon_agent = ReconAgent(
                llm_service=llm_service,
                tools=tools.get("recon", {}),
                event_emitter=event_emitter,
            )
            
            analysis_agent = AnalysisAgent(
                llm_service=llm_service,
                tools=tools.get("analysis", {}),
                event_emitter=event_emitter,
            )
            
            verification_agent = VerificationAgent(
                llm_service=llm_service,
                tools=tools.get("verification", {}),
                event_emitter=event_emitter,
            )
            
            # åˆ›å»º Orchestrator Agent
            orchestrator = OrchestratorAgent(
                llm_service=llm_service,
                tools=tools.get("orchestrator", {}),
                event_emitter=event_emitter,
                sub_agents={
                    "recon": recon_agent,
                    "analysis": analysis_agent,
                    "verification": verification_agent,
                },
            )
            
            # æ³¨å†Œåˆ°å…¨å±€
            _running_orchestrators[task_id] = orchestrator
            _running_tasks[task_id] = orchestrator  # å…¼å®¹æ—§çš„å–æ¶ˆé€»è¾‘
            _running_event_managers[task_id] = event_manager  # ç”¨äºŽ SSE æµ
            
            # ðŸ”¥ æ¸…ç†æ—§çš„ Agent æ³¨å†Œè¡¨ï¼Œé¿å…æ˜¾ç¤ºå¤šä¸ªæ ‘
            from app.services.agent.core import agent_registry
            agent_registry.clear()
            
            # æ³¨å†Œ Orchestrator åˆ° Agent Registryï¼ˆä½¿ç”¨å…¶å†…ç½®æ–¹æ³•ï¼‰
            orchestrator._register_to_registry(task="Root orchestrator for security audit")
            
            await event_emitter.emit_info("ðŸ§  åŠ¨æ€ Agent æ ‘æž¶æž„å¯åŠ¨")
            await event_emitter.emit_info(f"ðŸ“ é¡¹ç›®è·¯å¾„: {project_root}")
            
            # æ”¶é›†é¡¹ç›®ä¿¡æ¯ - ä¼ é€’æŽ’é™¤æ¨¡å¼å’Œç›®æ ‡æ–‡ä»¶
            project_info = await _collect_project_info(
                project_root, 
                project.name,
                exclude_patterns=task.exclude_patterns,
                target_files=task.target_files,
            )
            
            # æ›´æ–°ä»»åŠ¡æ–‡ä»¶ç»Ÿè®¡
            task.total_files = project_info.get("file_count", 0)
            await db.commit()
            
            # æž„å»ºè¾“å…¥æ•°æ®
            input_data = {
                "project_info": project_info,
                "config": {
                    "target_vulnerabilities": task.target_vulnerabilities or [],
                    "verification_level": task.verification_level or "sandbox",
                    "exclude_patterns": task.exclude_patterns or [],
                    "target_files": task.target_files or [],
                    "max_iterations": task.max_iterations or 50,
                },
                "project_root": project_root,
                "task_id": task_id,
            }
            
            # æ‰§è¡Œ Orchestrator
            await event_emitter.emit_phase_start("orchestration", "ðŸŽ¯ Orchestrator å¼€å§‹ç¼–æŽ’å®¡è®¡æµç¨‹")
            task.current_phase = AgentTaskPhase.ANALYSIS
            await db.commit()
            
            # ðŸ”¥ å°† orchestrator.run() åŒ…è£…åœ¨ asyncio.Task ä¸­ï¼Œä»¥ä¾¿å¯ä»¥å¼ºåˆ¶å–æ¶ˆ
            run_task = asyncio.create_task(orchestrator.run(input_data))
            _running_asyncio_tasks[task_id] = run_task
            
            try:
                result = await run_task
            finally:
                _running_asyncio_tasks.pop(task_id, None)
            
            # å¤„ç†ç»“æžœ
            duration_ms = int((time.time() - start_time) * 1000)
            
            await db.refresh(task)
            
            if result.success:
                # ä¿å­˜å‘çŽ°
                findings = result.data.get("findings", [])
                await _save_findings(db, task_id, findings)
                
                # æ›´æ–°ä»»åŠ¡ç»Ÿè®¡
                task.status = AgentTaskStatus.COMPLETED
                task.completed_at = datetime.now(timezone.utc)
                task.current_phase = AgentTaskPhase.REPORTING
                task.findings_count = len(findings)
                task.total_iterations = result.iterations
                task.tool_calls_count = result.tool_calls
                task.tokens_used = result.tokens_used
                
                # ç»Ÿè®¡ä¸¥é‡ç¨‹åº¦
                for f in findings:
                    if isinstance(f, dict):
                        sev = f.get("severity", "low")
                        if sev == "critical":
                            task.critical_count += 1
                        elif sev == "high":
                            task.high_count += 1
                        elif sev == "medium":
                            task.medium_count += 1
                        elif sev == "low":
                            task.low_count += 1
                
                # è®¡ç®—å®‰å…¨è¯„åˆ†
                task.security_score = _calculate_security_score(findings)
                # ðŸ”¥ æ³¨æ„: progress_percentage æ˜¯è®¡ç®—å±žæ€§ï¼Œä¸éœ€è¦æ‰‹åŠ¨è®¾ç½®
                # å½“ status = COMPLETED æ—¶ä¼šè‡ªåŠ¨è¿”å›ž 100.0
                
                await db.commit()
                
                await event_emitter.emit_task_complete(
                    findings_count=len(findings),
                    duration_ms=duration_ms,
                )
                
                logger.info(f"âœ… Task {task_id} completed: {len(findings)} findings, {duration_ms}ms")
            else:
                # ðŸ”¥ æ£€æŸ¥æ˜¯å¦æ˜¯å–æ¶ˆå¯¼è‡´çš„å¤±è´¥
                if result.error == "ä»»åŠ¡å·²å–æ¶ˆ":
                    # çŠ¶æ€å¯èƒ½å·²ç»è¢« cancel API æ›´æ–°ï¼Œåªéœ€ç¡®ä¿ä¸€è‡´æ€§
                    if task.status != AgentTaskStatus.CANCELLED:
                        task.status = AgentTaskStatus.CANCELLED
                        task.completed_at = datetime.now(timezone.utc)
                        await db.commit()
                    logger.info(f"ðŸ›‘ Task {task_id} cancelled")
                else:
                    task.status = AgentTaskStatus.FAILED
                    task.error_message = result.error or "Unknown error"
                    task.completed_at = datetime.now(timezone.utc)
                    await db.commit()
                    
                    await event_emitter.emit_error(result.error or "Unknown error")
                    logger.error(f"âŒ Task {task_id} failed: {result.error}")
            
        except asyncio.CancelledError:
            logger.info(f"Task {task_id} cancelled")
            try:
                task = await db.get(AgentTask, task_id)
                if task:
                    task.status = AgentTaskStatus.CANCELLED
                    task.completed_at = datetime.now(timezone.utc)
                    await db.commit()
            except Exception:
                pass
                
        except Exception as e:
            logger.error(f"Task {task_id} failed: {e}", exc_info=True)
            
            try:
                task = await db.get(AgentTask, task_id)
                if task:
                    task.status = AgentTaskStatus.FAILED
                    task.error_message = str(e)[:1000]
                    task.completed_at = datetime.now(timezone.utc)
                    await db.commit()
            except Exception as db_error:
                logger.error(f"Failed to update task status: {db_error}")
        
        finally:
            # æ¸…ç†
            _running_orchestrators.pop(task_id, None)
            _running_tasks.pop(task_id, None)
            _running_event_managers.pop(task_id, None)
            _running_asyncio_tasks.pop(task_id, None)  # ðŸ”¥ æ¸…ç† asyncio task
            
            # ä»Ž Registry æ³¨é”€
            if orchestrator:
                agent_registry.unregister_agent(orchestrator.agent_id)
            
            logger.debug(f"Task {task_id} cleaned up")


async def _get_user_config(db: AsyncSession, user_id: Optional[str]) -> Optional[Dict[str, Any]]:
    """èŽ·å–ç”¨æˆ·é…ç½®"""
    if not user_id:
        return None
    
    try:
        from app.api.v1.endpoints.config import (
            decrypt_config, 
            SENSITIVE_LLM_FIELDS, SENSITIVE_OTHER_FIELDS
        )
        
        result = await db.execute(
            select(UserConfig).where(UserConfig.user_id == user_id)
        )
        config = result.scalar_one_or_none()
        
        if config and config.llm_config:
            user_llm_config = json.loads(config.llm_config) if config.llm_config else {}
            user_other_config = json.loads(config.other_config) if config.other_config else {}
            
            user_llm_config = decrypt_config(user_llm_config, SENSITIVE_LLM_FIELDS)
            user_other_config = decrypt_config(user_other_config, SENSITIVE_OTHER_FIELDS)
            
            return {
                "llmConfig": user_llm_config,
                "otherConfig": user_other_config,
            }
    except Exception as e:
        logger.warning(f"Failed to get user config: {e}")
    
    return None


async def _initialize_tools(
    project_root: str, 
    llm_service, 
    user_config: Optional[Dict[str, Any]],
    exclude_patterns: Optional[List[str]] = None,
    target_files: Optional[List[str]] = None,
) -> Dict[str, Dict[str, Any]]:
    """åˆå§‹åŒ–å·¥å…·é›†
    
    Args:
        project_root: é¡¹ç›®æ ¹ç›®å½•
        llm_service: LLM æœåŠ¡
        user_config: ç”¨æˆ·é…ç½®
        exclude_patterns: æŽ’é™¤æ¨¡å¼åˆ—è¡¨
        target_files: ç›®æ ‡æ–‡ä»¶åˆ—è¡¨
    """
    from app.services.agent.tools import (
        FileReadTool, FileSearchTool, ListFilesTool,
        PatternMatchTool, CodeAnalysisTool, DataFlowAnalysisTool,
        SemgrepTool, BanditTool, GitleaksTool,
        ThinkTool, ReflectTool,
        CreateVulnerabilityReportTool,
        VulnerabilityValidationTool,
    )
    from app.services.agent.knowledge import (
        SecurityKnowledgeQueryTool,
        GetVulnerabilityKnowledgeTool,
    )
    
    # åŸºç¡€å·¥å…· - ä¼ é€’æŽ’é™¤æ¨¡å¼å’Œç›®æ ‡æ–‡ä»¶
    base_tools = {
        "read_file": FileReadTool(project_root, exclude_patterns, target_files),
        "list_files": ListFilesTool(project_root, exclude_patterns, target_files),
        "search_code": FileSearchTool(project_root, exclude_patterns, target_files),
        "think": ThinkTool(),
        "reflect": ReflectTool(),
    }
    
    # Recon å·¥å…·
    recon_tools = {
        **base_tools,
    }
    
    # Analysis å·¥å…·
    analysis_tools = {
        **base_tools,
        "pattern_match": PatternMatchTool(project_root),
        # TODO: code_analysis å·¥å…·æš‚æ—¶ç¦ç”¨ï¼Œå› ä¸º LLM è°ƒç”¨ç»å¸¸å¤±è´¥
        # "code_analysis": CodeAnalysisTool(llm_service),
        "dataflow_analysis": DataFlowAnalysisTool(llm_service),
        "semgrep_scan": SemgrepTool(project_root),
        "bandit_scan": BanditTool(project_root),
        "gitleaks_scan": GitleaksTool(project_root),
        "query_security_knowledge": SecurityKnowledgeQueryTool(),
        "get_vulnerability_knowledge": GetVulnerabilityKnowledgeTool(),
    }
    
    # Verification å·¥å…·
    verification_tools = {
        **base_tools,
        "vulnerability_validation": VulnerabilityValidationTool(llm_service),
        "dataflow_analysis": DataFlowAnalysisTool(llm_service),
        "create_vulnerability_report": CreateVulnerabilityReportTool(),
    }
    
    # Orchestrator å·¥å…·ï¼ˆä¸»è¦æ˜¯æ€è€ƒå·¥å…·ï¼‰
    orchestrator_tools = {
        "think": ThinkTool(),
        "reflect": ReflectTool(),
    }
    
    return {
        "recon": recon_tools,
        "analysis": analysis_tools,
        "verification": verification_tools,
        "orchestrator": orchestrator_tools,
    }


async def _collect_project_info(
    project_root: str, 
    project_name: str,
    exclude_patterns: Optional[List[str]] = None,
    target_files: Optional[List[str]] = None,
) -> Dict[str, Any]:
    """æ”¶é›†é¡¹ç›®ä¿¡æ¯
    
    Args:
        project_root: é¡¹ç›®æ ¹ç›®å½•
        project_name: é¡¹ç›®åç§°
        exclude_patterns: æŽ’é™¤æ¨¡å¼åˆ—è¡¨
        target_files: ç›®æ ‡æ–‡ä»¶åˆ—è¡¨
    
    ðŸ”¥ é‡è¦ï¼šå½“æŒ‡å®šäº† target_files æ—¶ï¼Œè¿”å›žçš„é¡¹ç›®ç»“æž„åº”è¯¥åªåŒ…å«ç›®æ ‡æ–‡ä»¶ç›¸å…³çš„ä¿¡æ¯ï¼Œ
    ä»¥ç¡®ä¿ Orchestrator å’Œå­ Agent çœ‹åˆ°çš„æ˜¯ä¸€è‡´çš„ã€è¿‡æ»¤åŽçš„è§†å›¾ã€‚
    """
    import fnmatch
    
    info = {
        "name": project_name,
        "root": project_root,
        "languages": [],
        "file_count": 0,
        "structure": {},
    }
    
    try:
        # é»˜è®¤æŽ’é™¤ç›®å½•
        exclude_dirs = {
            "node_modules", "__pycache__", ".git", "venv", ".venv",
            "build", "dist", "target", ".idea", ".vscode",
        }
        
        # ä»Žç”¨æˆ·é…ç½®çš„æŽ’é™¤æ¨¡å¼ä¸­æå–ç›®å½•
        if exclude_patterns:
            for pattern in exclude_patterns:
                if pattern.endswith("/**"):
                    exclude_dirs.add(pattern[:-3])
                elif "/" not in pattern and "*" not in pattern:
                    exclude_dirs.add(pattern)
        
        # ç›®æ ‡æ–‡ä»¶é›†åˆ
        target_files_set = set(target_files) if target_files else None
        
        lang_map = {
            ".py": "Python", ".js": "JavaScript", ".ts": "TypeScript",
            ".java": "Java", ".go": "Go", ".php": "PHP",
            ".rb": "Ruby", ".rs": "Rust", ".c": "C", ".cpp": "C++",
        }
        
        # ðŸ”¥ æ”¶é›†è¿‡æ»¤åŽçš„æ–‡ä»¶åˆ—è¡¨
        filtered_files = []
        filtered_dirs = set()
        
        for root, dirs, files in os.walk(project_root):
            dirs[:] = [d for d in dirs if d not in exclude_dirs]
            
            for f in files:
                relative_path = os.path.relpath(os.path.join(root, f), project_root)
                
                # æ£€æŸ¥æ˜¯å¦åœ¨ç›®æ ‡æ–‡ä»¶åˆ—è¡¨ä¸­
                if target_files_set and relative_path not in target_files_set:
                    continue
                
                # æ£€æŸ¥æŽ’é™¤æ¨¡å¼
                should_skip = False
                if exclude_patterns:
                    for pattern in exclude_patterns:
                        if fnmatch.fnmatch(relative_path, pattern) or fnmatch.fnmatch(f, pattern):
                            should_skip = True
                            break
                if should_skip:
                    continue
                
                info["file_count"] += 1
                filtered_files.append(relative_path)
                
                # ðŸ”¥ æ”¶é›†æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•
                dir_path = os.path.dirname(relative_path)
                if dir_path:
                    # æ·»åŠ ç›®å½•åŠå…¶çˆ¶ç›®å½•
                    parts = dir_path.split(os.sep)
                    for i in range(len(parts)):
                        filtered_dirs.add(os.sep.join(parts[:i+1]))
                
                ext = os.path.splitext(f)[1].lower()
                if ext in lang_map and lang_map[ext] not in info["languages"]:
                    info["languages"].append(lang_map[ext])
        
        # ðŸ”¥ æ ¹æ®æ˜¯å¦æœ‰ç›®æ ‡æ–‡ä»¶é™åˆ¶ï¼Œç”Ÿæˆä¸åŒçš„ç»“æž„ä¿¡æ¯
        if target_files_set:
            # å½“æŒ‡å®šäº†ç›®æ ‡æ–‡ä»¶æ—¶ï¼Œåªæ˜¾ç¤ºç›®æ ‡æ–‡ä»¶å’Œç›¸å…³ç›®å½•
            info["structure"] = {
                "directories": sorted(list(filtered_dirs))[:20],
                "files": filtered_files[:30],
                "scope_limited": True,  # ðŸ”¥ æ ‡è®°è¿™æ˜¯é™å®šèŒƒå›´çš„è§†å›¾
                "scope_message": f"å®¡è®¡èŒƒå›´é™å®šä¸º {len(filtered_files)} ä¸ªæŒ‡å®šæ–‡ä»¶",
            }
        else:
            # å…¨é¡¹ç›®å®¡è®¡æ—¶ï¼Œæ˜¾ç¤ºé¡¶å±‚ç›®å½•ç»“æž„
            try:
                top_items = os.listdir(project_root)
                info["structure"] = {
                    "directories": [d for d in top_items if os.path.isdir(os.path.join(project_root, d)) and d not in exclude_dirs],
                    "files": [f for f in top_items if os.path.isfile(os.path.join(project_root, f))][:20],
                    "scope_limited": False,
                }
            except Exception:
                pass
            
    except Exception as e:
        logger.warning(f"Failed to collect project info: {e}")
    
    return info


async def _save_findings(db: AsyncSession, task_id: str, findings: List[Dict]) -> None:
    """ä¿å­˜å‘çŽ°åˆ°æ•°æ®åº“"""
    from app.models.agent_task import VulnerabilityType
    
    severity_map = {
        "critical": VulnerabilitySeverity.CRITICAL,
        "high": VulnerabilitySeverity.HIGH,
        "medium": VulnerabilitySeverity.MEDIUM,
        "low": VulnerabilitySeverity.LOW,
        "info": VulnerabilitySeverity.INFO,
    }
    
    type_map = {
        "sql_injection": VulnerabilityType.SQL_INJECTION,
        "nosql_injection": VulnerabilityType.NOSQL_INJECTION,
        "xss": VulnerabilityType.XSS,
        "command_injection": VulnerabilityType.COMMAND_INJECTION,
        "code_injection": VulnerabilityType.CODE_INJECTION,
        "path_traversal": VulnerabilityType.PATH_TRAVERSAL,
        "ssrf": VulnerabilityType.SSRF,
        "xxe": VulnerabilityType.XXE,
        "auth_bypass": VulnerabilityType.AUTH_BYPASS,
        "idor": VulnerabilityType.IDOR,
        "sensitive_data_exposure": VulnerabilityType.SENSITIVE_DATA_EXPOSURE,
        "hardcoded_secret": VulnerabilityType.HARDCODED_SECRET,
    }
    
    for finding in findings:
        if not isinstance(finding, dict):
            continue
        
        try:
            db_finding = AgentFinding(
                id=str(uuid4()),
                task_id=task_id,
                vulnerability_type=type_map.get(
                    finding.get("vulnerability_type", "other"),
                    VulnerabilityType.OTHER
                ),
                severity=severity_map.get(
                    finding.get("severity", "medium"),
                    VulnerabilitySeverity.MEDIUM
                ),
                title=finding.get("title", "Unknown"),
                description=finding.get("description", ""),
                file_path=finding.get("file_path"),
                line_start=finding.get("line_start"),
                line_end=finding.get("line_end"),
                code_snippet=finding.get("code_snippet"),
                suggestion=finding.get("suggestion") or finding.get("recommendation"),
                is_verified=finding.get("is_verified", False),
                confidence=finding.get("confidence", 0.5),
                status=FindingStatus.VERIFIED if finding.get("is_verified") else FindingStatus.NEW,
            )
            db.add(db_finding)
        except Exception as e:
            logger.warning(f"Failed to save finding: {e}")
    
    try:
        await db.commit()
    except Exception as e:
        logger.error(f"Failed to commit findings: {e}")


def _calculate_security_score(findings: List[Dict]) -> float:
    """è®¡ç®—å®‰å…¨è¯„åˆ†"""
    if not findings:
        return 100.0
    
    # åŸºäºŽå‘çŽ°çš„ä¸¥é‡ç¨‹åº¦è®¡ç®—æ‰£åˆ†
    deductions = {
        "critical": 25,
        "high": 15,
        "medium": 8,
        "low": 3,
        "info": 1,
    }
    
    total_deduction = 0
    for f in findings:
        if isinstance(f, dict):
            sev = f.get("severity", "low")
            total_deduction += deductions.get(sev, 3)
    
    score = max(0, 100 - total_deduction)
    return float(score)


# ============ API Endpoints ============

@router.post("/", response_model=AgentTaskResponse)
async def create_agent_task(
    request: AgentTaskCreate,
    background_tasks: BackgroundTasks,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(deps.get_current_user),
) -> Any:
    """
    åˆ›å»ºå¹¶å¯åŠ¨ Agent å®¡è®¡ä»»åŠ¡
    """
    # éªŒè¯é¡¹ç›®
    project = await db.get(Project, request.project_id)
    if not project:
        raise HTTPException(status_code=404, detail="é¡¹ç›®ä¸å­˜åœ¨")
    
    if project.owner_id != current_user.id:
        raise HTTPException(status_code=403, detail="æ— æƒè®¿é—®æ­¤é¡¹ç›®")
    
    # åˆ›å»ºä»»åŠ¡
    task = AgentTask(
        id=str(uuid4()),
        project_id=project.id,
        name=request.name or f"Agent Audit - {datetime.now().strftime('%Y%m%d_%H%M%S')}",
        description=request.description,
        status=AgentTaskStatus.PENDING,
        current_phase=AgentTaskPhase.PLANNING,
        target_vulnerabilities=request.target_vulnerabilities,
        verification_level=request.verification_level or "sandbox",
        exclude_patterns=request.exclude_patterns,
        target_files=request.target_files,
        max_iterations=request.max_iterations or 50,
        timeout_seconds=request.timeout_seconds or 1800,
        created_by=current_user.id,
    )
    
    db.add(task)
    await db.commit()
    await db.refresh(task)
    
    # åœ¨åŽå°å¯åŠ¨ä»»åŠ¡ï¼ˆé¡¹ç›®æ ¹ç›®å½•åœ¨ä»»åŠ¡å†…éƒ¨èŽ·å–ï¼‰
    background_tasks.add_task(_execute_agent_task, task.id)
    
    logger.info(f"Created agent task {task.id} for project {project.name}")
    
    return task


@router.get("/", response_model=List[AgentTaskResponse])
async def list_agent_tasks(
    project_id: Optional[str] = None,
    status: Optional[str] = None,
    skip: int = Query(0, ge=0),
    limit: int = Query(20, ge=1, le=100),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(deps.get_current_user),
) -> Any:
    """
    èŽ·å– Agent ä»»åŠ¡åˆ—è¡¨
    """
    # èŽ·å–ç”¨æˆ·çš„é¡¹ç›®
    projects_result = await db.execute(
        select(Project.id).where(Project.owner_id == current_user.id)
    )
    user_project_ids = [p[0] for p in projects_result.fetchall()]
    
    if not user_project_ids:
        return []
    
    # æž„å»ºæŸ¥è¯¢
    query = select(AgentTask).where(AgentTask.project_id.in_(user_project_ids))
    
    if project_id:
        query = query.where(AgentTask.project_id == project_id)
    
    if status:
        try:
            status_enum = AgentTaskStatus(status)
            query = query.where(AgentTask.status == status_enum)
        except ValueError:
            pass
    
    query = query.order_by(AgentTask.created_at.desc())
    query = query.offset(skip).limit(limit)
    
    result = await db.execute(query)
    tasks = result.scalars().all()
    
    return tasks


@router.get("/{task_id}", response_model=AgentTaskResponse)
async def get_agent_task(
    task_id: str,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(deps.get_current_user),
) -> Any:
    """
    èŽ·å– Agent ä»»åŠ¡è¯¦æƒ…
    """
    task = await db.get(AgentTask, task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    # æ£€æŸ¥æƒé™
    project = await db.get(Project, task.project_id)
    if not project or project.owner_id != current_user.id:
        raise HTTPException(status_code=403, detail="æ— æƒè®¿é—®æ­¤ä»»åŠ¡")
    
    # æž„å»ºå“åº”ï¼Œç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½åŒ…å«
    try:
        # è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”
        progress = 0.0
        if hasattr(task, 'progress_percentage'):
            progress = task.progress_percentage
        elif task.status == AgentTaskStatus.COMPLETED:
            progress = 100.0
        elif task.status in [AgentTaskStatus.FAILED, AgentTaskStatus.CANCELLED]:
            progress = 0.0
        
        # ðŸ”¥ ä»Žè¿è¡Œä¸­çš„ Orchestrator èŽ·å–å®žæ—¶ç»Ÿè®¡
        total_iterations = task.total_iterations or 0
        tool_calls_count = task.tool_calls_count or 0
        tokens_used = task.tokens_used or 0
        
        orchestrator = _running_orchestrators.get(task_id)
        if orchestrator and task.status == AgentTaskStatus.RUNNING:
            # ä»Ž Orchestrator èŽ·å–ç»Ÿè®¡
            stats = orchestrator.get_stats()
            total_iterations = stats.get("iterations", 0)
            tool_calls_count = stats.get("tool_calls", 0)
            tokens_used = stats.get("tokens_used", 0)
            
            # ç´¯åŠ å­ Agent çš„ç»Ÿè®¡
            if hasattr(orchestrator, 'sub_agents'):
                for agent in orchestrator.sub_agents.values():
                    if hasattr(agent, 'get_stats'):
                        sub_stats = agent.get_stats()
                        total_iterations += sub_stats.get("iterations", 0)
                        tool_calls_count += sub_stats.get("tool_calls", 0)
                        tokens_used += sub_stats.get("tokens_used", 0)
        
        # æ‰‹åŠ¨æž„å»ºå“åº”æ•°æ®
        response_data = {
            "id": task.id,
            "project_id": task.project_id,
            "name": task.name,
            "description": task.description,
            "task_type": task.task_type or "agent_audit",
            "status": task.status,
            "current_phase": task.current_phase,
            "current_step": task.current_step,
            "total_files": task.total_files or 0,
            "indexed_files": task.indexed_files or 0,
            "analyzed_files": task.analyzed_files or 0,
            "total_chunks": task.total_chunks or 0,
            "total_iterations": total_iterations,
            "tool_calls_count": tool_calls_count,
            "tokens_used": tokens_used,
            "findings_count": task.findings_count or 0,
            "total_findings": task.findings_count or 0,  # å…¼å®¹å­—æ®µ
            "verified_count": task.verified_count or 0,
            "verified_findings": task.verified_count or 0,  # å…¼å®¹å­—æ®µ
            "false_positive_count": task.false_positive_count or 0,
            "critical_count": task.critical_count or 0,
            "high_count": task.high_count or 0,
            "medium_count": task.medium_count or 0,
            "low_count": task.low_count or 0,
            "quality_score": float(task.quality_score or 0.0),
            "security_score": float(task.security_score) if task.security_score is not None else None,
            "progress_percentage": progress,
            "created_at": task.created_at,
            "started_at": task.started_at,
            "completed_at": task.completed_at,
            "error_message": task.error_message,
            "audit_scope": task.audit_scope,
            "target_vulnerabilities": task.target_vulnerabilities,
            "verification_level": task.verification_level,
            "exclude_patterns": task.exclude_patterns,
            "target_files": task.target_files,
        }
        
        return AgentTaskResponse(**response_data)
    except Exception as e:
        logger.error(f"Error serializing task {task_id}: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"åºåˆ—åŒ–ä»»åŠ¡æ•°æ®å¤±è´¥: {str(e)}")


@router.post("/{task_id}/cancel")
async def cancel_agent_task(
    task_id: str,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(deps.get_current_user),
) -> Any:
    """
    å–æ¶ˆ Agent ä»»åŠ¡
    """
    task = await db.get(AgentTask, task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    project = await db.get(Project, task.project_id)
    if not project or project.owner_id != current_user.id:
        raise HTTPException(status_code=403, detail="æ— æƒæ“ä½œæ­¤ä»»åŠ¡")
    
    if task.status in [AgentTaskStatus.COMPLETED, AgentTaskStatus.FAILED, AgentTaskStatus.CANCELLED]:
        raise HTTPException(status_code=400, detail="ä»»åŠ¡å·²ç»“æŸï¼Œæ— æ³•å–æ¶ˆ")
    
    # ðŸ”¥ 1. è®¾ç½® Agent çš„å–æ¶ˆæ ‡å¿—
    runner = _running_tasks.get(task_id)
    if runner:
        runner.cancel()
        logger.info(f"[Cancel] Set cancel flag for task {task_id}")
    
    # ðŸ”¥ 2. å¼ºåˆ¶å–æ¶ˆ asyncio Taskï¼ˆç«‹å³ä¸­æ–­ LLM è°ƒç”¨ï¼‰
    asyncio_task = _running_asyncio_tasks.get(task_id)
    if asyncio_task and not asyncio_task.done():
        asyncio_task.cancel()
        logger.info(f"[Cancel] Cancelled asyncio task for {task_id}")
    
    # æ›´æ–°çŠ¶æ€
    task.status = AgentTaskStatus.CANCELLED
    task.completed_at = datetime.now(timezone.utc)
    await db.commit()
    
    logger.info(f"[Cancel] Task {task_id} cancelled successfully")
    return {"message": "ä»»åŠ¡å·²å–æ¶ˆ", "task_id": task_id}


@router.get("/{task_id}/events")
async def stream_agent_events(
    task_id: str,
    after_sequence: int = Query(0, ge=0, description="ä»Žå“ªä¸ªåºå·ä¹‹åŽå¼€å§‹"),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(deps.get_current_user),
):
    """
    èŽ·å– Agent äº‹ä»¶æµ (SSE)
    """
    task = await db.get(AgentTask, task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    project = await db.get(Project, task.project_id)
    if not project or project.owner_id != current_user.id:
        raise HTTPException(status_code=403, detail="æ— æƒè®¿é—®æ­¤ä»»åŠ¡")
    
    async def event_generator():
        """ç”Ÿæˆ SSE äº‹ä»¶æµ"""
        last_sequence = after_sequence
        poll_interval = 0.5
        max_idle = 300  # 5 åˆ†é’Ÿæ— äº‹ä»¶åŽå…³é—­
        idle_time = 0
        
        while True:
            # æŸ¥è¯¢æ–°äº‹ä»¶
            async with async_session_factory() as session:
                result = await session.execute(
                    select(AgentEvent)
                    .where(AgentEvent.task_id == task_id)
                    .where(AgentEvent.sequence > last_sequence)
                    .order_by(AgentEvent.sequence)
                    .limit(50)
                )
                events = result.scalars().all()
                
                # èŽ·å–ä»»åŠ¡çŠ¶æ€
                current_task = await session.get(AgentTask, task_id)
                task_status = current_task.status if current_task else None
            
            if events:
                idle_time = 0
                for event in events:
                    last_sequence = event.sequence
                    # event_type å·²ç»æ˜¯å­—ç¬¦ä¸²ï¼Œä¸éœ€è¦ .value
                    event_type_str = str(event.event_type)
                    phase_str = str(event.phase) if event.phase else None
                    
                    data = {
                        "id": event.id,
                        "type": event_type_str,
                        "phase": phase_str,
                        "message": event.message,
                        "sequence": event.sequence,
                        "timestamp": event.created_at.isoformat() if event.created_at else None,
                        "progress_percent": event.progress_percent,
                        "tool_name": event.tool_name,
                    }
                    yield f"data: {json.dumps(data, ensure_ascii=False)}\n\n"
            else:
                idle_time += poll_interval
            
            # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦ç»“æŸ
            if task_status:
                # task_status å¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–æžšä¸¾ï¼Œç»Ÿä¸€è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                status_str = str(task_status)
                if status_str in ["completed", "failed", "cancelled"]:
                    yield f"data: {json.dumps({'type': 'task_end', 'status': status_str})}\n\n"
                    break
            
            # æ£€æŸ¥ç©ºé—²è¶…æ—¶
            if idle_time >= max_idle:
                yield f"data: {json.dumps({'type': 'timeout'})}\n\n"
                break
            
            await asyncio.sleep(poll_interval)
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
        }
    )


@router.get("/{task_id}/stream")
async def stream_agent_with_thinking(
    task_id: str,
    include_thinking: bool = Query(True, description="æ˜¯å¦åŒ…å« LLM æ€è€ƒè¿‡ç¨‹"),
    include_tool_calls: bool = Query(True, description="æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨è¯¦æƒ…"),
    after_sequence: int = Query(0, ge=0, description="ä»Žå“ªä¸ªåºå·ä¹‹åŽå¼€å§‹"),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(deps.get_current_user),
):
    """
    å¢žå¼ºç‰ˆäº‹ä»¶æµ (SSE)
    
    æ”¯æŒ:
    - LLM æ€è€ƒè¿‡ç¨‹çš„ Token çº§æµå¼è¾“å‡º (ä»…è¿è¡Œæ—¶)
    - å·¥å…·è°ƒç”¨çš„è¯¦ç»†è¾“å…¥/è¾“å‡º
    - èŠ‚ç‚¹æ‰§è¡ŒçŠ¶æ€
    - å‘çŽ°äº‹ä»¶
    
    ä¼˜å…ˆä½¿ç”¨å†…å­˜ä¸­çš„äº‹ä»¶é˜Ÿåˆ— (æ”¯æŒ thinking_token)ï¼Œ
    å¦‚æžœä»»åŠ¡æœªåœ¨è¿è¡Œï¼Œåˆ™å›žé€€åˆ°æ•°æ®åº“è½®è¯¢ (ä¸æ”¯æŒ thinking_token å¤ç›˜)ã€‚
    """
    task = await db.get(AgentTask, task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    project = await db.get(Project, task.project_id)
    if not project or project.owner_id != current_user.id:
        raise HTTPException(status_code=403, detail="æ— æƒè®¿é—®æ­¤ä»»åŠ¡")
    
    # å®šä¹‰ SSE æ ¼å¼åŒ–å‡½æ•°
    def format_sse_event(event_data: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–ä¸º SSE äº‹ä»¶"""
        event_type = event_data.get("event_type") or event_data.get("type")
        
        # ç»Ÿä¸€å­—æ®µ
        if "type" not in event_data:
            event_data["type"] = event_type
            
        return f"event: {event_type}\ndata: {json.dumps(event_data, ensure_ascii=False)}\n\n"

    async def enhanced_event_generator():
        """ç”Ÿæˆå¢žå¼ºç‰ˆ SSE äº‹ä»¶æµ"""
        # 1. æ£€æŸ¥ä»»åŠ¡æ˜¯å¦åœ¨è¿è¡Œä¸­ (å†…å­˜)
        event_manager = _running_event_managers.get(task_id)
        
        if event_manager:
            logger.debug(f"Stream {task_id}: Using in-memory event manager")
            try:
                # ä½¿ç”¨ EventManager çš„æµå¼æŽ¥å£
                # è¿‡æ»¤é€‰é¡¹
                skip_types = set()
                if not include_thinking:
                    skip_types.update(["thinking_start", "thinking_token", "thinking_end"])
                if not include_tool_calls:
                    skip_types.update(["tool_call_start", "tool_call_input", "tool_call_output", "tool_call_end"])
                
                async for event in event_manager.stream_events(task_id, after_sequence=after_sequence):
                    event_type = event.get("event_type")
                    
                    if event_type in skip_types:
                        continue
                    
                    # ðŸ”¥ Debug: è®°å½• thinking_token äº‹ä»¶
                    if event_type == "thinking_token":
                        token = event.get("metadata", {}).get("token", "")[:20]
                        logger.debug(f"Stream {task_id}: Sending thinking_token: '{token}...'")
                        
                    # æ ¼å¼åŒ–å¹¶ yield
                    yield format_sse_event(event)
                    
                    # ðŸ”¥ CRITICAL: ä¸º thinking_token æ·»åŠ å¾®å°å»¶è¿Ÿ
                    # ç¡®ä¿äº‹ä»¶åœ¨ä¸åŒçš„ TCP åŒ…ä¸­å‘é€ï¼Œè®©å‰ç«¯èƒ½å¤Ÿé€ä¸ªå¤„ç†
                    # æ²¡æœ‰è¿™ä¸ªå»¶è¿Ÿï¼Œæ‰€æœ‰ token ä¼šåœ¨ä¸€æ¬¡ read() ä¸­è¢«æŽ¥æ”¶ï¼Œå¯¼è‡´ React æ‰¹é‡æ›´æ–°
                    if event_type == "thinking_token":
                        await asyncio.sleep(0.01)  # 10ms å»¶è¿Ÿ
                    
            except Exception as e:
                logger.error(f"In-memory stream error: {e}")
                err_data = {"type": "error", "message": str(e)}
                yield format_sse_event(err_data)
                
        else:
            logger.debug(f"Stream {task_id}: Task not running, falling back to DB polling")
            # 2. å›žé€€åˆ°æ•°æ®åº“è½®è¯¢ (æ— æ³•èŽ·å– thinking_token)
            last_sequence = after_sequence
            poll_interval = 2.0  # å®Œæˆçš„ä»»åŠ¡è½®è¯¢å¯ä»¥æ…¢ä¸€ç‚¹
            heartbeat_interval = 15
            max_idle = 60  # 1åˆ†é’Ÿæ— äº‹ä»¶å…³é—­
            idle_time = 0
            last_heartbeat = 0
            
            skip_types = set()
            if not include_thinking:
                skip_types.update(["thinking_start", "thinking_token", "thinking_end"])
            
            while True:
                try:
                    async with async_session_factory() as session:
                        # æŸ¥è¯¢æ–°äº‹ä»¶
                        result = await session.execute(
                            select(AgentEvent)
                            .where(AgentEvent.task_id == task_id)
                            .where(AgentEvent.sequence > last_sequence)
                            .order_by(AgentEvent.sequence)
                            .limit(100)
                        )
                        events = result.scalars().all()
                        
                        # èŽ·å–ä»»åŠ¡çŠ¶æ€
                        current_task = await session.get(AgentTask, task_id)
                        task_status = current_task.status if current_task else None
                    
                    if events:
                        idle_time = 0
                        for event in events:
                            last_sequence = event.sequence
                            event_type = str(event.event_type)
                            
                            if event_type in skip_types:
                                continue
                            
                            # æž„å»ºæ•°æ®
                            data = {
                                "id": event.id,
                                "type": event_type,
                                "phase": str(event.phase) if event.phase else None,
                                "message": event.message,
                                "sequence": event.sequence,
                                "timestamp": event.created_at.isoformat() if event.created_at else None,
                            }
                            
                            # æ·»åŠ è¯¦æƒ…
                            if include_tool_calls and event.tool_name:
                                data["tool"] = {
                                    "name": event.tool_name,
                                    "input": event.tool_input,
                                    "output": event.tool_output,
                                    "duration_ms": event.tool_duration_ms,
                                }
                                
                            if event.event_metadata:
                                data["metadata"] = event.event_metadata
                                
                            if event.tokens_used:
                                data["tokens_used"] = event.tokens_used
                            
                            yield format_sse_event(data)
                    else:
                        idle_time += poll_interval
                        
                        # æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»“æŸ
                        if task_status:
                            status_str = str(task_status)
                            # å¦‚æžœä»»åŠ¡å·²å®Œæˆä¸”æ²¡æœ‰æ–°äº‹ä»¶ï¼Œç»“æŸæµ
                            if status_str in ["completed", "failed", "cancelled"]:
                                end_data = {
                                    "type": "task_end",
                                    "status": status_str,
                                    "message": f"ä»»åŠ¡å·²{status_str}"
                                }
                                yield format_sse_event(end_data)
                                break
                    
                    # å¿ƒè·³
                    last_heartbeat += poll_interval
                    if last_heartbeat >= heartbeat_interval:
                        last_heartbeat = 0
                        yield format_sse_event({"type": "heartbeat", "timestamp": datetime.now(timezone.utc).isoformat()})
                    
                    # è¶…æ—¶
                    if idle_time >= max_idle:
                        break
                    
                    await asyncio.sleep(poll_interval)
                    
                except Exception as e:
                    logger.error(f"DB poll stream error: {e}")
                    yield format_sse_event({"type": "error", "message": str(e)})
                    break
    
    return StreamingResponse(
        enhanced_event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
            "Content-Type": "text/event-stream; charset=utf-8",
        }
    )


@router.get("/{task_id}/events/list", response_model=List[AgentEventResponse])
async def list_agent_events(
    task_id: str,
    after_sequence: int = Query(0, ge=0),
    limit: int = Query(100, ge=1, le=500),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(deps.get_current_user),
) -> Any:
    """
    èŽ·å– Agent äº‹ä»¶åˆ—è¡¨
    """
    task = await db.get(AgentTask, task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    project = await db.get(Project, task.project_id)
    if not project or project.owner_id != current_user.id:
        raise HTTPException(status_code=403, detail="æ— æƒè®¿é—®æ­¤ä»»åŠ¡")
    
    result = await db.execute(
        select(AgentEvent)
        .where(AgentEvent.task_id == task_id)
        .where(AgentEvent.sequence > after_sequence)
        .order_by(AgentEvent.sequence)
        .limit(limit)
    )
    events = result.scalars().all()
    
    return events


@router.get("/{task_id}/findings", response_model=List[AgentFindingResponse])
async def list_agent_findings(
    task_id: str,
    severity: Optional[str] = None,
    verified_only: bool = False,
    skip: int = Query(0, ge=0),
    limit: int = Query(50, ge=1, le=200),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(deps.get_current_user),
) -> Any:
    """
    èŽ·å– Agent å‘çŽ°åˆ—è¡¨
    """
    task = await db.get(AgentTask, task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    project = await db.get(Project, task.project_id)
    if not project or project.owner_id != current_user.id:
        raise HTTPException(status_code=403, detail="æ— æƒè®¿é—®æ­¤ä»»åŠ¡")
    
    query = select(AgentFinding).where(AgentFinding.task_id == task_id)
    
    if severity:
        try:
            sev_enum = VulnerabilitySeverity(severity)
            query = query.where(AgentFinding.severity == sev_enum)
        except ValueError:
            pass
    
    if verified_only:
        query = query.where(AgentFinding.is_verified == True)
    
    # æŒ‰ä¸¥é‡ç¨‹åº¦æŽ’åº
    severity_order = {
        VulnerabilitySeverity.CRITICAL: 0,
        VulnerabilitySeverity.HIGH: 1,
        VulnerabilitySeverity.MEDIUM: 2,
        VulnerabilitySeverity.LOW: 3,
        VulnerabilitySeverity.INFO: 4,
    }
    
    query = query.order_by(AgentFinding.severity, AgentFinding.created_at.desc())
    query = query.offset(skip).limit(limit)
    
    result = await db.execute(query)
    findings = result.scalars().all()
    
    return findings


@router.get("/{task_id}/summary", response_model=TaskSummaryResponse)
async def get_task_summary(
    task_id: str,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(deps.get_current_user),
) -> Any:
    """
    èŽ·å–ä»»åŠ¡æ‘˜è¦
    """
    task = await db.get(AgentTask, task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    project = await db.get(Project, task.project_id)
    if not project or project.owner_id != current_user.id:
        raise HTTPException(status_code=403, detail="æ— æƒè®¿é—®æ­¤ä»»åŠ¡")
    
    # èŽ·å–æ‰€æœ‰å‘çŽ°
    result = await db.execute(
        select(AgentFinding).where(AgentFinding.task_id == task_id)
    )
    findings = result.scalars().all()
    
    # ç»Ÿè®¡
    severity_distribution = {}
    vulnerability_types = {}
    verified_count = 0
    
    for f in findings:
        # severity å’Œ vulnerability_type å·²ç»æ˜¯å­—ç¬¦ä¸²
        sev = str(f.severity)
        vtype = str(f.vulnerability_type)
        
        severity_distribution[sev] = severity_distribution.get(sev, 0) + 1
        vulnerability_types[vtype] = vulnerability_types.get(vtype, 0) + 1
        
        if f.is_verified:
            verified_count += 1
    
    # è®¡ç®—æŒç»­æ—¶é—´
    duration = None
    if task.started_at and task.completed_at:
        duration = int((task.completed_at - task.started_at).total_seconds())
    
    # èŽ·å–å·²å®Œæˆçš„é˜¶æ®µ
    phases_result = await db.execute(
        select(AgentEvent.phase)
        .where(AgentEvent.task_id == task_id)
        .where(AgentEvent.event_type == AgentEventType.PHASE_COMPLETE)
        .distinct()
    )
    phases = [str(p[0]) for p in phases_result.fetchall() if p[0]]
    
    return TaskSummaryResponse(
        task_id=task_id,
        status=str(task.status),  # status å·²ç»æ˜¯å­—ç¬¦ä¸²
        security_score=task.security_score,
        total_findings=len(findings),
        verified_findings=verified_count,
        severity_distribution=severity_distribution,
        vulnerability_types=vulnerability_types,
        duration_seconds=duration,
        phases_completed=phases,
    )


@router.patch("/{task_id}/findings/{finding_id}/status")
async def update_finding_status(
    task_id: str,
    finding_id: str,
    status: str,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(deps.get_current_user),
) -> Any:
    """
    æ›´æ–°å‘çŽ°çŠ¶æ€
    """
    task = await db.get(AgentTask, task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    project = await db.get(Project, task.project_id)
    if not project or project.owner_id != current_user.id:
        raise HTTPException(status_code=403, detail="æ— æƒæ“ä½œ")
    
    finding = await db.get(AgentFinding, finding_id)
    if not finding or finding.task_id != task_id:
        raise HTTPException(status_code=404, detail="å‘çŽ°ä¸å­˜åœ¨")
    
    try:
        finding.status = FindingStatus(status)
    except ValueError:
        raise HTTPException(status_code=400, detail=f"æ— æ•ˆçš„çŠ¶æ€: {status}")
    
    await db.commit()
    
    return {"message": "çŠ¶æ€å·²æ›´æ–°", "finding_id": finding_id, "status": status}


# ============ Helper Functions ============

async def _get_project_root(project: Project, task_id: str) -> str:
    """
    èŽ·å–é¡¹ç›®æ ¹ç›®å½•
    
    æ”¯æŒä¸¤ç§é¡¹ç›®ç±»åž‹ï¼š
    - ZIP é¡¹ç›®ï¼šè§£åŽ‹ ZIP æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
    - ä»“åº“é¡¹ç›®ï¼šå…‹éš†ä»“åº“åˆ°ä¸´æ—¶ç›®å½•
    """
    import zipfile
    import subprocess
    
    base_path = f"/tmp/deepaudit/{task_id}"
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(base_path, exist_ok=True)
    
    # æ ¹æ®é¡¹ç›®ç±»åž‹å¤„ç†
    if project.source_type == "zip":
        # ðŸ”¥ ZIP é¡¹ç›®ï¼šè§£åŽ‹ ZIP æ–‡ä»¶
        from app.services.zip_storage import load_project_zip
        
        zip_path = await load_project_zip(project.id)
        
        if zip_path and os.path.exists(zip_path):
            try:
                with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                    zip_ref.extractall(base_path)
                logger.info(f"âœ… Extracted ZIP project {project.id} to {base_path}")
            except Exception as e:
                logger.error(f"Failed to extract ZIP {zip_path}: {e}")
        else:
            logger.warning(f"âš ï¸ ZIP file not found for project {project.id}")
    
    elif project.source_type == "repository" and project.repository_url:
        # ðŸ”¥ ä»“åº“é¡¹ç›®ï¼šå…‹éš†ä»“åº“
        try:
            branch = project.default_branch or "main"
            repo_url = project.repository_url
            
            # å…‹éš†ä»“åº“
            result = subprocess.run(
                ["git", "clone", "--depth", "1", "--branch", branch, repo_url, base_path],
                capture_output=True,
                text=True,
                timeout=300,
            )
            
            if result.returncode == 0:
                logger.info(f"âœ… Cloned repository {repo_url} (branch: {branch}) to {base_path}")
            else:
                logger.warning(f"Failed to clone branch {branch}, trying default branch: {result.stderr}")
                # å¦‚æžœå…‹éš†å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤åˆ†æ”¯
                if branch != "main":
                    result = subprocess.run(
                        ["git", "clone", "--depth", "1", repo_url, base_path],
                        capture_output=True,
                        text=True,
                        timeout=300,
                    )
                    if result.returncode == 0:
                        logger.info(f"âœ… Cloned repository {repo_url} (default branch) to {base_path}")
                    else:
                        logger.error(f"Failed to clone repository: {result.stderr}")
        except subprocess.TimeoutExpired:
            logger.error(f"Git clone timeout for {project.repository_url}")
        except Exception as e:
            logger.error(f"Failed to clone repository {project.repository_url}: {e}")
    
    return base_path


# ============ Agent Tree API ============

class AgentTreeNodeResponse(BaseModel):
    """Agent æ ‘èŠ‚ç‚¹å“åº”"""
    id: str
    agent_id: str
    agent_name: str
    agent_type: str
    parent_agent_id: Optional[str] = None
    depth: int = 0
    task_description: Optional[str] = None
    knowledge_modules: Optional[List[str]] = None
    status: str = "created"
    result_summary: Optional[str] = None
    findings_count: int = 0
    iterations: int = 0
    tokens_used: int = 0
    tool_calls: int = 0
    duration_ms: Optional[int] = None
    children: List["AgentTreeNodeResponse"] = []
    
    class Config:
        from_attributes = True


class AgentTreeResponse(BaseModel):
    """Agent æ ‘å“åº”"""
    task_id: str
    root_agent_id: Optional[str] = None
    total_agents: int = 0
    running_agents: int = 0
    completed_agents: int = 0
    failed_agents: int = 0
    total_findings: int = 0
    nodes: List[AgentTreeNodeResponse] = []


@router.get("/{task_id}/agent-tree", response_model=AgentTreeResponse)
async def get_agent_tree(
    task_id: str,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(deps.get_current_user),
) -> Any:
    """
    èŽ·å–ä»»åŠ¡çš„ Agent æ ‘ç»“æž„
    
    è¿”å›žåŠ¨æ€ Agent æ ‘çš„å®Œæ•´ç»“æž„ï¼ŒåŒ…æ‹¬ï¼š
    - æ‰€æœ‰ Agent èŠ‚ç‚¹
    - çˆ¶å­å…³ç³»
    - æ‰§è¡ŒçŠ¶æ€
    - å‘çŽ°ç»Ÿè®¡
    """
    task = await db.get(AgentTask, task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    project = await db.get(Project, task.project_id)
    if not project or project.owner_id != current_user.id:
        raise HTTPException(status_code=403, detail="æ— æƒè®¿é—®æ­¤ä»»åŠ¡")
    
    # å°è¯•ä»Žå†…å­˜ä¸­èŽ·å– Agent æ ‘ï¼ˆè¿è¡Œä¸­çš„ä»»åŠ¡ï¼‰
    runner = _running_tasks.get(task_id)
    logger.debug(f"[AgentTree API] task_id={task_id}, runner exists={runner is not None}")
    
    if runner:
        from app.services.agent.core import agent_registry
        
        tree = agent_registry.get_agent_tree()
        stats = agent_registry.get_statistics()
        logger.debug(f"[AgentTree API] tree nodes={len(tree.get('nodes', {}))}, root={tree.get('root_agent_id')}")
        logger.debug(f"[AgentTree API] èŠ‚ç‚¹è¯¦æƒ…: {list(tree.get('nodes', {}).keys())}")
        
        # æž„å»ºèŠ‚ç‚¹åˆ—è¡¨
        nodes = []
        for agent_id, node_data in tree.get("nodes", {}).items():
            # ðŸ”¥ ä»Ž Agent å®žä¾‹èŽ·å–å®žæ—¶ç»Ÿè®¡æ•°æ®
            iterations = 0
            tool_calls = 0
            tokens_used = 0
            findings_count = 0
            
            agent_instance = agent_registry.get_agent(agent_id)
            if agent_instance and hasattr(agent_instance, 'get_stats'):
                agent_stats = agent_instance.get_stats()
                iterations = agent_stats.get("iterations", 0)
                tool_calls = agent_stats.get("tool_calls", 0)
                tokens_used = agent_stats.get("tokens_used", 0)
            
            # ä»Žç»“æžœä¸­èŽ·å–å‘çŽ°æ•°é‡
            if node_data.get("result"):
                result = node_data.get("result", {})
                findings_count = len(result.get("findings", []))
            
            nodes.append(AgentTreeNodeResponse(
                id=node_data.get("id", agent_id),
                agent_id=agent_id,
                agent_name=node_data.get("name", "Unknown"),
                agent_type=node_data.get("type", "unknown"),
                parent_agent_id=node_data.get("parent_id"),
                task_description=node_data.get("task"),
                knowledge_modules=node_data.get("knowledge_modules", []),
                status=node_data.get("status", "unknown"),
                findings_count=findings_count,
                iterations=iterations,
                tool_calls=tool_calls,
                tokens_used=tokens_used,
                children=[],
            ))
        
        return AgentTreeResponse(
            task_id=task_id,
            root_agent_id=tree.get("root_agent_id"),
            total_agents=stats.get("total", 0),
            running_agents=stats.get("running", 0),
            completed_agents=stats.get("completed", 0),
            failed_agents=stats.get("failed", 0),
            total_findings=sum(n.findings_count for n in nodes),
            nodes=nodes,
        )
    
    # ä»Žæ•°æ®åº“èŽ·å–ï¼ˆå·²å®Œæˆçš„ä»»åŠ¡ï¼‰
    from app.models.agent_task import AgentTreeNode
    
    result = await db.execute(
        select(AgentTreeNode)
        .where(AgentTreeNode.task_id == task_id)
        .order_by(AgentTreeNode.depth, AgentTreeNode.created_at)
    )
    db_nodes = result.scalars().all()
    
    if not db_nodes:
        return AgentTreeResponse(
            task_id=task_id,
            nodes=[],
        )
    
    # æž„å»ºå“åº”
    nodes = []
    root_id = None
    running = 0
    completed = 0
    failed = 0
    total_findings = 0
    
    for node in db_nodes:
        if node.parent_agent_id is None:
            root_id = node.agent_id
        
        if node.status == "running":
            running += 1
        elif node.status == "completed":
            completed += 1
        elif node.status == "failed":
            failed += 1
        
        total_findings += node.findings_count or 0
        
        nodes.append(AgentTreeNodeResponse(
            id=node.id,
            agent_id=node.agent_id,
            agent_name=node.agent_name,
            agent_type=node.agent_type,
            parent_agent_id=node.parent_agent_id,
            depth=node.depth,
            task_description=node.task_description,
            knowledge_modules=node.knowledge_modules,
            status=node.status,
            result_summary=node.result_summary,
            findings_count=node.findings_count or 0,
            iterations=node.iterations or 0,
            tokens_used=node.tokens_used or 0,
            tool_calls=node.tool_calls or 0,
            duration_ms=node.duration_ms,
            children=[],
        ))
    
    return AgentTreeResponse(
        task_id=task_id,
        root_agent_id=root_id,
        total_agents=len(nodes),
        running_agents=running,
        completed_agents=completed,
        failed_agents=failed,
        total_findings=total_findings,
        nodes=nodes,
    )


# ============ Checkpoint API ============

class CheckpointResponse(BaseModel):
    """æ£€æŸ¥ç‚¹å“åº”"""
    id: str
    agent_id: str
    agent_name: str
    agent_type: str
    iteration: int
    status: str
    total_tokens: int = 0
    tool_calls: int = 0
    findings_count: int = 0
    checkpoint_type: str = "auto"
    checkpoint_name: Optional[str] = None
    created_at: Optional[str] = None
    
    class Config:
        from_attributes = True


@router.get("/{task_id}/checkpoints", response_model=List[CheckpointResponse])
async def list_checkpoints(
    task_id: str,
    agent_id: Optional[str] = None,
    limit: int = Query(20, ge=1, le=100),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(deps.get_current_user),
) -> Any:
    """
    èŽ·å–ä»»åŠ¡çš„æ£€æŸ¥ç‚¹åˆ—è¡¨
    
    ç”¨äºŽï¼š
    - æŸ¥çœ‹æ‰§è¡ŒåŽ†å²
    - çŠ¶æ€æ¢å¤
    - è°ƒè¯•åˆ†æž
    """
    task = await db.get(AgentTask, task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    project = await db.get(Project, task.project_id)
    if not project or project.owner_id != current_user.id:
        raise HTTPException(status_code=403, detail="æ— æƒè®¿é—®æ­¤ä»»åŠ¡")
    
    from app.models.agent_task import AgentCheckpoint
    
    query = select(AgentCheckpoint).where(AgentCheckpoint.task_id == task_id)
    
    if agent_id:
        query = query.where(AgentCheckpoint.agent_id == agent_id)
    
    query = query.order_by(AgentCheckpoint.created_at.desc()).limit(limit)
    
    result = await db.execute(query)
    checkpoints = result.scalars().all()
    
    return [
        CheckpointResponse(
            id=cp.id,
            agent_id=cp.agent_id,
            agent_name=cp.agent_name,
            agent_type=cp.agent_type,
            iteration=cp.iteration,
            status=cp.status,
            total_tokens=cp.total_tokens or 0,
            tool_calls=cp.tool_calls or 0,
            findings_count=cp.findings_count or 0,
            checkpoint_type=cp.checkpoint_type or "auto",
            checkpoint_name=cp.checkpoint_name,
            created_at=cp.created_at.isoformat() if cp.created_at else None,
        )
        for cp in checkpoints
    ]


@router.get("/{task_id}/checkpoints/{checkpoint_id}")
async def get_checkpoint_detail(
    task_id: str,
    checkpoint_id: str,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(deps.get_current_user),
) -> Any:
    """
    èŽ·å–æ£€æŸ¥ç‚¹è¯¦æƒ…
    
    è¿”å›žå®Œæ•´çš„ Agent çŠ¶æ€æ•°æ®
    """
    task = await db.get(AgentTask, task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    project = await db.get(Project, task.project_id)
    if not project or project.owner_id != current_user.id:
        raise HTTPException(status_code=403, detail="æ— æƒè®¿é—®æ­¤ä»»åŠ¡")
    
    from app.models.agent_task import AgentCheckpoint
    
    checkpoint = await db.get(AgentCheckpoint, checkpoint_id)
    if not checkpoint or checkpoint.task_id != task_id:
        raise HTTPException(status_code=404, detail="æ£€æŸ¥ç‚¹ä¸å­˜åœ¨")
    
    # è§£æžçŠ¶æ€æ•°æ®
    state_data = {}
    if checkpoint.state_data:
        try:
            state_data = json.loads(checkpoint.state_data)
        except json.JSONDecodeError:
            pass
    
    return {
        "id": checkpoint.id,
        "task_id": checkpoint.task_id,
        "agent_id": checkpoint.agent_id,
        "agent_name": checkpoint.agent_name,
        "agent_type": checkpoint.agent_type,
        "parent_agent_id": checkpoint.parent_agent_id,
        "iteration": checkpoint.iteration,
        "status": checkpoint.status,
        "total_tokens": checkpoint.total_tokens,
        "tool_calls": checkpoint.tool_calls,
        "findings_count": checkpoint.findings_count,
        "checkpoint_type": checkpoint.checkpoint_type,
        "checkpoint_name": checkpoint.checkpoint_name,
        "state_data": state_data,
        "metadata": checkpoint.checkpoint_metadata,
        "created_at": checkpoint.created_at.isoformat() if checkpoint.created_at else None,
    }
