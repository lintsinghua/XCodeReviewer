"""
LLMæœåŠ¡ - ä»£ç åˆ†ææ ¸å¿ƒæœåŠ¡
æ”¯æŒä¸­è‹±æ–‡åŒè¯­è¾“å‡º
"""

import json
import re
import logging
from typing import Dict, Any, Optional, List
from .types import LLMConfig, LLMProvider, LLMMessage, LLMRequest, DEFAULT_MODELS
from .factory import LLMFactory
from app.core.config import settings

# json-repair åº“ç”¨äºä¿®å¤æŸåçš„ JSON
try:
    from json_repair import repair_json
    JSON_REPAIR_AVAILABLE = True
except ImportError:
    JSON_REPAIR_AVAILABLE = False

logger = logging.getLogger(__name__)


class LLMService:
    """LLMæœåŠ¡ç±»"""
    
    def __init__(self, user_config: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ–LLMæœåŠ¡
        
        Args:
            user_config: ç”¨æˆ·é…ç½®å­—å…¸ï¼ŒåŒ…å«llmConfigå­—æ®µ
        """
        self._config: Optional[LLMConfig] = None
        self._user_config = user_config or {}
    
    @property
    def config(self) -> LLMConfig:
        """
        è·å–LLMé…ç½®
        
        ğŸ”¥ ä¼˜å…ˆçº§ï¼ˆä»é«˜åˆ°ä½ï¼‰ï¼š
        1. æ•°æ®åº“ç”¨æˆ·é…ç½®ï¼ˆç³»ç»Ÿé…ç½®é¡µé¢ä¿å­˜çš„é…ç½®ï¼‰
        2. ç¯å¢ƒå˜é‡é…ç½®ï¼ˆ.env æ–‡ä»¶ä¸­çš„é…ç½®ï¼‰
        
        å¦‚æœç”¨æˆ·é…ç½®ä¸­æŸä¸ªå­—æ®µä¸ºç©ºï¼Œåˆ™è‡ªåŠ¨å›é€€åˆ°ç¯å¢ƒå˜é‡ã€‚
        """
        if self._config is None:
            user_llm_config = self._user_config.get('llmConfig', {})
            
            # ğŸ”¥ Provider ä¼˜å…ˆçº§ï¼šç”¨æˆ·é…ç½® > ç¯å¢ƒå˜é‡
            provider_str = user_llm_config.get('llmProvider') or getattr(settings, 'LLM_PROVIDER', 'openai')
            provider = self._parse_provider(provider_str)
            
            # ğŸ”¥ API Key ä¼˜å…ˆçº§ï¼šç”¨æˆ·é…ç½® > ç¯å¢ƒå˜é‡é€šç”¨é…ç½® > ç¯å¢ƒå˜é‡å¹³å°ä¸“å±é…ç½®
            api_key = (
                user_llm_config.get('llmApiKey') or
                getattr(settings, 'LLM_API_KEY', '') or
                self._get_provider_api_key_from_user_config(provider, user_llm_config) or
                self._get_provider_api_key(provider)
            )
            
            # ğŸ”¥ Base URL ä¼˜å…ˆçº§ï¼šç”¨æˆ·é…ç½® > ç¯å¢ƒå˜é‡
            base_url = (
                user_llm_config.get('llmBaseUrl') or
                getattr(settings, 'LLM_BASE_URL', None) or
                self._get_provider_base_url(provider)
            )
            
            # ğŸ”¥ Model ä¼˜å…ˆçº§ï¼šç”¨æˆ·é…ç½® > ç¯å¢ƒå˜é‡ > é»˜è®¤æ¨¡å‹
            model = (
                user_llm_config.get('llmModel') or
                getattr(settings, 'LLM_MODEL', '') or
                DEFAULT_MODELS.get(provider, 'gpt-4o-mini')
            )
            
            # ğŸ”¥ Timeout ä¼˜å…ˆçº§ï¼šç”¨æˆ·é…ç½®ï¼ˆæ¯«ç§’ï¼‰ > ç¯å¢ƒå˜é‡ï¼ˆç§’ï¼‰
            timeout_ms = user_llm_config.get('llmTimeout')
            if timeout_ms:
                # ç”¨æˆ·é…ç½®æ˜¯æ¯«ç§’ï¼Œè½¬æ¢ä¸ºç§’
                timeout = int(timeout_ms / 1000) if timeout_ms > 1000 else int(timeout_ms)
            else:
                # ç¯å¢ƒå˜é‡æ˜¯ç§’
                timeout = int(getattr(settings, 'LLM_TIMEOUT', 150))
            
            # ğŸ”¥ Temperature ä¼˜å…ˆçº§ï¼šç”¨æˆ·é…ç½® > ç¯å¢ƒå˜é‡
            temperature = user_llm_config.get('llmTemperature') if user_llm_config.get('llmTemperature') is not None else float(getattr(settings, 'LLM_TEMPERATURE', 0.1))
            
            # ğŸ”¥ Max Tokens ä¼˜å…ˆçº§ï¼šç”¨æˆ·é…ç½® > ç¯å¢ƒå˜é‡
            max_tokens = user_llm_config.get('llmMaxTokens') or int(getattr(settings, 'LLM_MAX_TOKENS', 4096))
            
            self._config = LLMConfig(
                provider=provider,
                api_key=api_key,
                model=model,
                base_url=base_url,
                timeout=timeout,
                temperature=temperature,
                max_tokens=max_tokens,
            )
        return self._config
    
    def _get_provider_api_key_from_user_config(self, provider: LLMProvider, user_llm_config: Dict[str, Any]) -> Optional[str]:
        """ä»ç”¨æˆ·é…ç½®ä¸­è·å–å¹³å°ä¸“å±API Key"""
        provider_key_map = {
            LLMProvider.OPENAI: 'openaiApiKey',
            LLMProvider.GEMINI: 'geminiApiKey',
            LLMProvider.CLAUDE: 'claudeApiKey',
            LLMProvider.QWEN: 'qwenApiKey',
            LLMProvider.DEEPSEEK: 'deepseekApiKey',
            LLMProvider.ZHIPU: 'zhipuApiKey',
            LLMProvider.MOONSHOT: 'moonshotApiKey',
            LLMProvider.BAIDU: 'baiduApiKey',
            LLMProvider.MINIMAX: 'minimaxApiKey',
            LLMProvider.DOUBAO: 'doubaoApiKey',
        }
        key_name = provider_key_map.get(provider)
        if key_name:
            return user_llm_config.get(key_name)
        return None
    
    def _get_provider_api_key(self, provider: LLMProvider) -> str:
        """æ ¹æ®æä¾›å•†è·å–API Key"""
        provider_key_map = {
            LLMProvider.OPENAI: 'OPENAI_API_KEY',
            LLMProvider.GEMINI: 'GEMINI_API_KEY',
            LLMProvider.CLAUDE: 'CLAUDE_API_KEY',
            LLMProvider.QWEN: 'QWEN_API_KEY',
            LLMProvider.DEEPSEEK: 'DEEPSEEK_API_KEY',
            LLMProvider.ZHIPU: 'ZHIPU_API_KEY',
            LLMProvider.MOONSHOT: 'MOONSHOT_API_KEY',
            LLMProvider.BAIDU: 'BAIDU_API_KEY',
            LLMProvider.MINIMAX: 'MINIMAX_API_KEY',
            LLMProvider.DOUBAO: 'DOUBAO_API_KEY',
            LLMProvider.OLLAMA: None,  # Ollama ä¸éœ€è¦ API Key
        }
        key_name = provider_key_map.get(provider)
        if key_name:
            return getattr(settings, key_name, '') or ''
        return 'ollama'  # Ollamaçš„é»˜è®¤å€¼
    
    def _get_provider_base_url(self, provider: LLMProvider) -> Optional[str]:
        """æ ¹æ®æä¾›å•†è·å–Base URL"""
        if provider == LLMProvider.OPENAI:
            return getattr(settings, 'OPENAI_BASE_URL', None)
        elif provider == LLMProvider.OLLAMA:
            return getattr(settings, 'OLLAMA_BASE_URL', 'http://localhost:11434/v1')
        return None
    
    def _parse_provider(self, provider_str: str) -> LLMProvider:
        """è§£æproviderå­—ç¬¦ä¸²"""
        provider_map = {
            'gemini': LLMProvider.GEMINI,
            'openai': LLMProvider.OPENAI,
            'claude': LLMProvider.CLAUDE,
            'qwen': LLMProvider.QWEN,
            'deepseek': LLMProvider.DEEPSEEK,
            'zhipu': LLMProvider.ZHIPU,
            'moonshot': LLMProvider.MOONSHOT,
            'baidu': LLMProvider.BAIDU,
            'minimax': LLMProvider.MINIMAX,
            'doubao': LLMProvider.DOUBAO,
            'ollama': LLMProvider.OLLAMA,
        }
        return provider_map.get(provider_str.lower(), LLMProvider.OPENAI)
    
    def _get_output_language(self) -> str:
        """è·å–è¾“å‡ºè¯­è¨€é…ç½®ï¼ˆä¼˜å…ˆä½¿ç”¨ç”¨æˆ·é…ç½®ï¼‰"""
        user_other_config = self._user_config.get('otherConfig', {})
        return user_other_config.get('outputLanguage') or getattr(settings, 'OUTPUT_LANGUAGE', 'zh-CN')
    
    def _build_system_prompt(self, is_chinese: bool) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯ï¼ˆæ”¯æŒä¸­è‹±æ–‡ï¼‰"""
        schema = """{
    "issues": [
        {
            "type": "security|bug|performance|style|maintainability",
            "severity": "critical|high|medium|low",
            "title": "string",
            "description": "string",
            "suggestion": "string",
            "line": 1,
            "column": 1,
            "code_snippet": "string",
            "ai_explanation": "string",
            "xai": {
                "what": "string",
                "why": "string",
                "how": "string",
                "learn_more": "string(optional)"
            }
        }
    ],
    "quality_score": 0-100,
    "summary": {
        "total_issues": number,
        "critical_issues": number,
        "high_issues": number,
        "medium_issues": number,
        "low_issues": number
    },
    "metrics": {
        "complexity": 0-100,
        "maintainability": 0-100,
        "security": 0-100,
        "performance": 0-100
    }
}"""

        if is_chinese:
            return f"""âš ï¸âš ï¸âš ï¸ åªè¾“å‡ºJSONï¼Œç¦æ­¢è¾“å‡ºå…¶ä»–ä»»ä½•æ ¼å¼ï¼ç¦æ­¢markdownï¼ç¦æ­¢æ–‡æœ¬åˆ†æï¼âš ï¸âš ï¸âš ï¸

ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç å®¡è®¡åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æä»£ç å¹¶è¿”å›ä¸¥æ ¼ç¬¦åˆJSON Schemaçš„ç»“æœã€‚

ã€æœ€é‡è¦ã€‘è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
1. å¿…é¡»åªè¾“å‡ºçº¯JSONå¯¹è±¡ï¼Œä»{{å¼€å§‹ï¼Œåˆ°}}ç»“æŸ
2. ç¦æ­¢åœ¨JSONå‰åæ·»åŠ ä»»ä½•æ–‡å­—ã€è¯´æ˜ã€markdownæ ‡è®°
3. ç¦æ­¢è¾“å‡º```jsonæˆ–###ç­‰markdownè¯­æ³•
4. å¦‚æœæ˜¯æ–‡æ¡£æ–‡ä»¶ï¼ˆå¦‚READMEï¼‰ï¼Œä¹Ÿå¿…é¡»ä»¥JSONæ ¼å¼è¾“å‡ºåˆ†æç»“æœ

ã€å†…å®¹è¦æ±‚ã€‘ï¼š
1. æ‰€æœ‰æ–‡æœ¬å†…å®¹å¿…é¡»ç»Ÿä¸€ä½¿ç”¨ç®€ä½“ä¸­æ–‡
2. JSONå­—ç¬¦ä¸²å€¼ä¸­çš„ç‰¹æ®Šå­—ç¬¦å¿…é¡»æ­£ç¡®è½¬ä¹‰ï¼ˆæ¢è¡Œç”¨\\nï¼ŒåŒå¼•å·ç”¨\\"ï¼Œåæ–œæ ç”¨\\\\ï¼‰
3. code_snippetå­—æ®µå¿…é¡»ä½¿ç”¨\\nè¡¨ç¤ºæ¢è¡Œ

è¯·ä»ä»¥ä¸‹ç»´åº¦å…¨é¢ã€å½»åº•åœ°åˆ†æä»£ç ï¼Œæ‰¾å‡ºæ‰€æœ‰é—®é¢˜ï¼š
- å®‰å…¨æ¼æ´ï¼ˆSQLæ³¨å…¥ã€XSSã€å‘½ä»¤æ³¨å…¥ã€è·¯å¾„éå†ã€SSRFã€XXEã€ååºåˆ—åŒ–ã€ç¡¬ç¼–ç å¯†é’¥ç­‰ï¼‰
- æ½œåœ¨çš„ Bug å’Œé€»è¾‘é”™è¯¯
- æ€§èƒ½é—®é¢˜å’Œä¼˜åŒ–å»ºè®®
- ç¼–ç è§„èŒƒå’Œä»£ç é£æ ¼
- å¯ç»´æŠ¤æ€§å’Œå¯è¯»æ€§
- æœ€ä½³å®è·µå’Œè®¾è®¡æ¨¡å¼

ã€é‡è¦ã€‘è¯·å°½å¯èƒ½å¤šåœ°æ‰¾å‡ºä»£ç ä¸­çš„æ‰€æœ‰é—®é¢˜ï¼Œä¸è¦é—æ¼ä»»ä½•å®‰å…¨æ¼æ´æˆ–æ½œåœ¨é£é™©ï¼

è¾“å‡ºæ ¼å¼å¿…é¡»ä¸¥æ ¼ç¬¦åˆä»¥ä¸‹ JSON Schemaï¼š

{schema}

æ³¨æ„ï¼š
- title: é—®é¢˜çš„ç®€çŸ­æ ‡é¢˜ï¼ˆä¸­æ–‡ï¼‰
- description: è¯¦ç»†æè¿°é—®é¢˜ï¼ˆä¸­æ–‡ï¼‰
- suggestion: å…·ä½“çš„ä¿®å¤å»ºè®®ï¼ˆä¸­æ–‡ï¼‰
- line: é—®é¢˜æ‰€åœ¨çš„è¡Œå·ï¼ˆä»1å¼€å§‹è®¡æ•°ï¼Œå¿…é¡»å‡†ç¡®å¯¹åº”ä»£ç ä¸­çš„è¡Œå·ï¼‰
- column: é—®é¢˜æ‰€åœ¨çš„åˆ—å·ï¼ˆä»1å¼€å§‹è®¡æ•°ï¼ŒæŒ‡å‘é—®é¢˜ä»£ç çš„èµ·å§‹ä½ç½®ï¼‰
- code_snippet: åŒ…å«é—®é¢˜çš„ä»£ç ç‰‡æ®µï¼ˆå»ºè®®åŒ…å«é—®é¢˜è¡ŒåŠå…¶å‰å1-2è¡Œä½œä¸ºä¸Šä¸‹æ–‡ï¼Œä¿æŒåŸå§‹ç¼©è¿›æ ¼å¼ï¼‰
- ai_explanation: AI çš„æ·±å…¥è§£é‡Šï¼ˆä¸­æ–‡ï¼‰
- xai.what: è¿™æ˜¯ä»€ä¹ˆé—®é¢˜ï¼ˆä¸­æ–‡ï¼‰
- xai.why: ä¸ºä»€ä¹ˆä¼šæœ‰è¿™ä¸ªé—®é¢˜ï¼ˆä¸­æ–‡ï¼‰
- xai.how: å¦‚ä½•ä¿®å¤è¿™ä¸ªé—®é¢˜ï¼ˆä¸­æ–‡ï¼‰

ã€é‡è¦ã€‘å…³äºè¡Œå·å’Œä»£ç ç‰‡æ®µï¼š
1. line å¿…é¡»æ˜¯é—®é¢˜ä»£ç çš„è¡Œå·ï¼ï¼ï¼ä»£ç å·¦ä¾§æœ‰"è¡Œå·|"æ ‡æ³¨ï¼Œä¾‹å¦‚"25| const x = 1"è¡¨ç¤ºç¬¬25è¡Œï¼Œlineå­—æ®µå¿…é¡»å¡«25
2. column æ˜¯é—®é¢˜ä»£ç åœ¨è¯¥è¡Œä¸­çš„èµ·å§‹åˆ—ä½ç½®ï¼ˆä»1å¼€å§‹ï¼Œä¸åŒ…æ‹¬"è¡Œå·|"å‰ç¼€éƒ¨åˆ†ï¼‰
3. code_snippet åº”è¯¥åŒ…å«é—®é¢˜ä»£ç åŠå…¶ä¸Šä¸‹æ–‡ï¼ˆå‰åå„1-2è¡Œï¼‰ï¼Œå»æ‰"è¡Œå·|"å‰ç¼€ï¼Œä¿æŒåŸå§‹ä»£ç çš„ç¼©è¿›
4. å¦‚æœä»£ç ç‰‡æ®µåŒ…å«å¤šè¡Œï¼Œå¿…é¡»ä½¿ç”¨ \\n è¡¨ç¤ºæ¢è¡Œç¬¦ï¼ˆè¿™æ˜¯JSONçš„è¦æ±‚ï¼‰
5. å¦‚æœæ— æ³•ç¡®å®šå‡†ç¡®çš„è¡Œå·ï¼Œä¸è¦å¡«å†™lineå’Œcolumnå­—æ®µï¼ˆä¸è¦å¡«0ï¼‰

ã€ä¸¥æ ¼ç¦æ­¢ã€‘ï¼š
- ç¦æ­¢åœ¨ä»»ä½•å­—æ®µä¸­ä½¿ç”¨è‹±æ–‡ï¼Œæ‰€æœ‰å†…å®¹å¿…é¡»æ˜¯ç®€ä½“ä¸­æ–‡
- ç¦æ­¢åœ¨JSONå­—ç¬¦ä¸²å€¼ä¸­ä½¿ç”¨çœŸå®æ¢è¡Œç¬¦ï¼Œå¿…é¡»ç”¨\\nè½¬ä¹‰
- ç¦æ­¢è¾“å‡ºmarkdownä»£ç å—æ ‡è®°ï¼ˆå¦‚```jsonï¼‰

âš ï¸ é‡è¦æé†’ï¼šlineå­—æ®µå¿…é¡»ä»ä»£ç å·¦ä¾§çš„è¡Œå·æ ‡æ³¨ä¸­è¯»å–ï¼Œä¸è¦çŒœæµ‹æˆ–å¡«0ï¼"""
        else:
            return f"""âš ï¸âš ï¸âš ï¸ OUTPUT JSON ONLY! NO OTHER FORMAT! NO MARKDOWN! NO TEXT ANALYSIS! âš ï¸âš ï¸âš ï¸

You are a professional code auditing assistant. Your task is to analyze code and return results in strict JSON Schema format.

ã€MOST IMPORTANTã€‘Output format requirements:
1. MUST output pure JSON object only, starting with {{ and ending with }}
2. NO text, explanation, or markdown markers before or after JSON
3. NO ```json or ### markdown syntax
4. Even for document files (like README), output analysis in JSON format

ã€Content requirementsã€‘:
1. All text content MUST be in English ONLY
2. Special characters in JSON strings must be properly escaped (\\n for newlines, \\" for quotes, \\\\ for backslashes)
3. code_snippet field MUST use \\n for newlines

Please comprehensively and thoroughly analyze the code, finding ALL issues from the following dimensions:
- Security vulnerabilities (SQL injection, XSS, command injection, path traversal, SSRF, XXE, deserialization, hardcoded secrets, etc.)
- Potential bugs and logical errors
- Performance issues and optimization suggestions
- Coding standards and code style
- Maintainability and readability
- Best practices and design patterns

ã€IMPORTANTã€‘Find as many issues as possible! Do NOT miss any security vulnerabilities or potential risks!

The output format MUST strictly conform to the following JSON Schema:

{schema}

Note:
- title: Brief title of the issue (in English)
- description: Detailed description of the issue (in English)
- suggestion: Specific fix suggestions (in English)
- line: Line number where the issue occurs (1-indexed, must accurately correspond to the line in the code)
- column: Column number where the issue starts (1-indexed, pointing to the start position of the problematic code)
- code_snippet: Code snippet containing the issue (should include the problem line plus 1-2 lines before and after for context, preserve original indentation)
- ai_explanation: AI's in-depth explanation (in English)
- xai.what: What is this issue (in English)
- xai.why: Why does this issue exist (in English)
- xai.how: How to fix this issue (in English)

ã€IMPORTANTã€‘About line numbers and code snippets:
1. 'line' MUST be the line number from code!!! Code has "lineNumber|" prefix, e.g. "25| const x = 1" means line 25, you MUST set line to 25
2. 'column' is the starting column position in that line (1-indexed, excluding the "lineNumber|" prefix)
3. 'code_snippet' should include the problematic code with context (1-2 lines before/after), remove "lineNumber|" prefix, preserve indentation
4. If code snippet has multiple lines, use \\n for newlines (JSON requirement)
5. If you cannot determine the exact line number, do NOT fill line and column fields (don't use 0)

ã€STRICTLY PROHIBITEDã€‘:
- NO Chinese characters in any field - English ONLY
- NO real newline characters in JSON string values - must use \\n
- NO markdown code block markers (like ```json)

âš ï¸ CRITICAL: Read line numbers from the "lineNumber|" prefix on the left of each code line. Do NOT guess or use 0!"""

    async def analyze_code(self, code: str, language: str) -> Dict[str, Any]:
        """
        åˆ†æä»£ç å¹¶è¿”å›ç»“æ„åŒ–é—®é¢˜
        æ”¯æŒä¸­è‹±æ–‡è¾“å‡º
        
        Raises:
            Exception: å½“LLMè°ƒç”¨å¤±è´¥æˆ–è¿”å›æ— æ•ˆå“åº”æ—¶æŠ›å‡ºå¼‚å¸¸
        """
        # è·å–è¾“å‡ºè¯­è¨€é…ç½®
        output_language = self._get_output_language()
        is_chinese = output_language == 'zh-CN'
        
        # æ·»åŠ è¡Œå·å¸®åŠ©LLMå®šä½é—®é¢˜
        code_with_lines = '\n'.join(
            f"{i+1}| {line}" for i, line in enumerate(code.split('\n'))
        )
        
        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = self._build_system_prompt(is_chinese)
        
        # æ„å»ºç”¨æˆ·æç¤ºè¯
        if is_chinese:
            user_prompt = f"""ç¼–ç¨‹è¯­è¨€: {language}

âš ï¸ ä»£ç å·²æ ‡æ³¨è¡Œå·ï¼ˆæ ¼å¼ï¼šè¡Œå·| ä»£ç å†…å®¹ï¼‰ï¼Œè¯·æ ¹æ®è¡Œå·å‡†ç¡®å¡«å†™ line å­—æ®µï¼

è¯·åˆ†æä»¥ä¸‹ä»£ç :

{code_with_lines}"""
        else:
            user_prompt = f"""Programming Language: {language}

âš ï¸ Code is annotated with line numbers (format: lineNumber| code), please fill the 'line' field accurately based on these numbers!

Please analyze the following code:

{code_with_lines}"""
        
        try:
            adapter = LLMFactory.create_adapter(self.config)
            
            request = LLMRequest(
                messages=[
                    LLMMessage(role="system", content=system_prompt),
                    LLMMessage(role="user", content=user_prompt)
                ],
                temperature=0.1,
            )
            
            response = await adapter.complete(request)
            content = response.content
            
            # è®°å½• LLM åŸå§‹å“åº”ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            logger.info(f"ğŸ“¥ LLM åŸå§‹å“åº”é•¿åº¦: {len(content) if content else 0} å­—ç¬¦")
            logger.info(f"ğŸ“¥ LLM åŸå§‹å“åº”å†…å®¹:\n{content}")
            
            # æ£€æŸ¥å“åº”å†…å®¹æ˜¯å¦ä¸ºç©º
            if not content or not content.strip():
                error_msg = f"LLMè¿”å›ç©ºå“åº” - Provider: {self.config.provider.value}, Model: {self.config.model}"
                logger.error(error_msg)
                logger.error(f"å“åº”è¯¦æƒ… - Finish Reason: {response.finish_reason}, Usage: {response.usage}")
                raise Exception(error_msg)
            
            # å°è¯•ä»å“åº”ä¸­æå–JSON
            result = self._parse_json(content)
            
            # è®°å½•è§£æåçš„é—®é¢˜æ•°é‡
            issues_count = len(result.get("issues", []))
            logger.info(f"ğŸ“Š LLM åˆ†æç»“æœ: å‘ç° {issues_count} ä¸ªé—®é¢˜, è´¨é‡è¯„åˆ†: {result.get('quality_score', 'N/A')}")
            
            # æ£€æŸ¥è§£æç»“æœæ˜¯å¦æœ‰æ•ˆï¼ˆä¸æ˜¯é»˜è®¤å“åº”ï¼‰
            if result == self._get_default_response():
                error_msg = f"æ— æ³•è§£æLLMå“åº”ä¸ºæœ‰æ•ˆçš„åˆ†æç»“æœ - Provider: {self.config.provider.value}"
                logger.error(error_msg)
                raise Exception(error_msg)
            
            return result
            
        except Exception as e:
            logger.error(f"LLM Analysis failed: {e}", exc_info=True)
            logger.error(f"Provider: {self.config.provider.value}, Model: {self.config.model}")
            # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®©è°ƒç”¨è€…å¤„ç†
            raise
    
    async def chat_completion_raw(
        self,
        messages: List[Dict[str, str]],
        temperature: float = 0.1,
        max_tokens: int = 4096,
    ) -> Dict[str, Any]:
        """
        ğŸ”¥ Agent ä½¿ç”¨çš„åŸå§‹èŠå¤©å®Œæˆæ¥å£ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨ï¼Œæ ¼å¼ä¸º [{"role": "user", "content": "..."}]
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§tokenæ•°
            
        Returns:
            åŒ…å« content å’Œ usage çš„å­—å…¸
        """
        # è½¬æ¢æ¶ˆæ¯æ ¼å¼
        llm_messages = [
            LLMMessage(role=msg["role"], content=msg["content"])
            for msg in messages
        ]
        
        request = LLMRequest(
            messages=llm_messages,
            temperature=temperature,
            max_tokens=max_tokens,
        )
        
        adapter = LLMFactory.create_adapter(self.config)
        response = await adapter.complete(request)
        
        return {
            "content": response.content,
            "usage": {
                "prompt_tokens": response.usage.prompt_tokens if response.usage else 0,
                "completion_tokens": response.usage.completion_tokens if response.usage else 0,
                "total_tokens": response.usage.total_tokens if response.usage else 0,
            },
        }
    
    async def chat_completion_stream(
        self,
        messages: List[Dict[str, str]],
        temperature: float = 0.1,
        max_tokens: int = 4096,
    ):
        """
        æµå¼èŠå¤©å®Œæˆæ¥å£ï¼Œé€ token è¿”å›
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§tokenæ•°
            
        Yields:
            dict: {"type": "token", "content": str} æˆ– {"type": "done", ...}
        """
        from .adapters.litellm_adapter import LiteLLMAdapter
        
        llm_messages = [
            LLMMessage(role=msg["role"], content=msg["content"])
            for msg in messages
        ]
        
        request = LLMRequest(
            messages=llm_messages,
            temperature=temperature,
            max_tokens=max_tokens,
        )
        
        # ä½¿ç”¨ LiteLLM adapter è¿›è¡Œæµå¼è°ƒç”¨
        adapter = LiteLLMAdapter(self.config)
        
        async for chunk in adapter.stream_complete(request):
            yield chunk
    
    def _parse_json(self, text: str) -> Dict[str, Any]:
        """ä»LLMå“åº”ä¸­è§£æJSONï¼ˆå¢å¼ºç‰ˆï¼‰"""
        
        # æ£€æŸ¥è¾“å…¥æ˜¯å¦ä¸ºç©º
        if not text or not text.strip():
            logger.error("LLMå“åº”å†…å®¹ä¸ºç©ºï¼Œæ— æ³•è§£æJSON")
            raise ValueError("LLMå“åº”å†…å®¹ä¸ºç©º")
        
        def clean_text(s: str) -> str:
            """æ¸…ç†æ–‡æœ¬ä¸­çš„æ§åˆ¶å­—ç¬¦"""
            # ç§»é™¤BOMå’Œé›¶å®½å­—ç¬¦
            s = s.replace('\ufeff', '').replace('\u200b', '').replace('\u200c', '').replace('\u200d', '')
            return s
        
        def fix_json_format(s: str) -> str:
            """ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜"""
            s = s.strip()
            # ç§»é™¤å°¾éƒ¨é€—å·
            s = re.sub(r',(\s*[}\]])', r'\1', s)
            # ä¿®å¤æœªè½¬ä¹‰çš„æ¢è¡Œç¬¦ï¼ˆåœ¨å­—ç¬¦ä¸²å€¼ä¸­ï¼‰
            s = re.sub(r':\s*"([^"]*)\n([^"]*)"', r': "\1\\n\2"', s)
            return s
        
        def aggressive_fix_json(s: str) -> str:
            """æ¿€è¿›çš„JSONä¿®å¤ï¼šå°è¯•ä¿®å¤æ›´å¤šæ ¼å¼é—®é¢˜"""
            s = clean_text(s)
            s = s.strip()
            
            # æ‰¾åˆ°ç¬¬ä¸€ä¸ª { å’Œæœ€åä¸€ä¸ª }
            start_idx = s.find('{')
            if start_idx == -1:
                raise ValueError("No JSON object found")
            
            # å°è¯•æ‰¾åˆ°æœ€åä¸€ä¸ª }
            last_brace = s.rfind('}')
            if last_brace > start_idx:
                s = s[start_idx:last_brace + 1]
            
            # ä¿®å¤å¸¸è§çš„JSONé—®é¢˜
            # 1. ç§»é™¤å°¾éƒ¨é€—å·
            s = re.sub(r',(\s*[}\]])', r'\1', s)
            # 2. ä¿®å¤å•å¼•å·ä¸ºåŒå¼•å·ï¼ˆä»…åœ¨é”®åä¸­ï¼Œå°å¿ƒå¤„ç†ï¼‰
            s = re.sub(r"'(\w+)'\s*:", r'"\1":', s)
            # 3. ä¿®å¤æœªè½¬ä¹‰çš„æ§åˆ¶å­—ç¬¦ï¼ˆåœ¨å­—ç¬¦ä¸²å€¼ä¸­ï¼Œä½†ä¸åœ¨é”®åä¸­ï¼‰
            # åªç§»é™¤ä¸åœ¨å¼•å·å†…çš„æ§åˆ¶å­—ç¬¦ï¼Œæˆ–æœªè½¬ä¹‰çš„æ¢è¡Œç¬¦/åˆ¶è¡¨ç¬¦
            lines = []
            in_string = False
            escape_next = False
            for char in s:
                if escape_next:
                    escape_next = False
                    lines.append(char)
                    continue
                if char == '\\':
                    escape_next = True
                    lines.append(char)
                    continue
                if char == '"':
                    in_string = not in_string
                    lines.append(char)
                    continue
                # å¦‚æœåœ¨å­—ç¬¦ä¸²å¤–ï¼Œç§»é™¤æ§åˆ¶å­—ç¬¦ï¼›å¦‚æœåœ¨å­—ç¬¦ä¸²å†…ï¼Œä¿ç•™ï¼ˆå‡è®¾å·²è½¬ä¹‰ï¼‰
                if not in_string and ord(char) < 32 and char not in ['\n', '\t', '\r']:
                    continue  # è·³è¿‡æ§åˆ¶å­—ç¬¦
                lines.append(char)
            s = ''.join(lines)
            
            return s
        
        # å°è¯•å¤šç§æ–¹å¼è§£æ
        attempts = [
            # 1. ç›´æ¥è§£æ
            lambda: json.loads(text),
            # 2. æ¸…ç†åè§£æ
            lambda: json.loads(fix_json_format(clean_text(text))),
            # 3. ä»markdownä»£ç å—æå–
            lambda: self._extract_from_markdown(text),
            # 4. æ™ºèƒ½æå–JSONå¯¹è±¡
            lambda: self._extract_json_object(clean_text(text)),
            # 5. ä¿®å¤æˆªæ–­çš„JSON
            lambda: self._fix_truncated_json(clean_text(text)),
            # 6. æ¿€è¿›ä¿®å¤åè§£æ
            lambda: json.loads(aggressive_fix_json(text)),
            # 7. ä½¿ç”¨ json-repair åº“ä½œä¸ºæœ€ç»ˆå…œåº•æ–¹æ¡ˆ
            lambda: self._repair_json_with_library(text),
        ]
        
        last_error = None
        for i, attempt in enumerate(attempts):
            try:
                result = attempt()
                if result and isinstance(result, dict):
                    if i > 0:
                        logger.info(f"âœ… JSONè§£ææˆåŠŸï¼ˆæ–¹æ³• {i + 1}/{len(attempts)}ï¼‰")
                    return result
            except Exception as e:
                last_error = e
                if i == 0:
                    logger.debug(f"ç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•å…¶ä»–æ–¹æ³•... {e}")
        
        # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥
        logger.error("âŒ æ— æ³•è§£æLLMå“åº”ä¸ºJSON")
        logger.error(f"åŸå§‹å†…å®¹é•¿åº¦: {len(text)} å­—ç¬¦")
        logger.error(f"åŸå§‹å†…å®¹ï¼ˆå‰500å­—ç¬¦ï¼‰: {text[:500]}")
        logger.error(f"åŸå§‹å†…å®¹ï¼ˆå500å­—ç¬¦ï¼‰: {text[-500:] if len(text) > 500 else text}")
        if last_error:
            logger.error(f"æœ€åé”™è¯¯: {type(last_error).__name__}: {str(last_error)}")
        # æŠ›å‡ºå¼‚å¸¸è€Œä¸æ˜¯è¿”å›é»˜è®¤å“åº”
        raise ValueError(f"æ— æ³•è§£æLLMå“åº”ä¸ºæœ‰æ•ˆçš„JSONæ ¼å¼: {str(last_error) if last_error else 'æœªçŸ¥é”™è¯¯'}")
    
    def _extract_from_markdown(self, text: str) -> Dict[str, Any]:
        """ä»markdownä»£ç å—æå–JSON"""
        match = re.search(r'```(?:json)?\s*(\{[\s\S]*?\})\s*```', text)
        if match:
            return json.loads(match.group(1))
        raise ValueError("No markdown code block found")
    
    def _extract_json_object(self, text: str) -> Dict[str, Any]:
        """æ™ºèƒ½æå–JSONå¯¹è±¡"""
        start_idx = text.find('{')
        if start_idx == -1:
            raise ValueError("No JSON object found")
        
        # è€ƒè™‘å­—ç¬¦ä¸²å†…çš„èŠ±æ‹¬å·å’Œè½¬ä¹‰å­—ç¬¦
        brace_count = 0
        bracket_count = 0
        in_string = False
        escape_next = False
        end_idx = -1
        
        for i in range(start_idx, len(text)):
            char = text[i]
            
            if escape_next:
                escape_next = False
                continue
            
            if char == '\\':
                escape_next = True
                continue
            
            if char == '"' and not escape_next:
                in_string = not in_string
                continue
            
            if not in_string:
                if char == '{':
                    brace_count += 1
                elif char == '}':
                    brace_count -= 1
                    if brace_count == 0 and bracket_count == 0:
                        end_idx = i + 1
                        break
                elif char == '[':
                    bracket_count += 1
                elif char == ']':
                    bracket_count -= 1
        
        if end_idx == -1:
            # å¦‚æœæ‰¾ä¸åˆ°å®Œæ•´çš„JSONï¼Œå°è¯•ä½¿ç”¨æœ€åä¸€ä¸ª }
            last_brace = text.rfind('}')
            if last_brace > start_idx:
                end_idx = last_brace + 1
            else:
                raise ValueError("Incomplete JSON object")
        
        json_str = text[start_idx:end_idx]
        # ä¿®å¤æ ¼å¼é—®é¢˜
        json_str = re.sub(r',(\s*[}\]])', r'\1', json_str)
        # å°è¯•ä¿®å¤æœªé—­åˆçš„æ‹¬å·
        open_braces = json_str.count('{') - json_str.count('}')
        open_brackets = json_str.count('[') - json_str.count(']')
        if open_braces > 0:
            json_str += '}' * open_braces
        if open_brackets > 0:
            json_str += ']' * open_brackets
        
        return json.loads(json_str)
    
    def _fix_truncated_json(self, text: str) -> Dict[str, Any]:
        """ä¿®å¤æˆªæ–­çš„JSON"""
        start_idx = text.find('{')
        if start_idx == -1:
            raise ValueError("Cannot fix truncated JSON")
        
        json_str = text[start_idx:]
        
        # è®¡ç®—ç¼ºå¤±çš„é—­åˆç¬¦å·
        open_braces = json_str.count('{')
        close_braces = json_str.count('}')
        open_brackets = json_str.count('[')
        close_brackets = json_str.count(']')
        
        # è¡¥å…¨ç¼ºå¤±çš„é—­åˆç¬¦å·
        json_str += ']' * max(0, open_brackets - close_brackets)
        json_str += '}' * max(0, open_braces - close_braces)
        
        # ä¿®å¤æ ¼å¼
        json_str = re.sub(r',(\s*[}\]])', r'\1', json_str)
        return json.loads(json_str)
    
    def _repair_json_with_library(self, text: str) -> Dict[str, Any]:
        """ä½¿ç”¨ json-repair åº“ä¿®å¤æŸåçš„ JSONï¼ˆå…œåº•æ–¹æ¡ˆï¼‰"""
        if not JSON_REPAIR_AVAILABLE:
            raise ValueError("json-repair library not available")
        
        # å…ˆå°è¯•æå– JSON éƒ¨åˆ†
        start_idx = text.find('{')
        if start_idx == -1:
            raise ValueError("No JSON object found for repair")
        
        # å°è¯•æ‰¾åˆ°æœ€åä¸€ä¸ª }
        end_idx = text.rfind('}')
        if end_idx > start_idx:
            json_str = text[start_idx:end_idx + 1]
        else:
            json_str = text[start_idx:]
        
        # ä½¿ç”¨ json-repair ä¿®å¤
        repaired = repair_json(json_str, return_objects=True)
        
        if isinstance(repaired, dict):
            logger.info("âœ… json-repair åº“æˆåŠŸä¿®å¤ JSON")
            return repaired
        
        raise ValueError(f"json-repair returned unexpected type: {type(repaired)}")
    
    def _get_default_response(self) -> Dict[str, Any]:
        """è¿”å›é»˜è®¤å“åº”"""
        return {
            "issues": [],
            "quality_score": 80,
            "summary": {
                "total_issues": 0,
                "critical_issues": 0,
                "high_issues": 0,
                "medium_issues": 0,
                "low_issues": 0
            },
            "metrics": {
                "complexity": 80,
                "maintainability": 80,
                "security": 80,
                "performance": 80
            }
        }

    async def analyze_code_with_custom_prompt(
        self, 
        code: str, 
        language: str, 
        custom_prompt: str,
        rules: Optional[list] = None,
        output_language: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯åˆ†æä»£ç 
        
        Args:
            code: è¦åˆ†æçš„ä»£ç 
            language: ç¼–ç¨‹è¯­è¨€
            custom_prompt: è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯
            rules: å¯é€‰çš„å®¡è®¡è§„åˆ™åˆ—è¡¨
            output_language: è¾“å‡ºè¯­è¨€ (zh/en)ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨ç³»ç»Ÿé…ç½®
        """
        if output_language:
            is_chinese = output_language == 'zh'
        else:
            system_output_language = self._get_output_language()
            is_chinese = system_output_language == 'zh-CN'
        
        # æ·»åŠ è¡Œå·
        code_with_lines = '\n'.join(
            f"{i+1}| {line}" for i, line in enumerate(code.split('\n'))
        )
        
        # æ„å»ºè§„åˆ™æç¤ºè¯
        rules_prompt = ""
        if rules:
            rules_prompt = "\n\nã€å®¡è®¡è§„åˆ™ã€‘è¯·ç‰¹åˆ«å…³æ³¨ä»¥ä¸‹è§„åˆ™ï¼š\n"
            for rule in rules:
                if rule.get('enabled', True):
                    rules_prompt += f"- [{rule.get('rule_code', '')}] {rule.get('name', '')}: {rule.get('description', '')}\n"
                    if rule.get('custom_prompt'):
                        rules_prompt += f"  æ£€æµ‹è¦ç‚¹: {rule.get('custom_prompt')}\n"
        
        # JSON Schema
        schema = """{
    "issues": [
        {
            "type": "security|bug|performance|style|maintainability",
            "severity": "critical|high|medium|low",
            "title": "string",
            "description": "string",
            "suggestion": "string",
            "line": 1,
            "column": 1,
            "code_snippet": "string",
            "rule_code": "string (optional, if matched a specific rule)"
        }
    ],
    "quality_score": 0-100,
    "summary": {
        "total_issues": number,
        "critical_issues": number,
        "high_issues": number,
        "medium_issues": number,
        "low_issues": number
    }
}"""
        
        # æ„å»ºå®Œæ•´çš„ç³»ç»Ÿæç¤ºè¯
        if is_chinese:
            format_instruction = f"""

ã€è¾“å‡ºæ ¼å¼è¦æ±‚ã€‘
1. å¿…é¡»åªè¾“å‡ºçº¯JSONå¯¹è±¡
2. ç¦æ­¢åœ¨JSONå‰åæ·»åŠ ä»»ä½•æ–‡å­—ã€è¯´æ˜ã€markdownæ ‡è®°
3. æ‰€æœ‰æ–‡æœ¬å­—æ®µï¼ˆtitle, description, suggestionç­‰ï¼‰å¿…é¡»ä½¿ç”¨ä¸­æ–‡è¾“å‡º
4. è¾“å‡ºæ ¼å¼å¿…é¡»ç¬¦åˆä»¥ä¸‹ JSON Schemaï¼š

{schema}
{rules_prompt}"""
        else:
            format_instruction = f"""

ã€Output Format Requirementsã€‘
1. Must output pure JSON object only
2. Do not add any text, explanation, or markdown markers before or after JSON
3. All text fields (title, description, suggestion, etc.) must be in English
4. Output format must conform to the following JSON Schema:

{schema}
{rules_prompt}"""
        
        full_system_prompt = custom_prompt + format_instruction
        
        # æ„å»ºç”¨æˆ·æç¤ºè¯
        if is_chinese:
            user_prompt = f"""ç¼–ç¨‹è¯­è¨€: {language}

ä»£ç å·²æ ‡æ³¨è¡Œå·ï¼ˆæ ¼å¼ï¼šè¡Œå·| ä»£ç å†…å®¹ï¼‰ï¼Œè¯·æ ¹æ®è¡Œå·å‡†ç¡®å¡«å†™ line å­—æ®µã€‚

è¯·åˆ†æä»¥ä¸‹ä»£ç :

{code_with_lines}"""
        else:
            user_prompt = f"""Programming Language: {language}

Code is annotated with line numbers (format: lineNumber| code), please fill the 'line' field accurately.

Please analyze the following code:

{code_with_lines}"""
        
        try:
            adapter = LLMFactory.create_adapter(self.config)
            
            request = LLMRequest(
                messages=[
                    LLMMessage(role="system", content=full_system_prompt),
                    LLMMessage(role="user", content=user_prompt)
                ],
                temperature=0.1,
            )
            
            response = await adapter.complete(request)
            content = response.content
            
            if not content or not content.strip():
                raise Exception("LLMè¿”å›ç©ºå“åº”")
            
            result = self._parse_json(content)
            return result
            
        except Exception as e:
            logger.error(f"Custom prompt analysis failed: {e}", exc_info=True)
            raise

    async def analyze_code_with_rules(
        self, 
        code: str, 
        language: str,
        rule_set_id: Optional[str] = None,
        prompt_template_id: Optional[str] = None,
        db_session = None,
        use_default_template: bool = True
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨æŒ‡å®šçš„è§„åˆ™é›†å’Œæç¤ºè¯æ¨¡æ¿åˆ†æä»£ç 
        
        Args:
            code: è¦åˆ†æçš„ä»£ç 
            language: ç¼–ç¨‹è¯­è¨€
            rule_set_id: è§„åˆ™é›†IDï¼ˆå¯é€‰ï¼‰
            prompt_template_id: æç¤ºè¯æ¨¡æ¿IDï¼ˆå¯é€‰ï¼‰
            db_session: æ•°æ®åº“ä¼šè¯
            use_default_template: å½“æ²¡æœ‰æŒ‡å®šæ¨¡æ¿æ—¶æ˜¯å¦ä½¿ç”¨æ•°æ®åº“ä¸­çš„é»˜è®¤æ¨¡æ¿
        """
        custom_prompt = None
        rules = None
        
        if db_session:
            from sqlalchemy.future import select
            from sqlalchemy.orm import selectinload
            from app.models.prompt_template import PromptTemplate
            
            # è·å–æç¤ºè¯æ¨¡æ¿
            if prompt_template_id:
                result = await db_session.execute(
                    select(PromptTemplate).where(PromptTemplate.id == prompt_template_id)
                )
                template = result.scalar_one_or_none()
                if template:
                    output_language = self._get_output_language()
                    custom_prompt = template.content_zh if output_language == 'zh-CN' else template.content_en
            elif use_default_template:
                # æ²¡æœ‰æŒ‡å®šæ¨¡æ¿æ—¶ï¼Œä½¿ç”¨æ•°æ®åº“ä¸­çš„é»˜è®¤æ¨¡æ¿
                result = await db_session.execute(
                    select(PromptTemplate).where(
                        PromptTemplate.is_default == True,
                        PromptTemplate.is_active == True,
                        PromptTemplate.template_type == 'system'
                    )
                )
                template = result.scalar_one_or_none()
                if template:
                    output_language = self._get_output_language()
                    custom_prompt = template.content_zh if output_language == 'zh-CN' else template.content_en
                    logger.info(f"ğŸ“‹ ä½¿ç”¨é»˜è®¤æç¤ºè¯æ¨¡æ¿: {template.name}")
            
            # è·å–è§„åˆ™é›†
            if rule_set_id:
                from app.models.audit_rule import AuditRuleSet
                result = await db_session.execute(
                    select(AuditRuleSet)
                    .options(selectinload(AuditRuleSet.rules))
                    .where(AuditRuleSet.id == rule_set_id)
                )
                rule_set = result.scalar_one_or_none()
                if rule_set and rule_set.rules:
                    rules = [
                        {
                            "rule_code": r.rule_code,
                            "name": r.name,
                            "description": r.description,
                            "category": r.category,
                            "severity": r.severity,
                            "custom_prompt": r.custom_prompt,
                            "enabled": r.enabled,
                        }
                        for r in rule_set.rules if r.enabled
                    ]
        
        # å¦‚æœæœ‰è‡ªå®šä¹‰æç¤ºè¯ï¼Œä½¿ç”¨è‡ªå®šä¹‰åˆ†æ
        if custom_prompt:
            return await self.analyze_code_with_custom_prompt(code, language, custom_prompt, rules)
        
        # å¦åˆ™ä½¿ç”¨ç¡¬ç¼–ç çš„é»˜è®¤åˆ†æï¼ˆå…œåº•ï¼‰
        return await self.analyze_code(code, language)


# å…¨å±€æœåŠ¡å®ä¾‹
llm_service = LLMService()
