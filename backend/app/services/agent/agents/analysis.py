"""
Analysis Agent (æ¼æ´åˆ†æå±‚) - LLM é©±åŠ¨ç‰ˆ

LLM æ˜¯çœŸæ­£çš„å®‰å…¨åˆ†æå¤§è„‘ï¼
- LLM å†³å®šåˆ†æç­–ç•¥
- LLM é€‰æ‹©ä½¿ç”¨ä»€ä¹ˆå·¥å…·
- LLM å†³å®šæ·±å…¥åˆ†æå“ªäº›ä»£ç 
- LLM åˆ¤æ–­å‘ç°çš„é—®é¢˜æ˜¯å¦æ˜¯çœŸå®æ¼æ´

ç±»å‹: ReAct (çœŸæ­£çš„!)
"""

import asyncio
import json
import logging
import re
from typing import List, Dict, Any, Optional
from dataclasses import dataclass

from .base import BaseAgent, AgentConfig, AgentResult, AgentType, AgentPattern
from ..json_parser import AgentJsonParser
from ..prompts import CORE_SECURITY_PRINCIPLES, VULNERABILITY_PRIORITIES

logger = logging.getLogger(__name__)


ANALYSIS_SYSTEM_PROMPT = """ä½ æ˜¯ DeepAudit çš„æ¼æ´åˆ†æ Agentï¼Œä¸€ä¸ª**è‡ªä¸»**çš„å®‰å…¨ä¸“å®¶ã€‚

## ä½ çš„è§’è‰²
ä½ æ˜¯å®‰å…¨å®¡è®¡çš„**æ ¸å¿ƒå¤§è„‘**ï¼Œä¸æ˜¯å·¥å…·æ‰§è¡Œå™¨ã€‚ä½ éœ€è¦ï¼š
1. è‡ªä¸»åˆ¶å®šåˆ†æç­–ç•¥
2. é€‰æ‹©æœ€æœ‰æ•ˆçš„å·¥å…·å’Œæ–¹æ³•
3. æ·±å…¥åˆ†æå¯ç–‘ä»£ç 
4. åˆ¤æ–­æ˜¯å¦æ˜¯çœŸå®æ¼æ´
5. åŠ¨æ€è°ƒæ•´åˆ†ææ–¹å‘

## âš ï¸ æ ¸å¿ƒåŸåˆ™ï¼šä¼˜å…ˆä½¿ç”¨å¤–éƒ¨ä¸“ä¸šå·¥å…·ï¼

**å¤–éƒ¨å·¥å…·ä¼˜å…ˆçº§æœ€é«˜ï¼** å¿…é¡»é¦–å…ˆä½¿ç”¨å¤–éƒ¨å®‰å…¨å·¥å…·è¿›è¡Œæ‰«æï¼Œå®ƒä»¬æœ‰ï¼š
- ç»è¿‡éªŒè¯çš„ä¸“ä¸šè§„åˆ™åº“
- æ›´ä½çš„è¯¯æŠ¥ç‡
- æ›´å…¨é¢çš„æ¼æ´æ£€æµ‹èƒ½åŠ›

## ğŸ”§ å·¥å…·ä¼˜å…ˆçº§ï¼ˆå¿…é¡»æŒ‰æ­¤é¡ºåºä½¿ç”¨ï¼‰

### ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šå¤–éƒ¨ä¸“ä¸šå®‰å…¨å·¥å…· â­â­â­ ã€å¿…é¡»é¦–å…ˆä½¿ç”¨ï¼ã€‘
- **semgrep_scan**: å…¨è¯­è¨€é™æ€åˆ†æ - **æ¯æ¬¡åˆ†æå¿…ç”¨**
  å‚æ•°: target_path (str), rules (str: "auto" æˆ– "p/security-audit")
  ç¤ºä¾‹: {"target_path": ".", "rules": "auto"}

- **bandit_scan**: Python å®‰å…¨æ‰«æ - **Pythoné¡¹ç›®å¿…ç”¨**
  å‚æ•°: target_path (str), severity (str)
  ç¤ºä¾‹: {"target_path": ".", "severity": "medium"}

- **gitleaks_scan**: å¯†é’¥æ³„éœ²æ£€æµ‹ - **æ¯æ¬¡åˆ†æå¿…ç”¨**
  å‚æ•°: target_path (str)
  ç¤ºä¾‹: {"target_path": "."}

- **safety_scan**: Python ä¾èµ–æ¼æ´ - **æœ‰ requirements.txt æ—¶å¿…ç”¨**
  å‚æ•°: requirements_file (str)
  ç¤ºä¾‹: {"requirements_file": "requirements.txt"}

- **npm_audit**: Node.js ä¾èµ–æ¼æ´ - **æœ‰ package.json æ—¶å¿…ç”¨**
  å‚æ•°: target_path (str)
  ç¤ºä¾‹: {"target_path": "."}

- **kunlun_scan**: æ·±åº¦ä»£ç å®¡è®¡ï¼ˆKunlun-Mï¼‰
  å‚æ•°: target_path (str), language (str: "php"|"javascript")
  ç¤ºä¾‹: {"target_path": ".", "language": "php"}

### ç¬¬äºŒä¼˜å…ˆçº§ï¼šæ™ºèƒ½æ‰«æå·¥å…· â­â­
- **smart_scan**: æ™ºèƒ½æ‰¹é‡å®‰å…¨æ‰«æ
  å‚æ•°: target (str), quick_mode (bool), focus_vulnerabilities (list)
  ç¤ºä¾‹: {"target": ".", "quick_mode": true}

- **quick_audit**: å¿«é€Ÿæ–‡ä»¶å®¡è®¡
  å‚æ•°: file_path (str), deep_analysis (bool)
  ç¤ºä¾‹: {"file_path": "app/views.py", "deep_analysis": true}

### ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼šå†…ç½®åˆ†æå·¥å…· â­
- **pattern_match**: å±é™©æ¨¡å¼åŒ¹é…ï¼ˆå¤–éƒ¨å·¥å…·ä¸å¯ç”¨æ—¶çš„å¤‡é€‰ï¼‰
  å‚æ•°: scan_file (str) æˆ– code (str), pattern_types (list)
  ç¤ºä¾‹: {"scan_file": "app/models.py", "pattern_types": ["sql_injection"]}

- **dataflow_analysis**: æ•°æ®æµè¿½è¸ª
  å‚æ•°: source_code (str), variable_name (str)

### è¾…åŠ©å·¥å…·ï¼ˆRAG ä¼˜å…ˆï¼ï¼‰
- **rag_query**: **ğŸ”¥ é¦–é€‰** è¯­ä¹‰æœç´¢ä»£ç ï¼Œç†è§£ä¸šåŠ¡é€»è¾‘
  å‚æ•°: query (str), top_k (int)
- **security_search**: **ğŸ”¥ é¦–é€‰** å®‰å…¨ç›¸å…³æœç´¢
  å‚æ•°: query (str)
- **read_file**: è¯»å–æ–‡ä»¶å†…å®¹
  å‚æ•°: file_path (str), start_line (int), end_line (int)
- **list_files**: âš ï¸ ä»…åˆ—å‡ºç›®å½•ï¼Œä¸¥ç¦éå†
- **search_code**: âš ï¸ ä»…æŸ¥æ‰¾å¸¸é‡ï¼Œä¸¥ç¦é€šç”¨æœç´¢

## ğŸ“‹ æ¨èåˆ†ææµç¨‹ï¼ˆä¸¥æ ¼æŒ‰æ­¤æ‰§è¡Œï¼ï¼‰

### ç¬¬ä¸€æ­¥ï¼šå¤–éƒ¨å·¥å…·å…¨é¢æ‰«æï¼ˆ60%æ—¶é—´ï¼‰âš¡ æœ€é‡è¦ï¼
æ ¹æ®é¡¹ç›®æŠ€æœ¯æ ˆï¼Œ**å¿…é¡»é¦–å…ˆ**æ‰§è¡Œä»¥ä¸‹å¤–éƒ¨å·¥å…·ï¼š

```
# æ‰€æœ‰é¡¹ç›®å¿…åš
Action: semgrep_scan
Action Input: {"target_path": ".", "rules": "auto"}

Action: gitleaks_scan
Action Input: {"target_path": "."}

# Python é¡¹ç›®å¿…åš
Action: bandit_scan
Action Input: {"target_path": ".", "severity": "medium"}

Action: safety_scan
Action Input: {"requirements_file": "requirements.txt"}

# Node.js é¡¹ç›®å¿…åš
Action: npm_audit
Action Input: {"target_path": "."}
```

### ç¬¬äºŒæ­¥ï¼šåˆ†æå¤–éƒ¨å·¥å…·ç»“æœï¼ˆ25%æ—¶é—´ï¼‰
å¯¹å¤–éƒ¨å·¥å…·å‘ç°çš„é—®é¢˜è¿›è¡Œæ·±å…¥åˆ†æï¼š
- ä½¿ç”¨ `read_file` æŸ¥çœ‹å®Œæ•´ä»£ç ä¸Šä¸‹æ–‡
- ä½¿ç”¨ `dataflow_analysis` è¿½è¸ªæ•°æ®æµ
- éªŒè¯æ˜¯å¦ä¸ºçœŸå®æ¼æ´ï¼Œæ’é™¤è¯¯æŠ¥

### ç¬¬ä¸‰æ­¥ï¼šè¡¥å……æ‰«æï¼ˆ10%æ—¶é—´ï¼‰
å¦‚æœå¤–éƒ¨å·¥å…·è¦†ç›–ä¸è¶³ï¼Œä½¿ç”¨å†…ç½®å·¥å…·è¡¥å……ï¼š
- `smart_scan` ç»¼åˆæ‰«æ
- `pattern_match` æ¨¡å¼åŒ¹é…

### ç¬¬å››æ­¥ï¼šæ±‡æ€»æŠ¥å‘Šï¼ˆ5%æ—¶é—´ï¼‰
æ•´ç†æ‰€æœ‰å‘ç°ï¼Œè¾“å‡º Final Answer

## âš ï¸ é‡è¦æé†’
1. **ä¸è¦è·³è¿‡å¤–éƒ¨å·¥å…·ï¼** å³ä½¿å†…ç½®å·¥å…·å¯èƒ½æ›´å¿«ï¼Œå¤–éƒ¨å·¥å…·çš„æ£€æµ‹èƒ½åŠ›æ›´å¼º
2. **Dockerä¾èµ–**ï¼šå¤–éƒ¨å·¥å…·éœ€è¦Dockerç¯å¢ƒï¼Œå¦‚æœè¿”å›"Dockerä¸å¯ç”¨"ï¼Œå†ä½¿ç”¨å†…ç½®å·¥å…·
3. **å¹¶è¡Œæ‰§è¡Œ**ï¼šå¯ä»¥è¿ç»­è°ƒç”¨å¤šä¸ªå¤–éƒ¨å·¥å…·

## å·¥ä½œæ–¹å¼
æ¯ä¸€æ­¥ï¼Œä½ éœ€è¦è¾“å‡ºï¼š

```
Thought: [åˆ†æå½“å‰æƒ…å†µï¼Œæ€è€ƒä¸‹ä¸€æ­¥åº”è¯¥åšä»€ä¹ˆ]
Action: [å·¥å…·åç§°]
Action Input: [JSON æ ¼å¼çš„å‚æ•°]
```

å½“ä½ å®Œæˆåˆ†æåï¼Œè¾“å‡ºï¼š

```
Thought: [æ€»ç»“æ‰€æœ‰å‘ç°]
Final Answer: [JSON æ ¼å¼çš„æ¼æ´æŠ¥å‘Š]
```

## Final Answer æ ¼å¼
```json
{
    "findings": [
        {
            "vulnerability_type": "sql_injection",
            "severity": "high",
            "title": "SQL æ³¨å…¥æ¼æ´",
            "description": "è¯¦ç»†æè¿°",
            "file_path": "path/to/file.py",
            "line_start": 42,
            "code_snippet": "å±é™©ä»£ç ç‰‡æ®µ",
            "source": "æ±¡ç‚¹æ¥æº",
            "sink": "å±é™©å‡½æ•°",
            "suggestion": "ä¿®å¤å»ºè®®",
            "confidence": 0.9,
            "needs_verification": true
        }
    ],
    "summary": "åˆ†ææ€»ç»“"
}
```

## é‡ç‚¹å…³æ³¨çš„æ¼æ´ç±»å‹
- SQL æ³¨å…¥ (query, execute, raw SQL)
- XSS (innerHTML, document.write, v-html)
- å‘½ä»¤æ³¨å…¥ (exec, system, subprocess)
- è·¯å¾„éå† (open, readFile, path æ‹¼æ¥)
- SSRF (requests, fetch, http client)
- ç¡¬ç¼–ç å¯†é’¥ (password, secret, api_key)
- ä¸å®‰å…¨çš„ååºåˆ—åŒ– (pickle, yaml.load, eval)

## é‡è¦åŸåˆ™
1. **å¤–éƒ¨å·¥å…·ä¼˜å…ˆ** - é¦–å…ˆä½¿ç”¨ semgrepã€bandit ç­‰ä¸“ä¸šå·¥å…·
2. **è´¨é‡ä¼˜å…ˆ** - å®å¯æ·±å…¥åˆ†æå‡ ä¸ªçœŸå®æ¼æ´ï¼Œä¸è¦æµ…å°è¾„æ­¢æŠ¥å‘Šå¤§é‡è¯¯æŠ¥
3. **ä¸Šä¸‹æ–‡åˆ†æ** - çœ‹åˆ°å¯ç–‘ä»£ç è¦è¯»å–ä¸Šä¸‹æ–‡ï¼Œç†è§£å®Œæ•´é€»è¾‘
4. **è‡ªä¸»åˆ¤æ–­** - ä¸è¦æœºæ¢°ç›¸ä¿¡å·¥å…·è¾“å‡ºï¼Œè¦ç”¨ä½ çš„ä¸“ä¸šçŸ¥è¯†åˆ¤æ–­

## âš ï¸ å…³é”®çº¦æŸ - å¿…é¡»éµå®ˆï¼
1. **ç¦æ­¢ç›´æ¥è¾“å‡º Final Answer** - ä½ å¿…é¡»å…ˆè°ƒç”¨å·¥å…·æ¥åˆ†æä»£ç 
2. **è‡³å°‘è°ƒç”¨ä¸¤ä¸ªå·¥å…·** - ä½¿ç”¨ smart_scan/semgrep_scan è¿›è¡Œæ‰«æï¼Œç„¶åç”¨ read_file æŸ¥çœ‹ä»£ç 
3. **æ²¡æœ‰å·¥å…·è°ƒç”¨çš„åˆ†ææ— æ•ˆ** - ä¸å…è®¸ä»…å‡­æ¨æµ‹ç›´æ¥æŠ¥å‘Šæ¼æ´
4. **å…ˆ Action å Final Answer** - å¿…é¡»å…ˆæ‰§è¡Œå·¥å…·ï¼Œè·å– Observationï¼Œå†è¾“å‡ºæœ€ç»ˆç»“è®º

é”™è¯¯ç¤ºä¾‹ï¼ˆç¦æ­¢ï¼‰ï¼š
```
Thought: æ ¹æ®é¡¹ç›®ä¿¡æ¯ï¼Œå¯èƒ½å­˜åœ¨å®‰å…¨é—®é¢˜
Final Answer: {...}  âŒ æ²¡æœ‰è°ƒç”¨ä»»ä½•å·¥å…·ï¼
```

æ­£ç¡®ç¤ºä¾‹ï¼ˆå¿…é¡»ï¼‰ï¼š
```
Thought: æˆ‘éœ€è¦å…ˆä½¿ç”¨æ™ºèƒ½æ‰«æå·¥å…·å¯¹é¡¹ç›®è¿›è¡Œå…¨é¢åˆ†æ
Action: smart_scan
Action Input: {"scan_type": "security", "max_files": 50}
```
ç„¶åç­‰å¾… Observationï¼Œå†ç»§ç»­æ·±å…¥åˆ†ææˆ–è¾“å‡º Final Answerã€‚

ç°åœ¨å¼€å§‹ä½ çš„å®‰å…¨åˆ†æï¼é¦–å…ˆä½¿ç”¨å¤–éƒ¨å·¥å…·è¿›è¡Œå…¨é¢æ‰«æã€‚"""


@dataclass
class AnalysisStep:
    """åˆ†ææ­¥éª¤"""
    thought: str
    action: Optional[str] = None
    action_input: Optional[Dict] = None
    observation: Optional[str] = None
    is_final: bool = False
    final_answer: Optional[Dict] = None


class AnalysisAgent(BaseAgent):
    """
    æ¼æ´åˆ†æ Agent - LLM é©±åŠ¨ç‰ˆ
    
    LLM å…¨ç¨‹å‚ä¸ï¼Œè‡ªä¸»å†³å®šï¼š
    1. åˆ†æä»€ä¹ˆ
    2. ä½¿ç”¨ä»€ä¹ˆå·¥å…·
    3. æ·±å…¥å“ªäº›ä»£ç 
    4. æŠ¥å‘Šä»€ä¹ˆå‘ç°
    """
    
    def __init__(
        self,
        llm_service,
        tools: Dict[str, Any],
        event_emitter=None,
    ):
        # ç»„åˆå¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯ï¼Œæ³¨å…¥æ ¸å¿ƒå®‰å…¨åŸåˆ™å’Œæ¼æ´ä¼˜å…ˆçº§
        full_system_prompt = f"{ANALYSIS_SYSTEM_PROMPT}\n\n{CORE_SECURITY_PRINCIPLES}\n\n{VULNERABILITY_PRIORITIES}"
        
        config = AgentConfig(
            name="Analysis",
            agent_type=AgentType.ANALYSIS,
            pattern=AgentPattern.REACT,
            max_iterations=30,
            system_prompt=full_system_prompt,
        )
        super().__init__(config, llm_service, tools, event_emitter)
        
        self._conversation_history: List[Dict[str, str]] = []
        self._steps: List[AnalysisStep] = []
    

    
    def _parse_llm_response(self, response: str) -> AnalysisStep:
        """è§£æ LLM å“åº” - å¢å¼ºç‰ˆï¼Œæ›´å¥å£®åœ°æå–æ€è€ƒå†…å®¹"""
        step = AnalysisStep(thought="")

        # ğŸ”¥ é¦–å…ˆå°è¯•æå–æ˜ç¡®çš„ Thought æ ‡è®°
        thought_match = re.search(r'Thought:\s*(.*?)(?=Action:|Final Answer:|$)', response, re.DOTALL)
        if thought_match:
            step.thought = thought_match.group(1).strip()

        # ğŸ”¥ æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ç»ˆç­”æ¡ˆ
        final_match = re.search(r'Final Answer:\s*(.*?)$', response, re.DOTALL)
        if final_match:
            step.is_final = True
            answer_text = final_match.group(1).strip()
            answer_text = re.sub(r'```json\s*', '', answer_text)
            answer_text = re.sub(r'```\s*', '', answer_text)
            # ä½¿ç”¨å¢å¼ºçš„ JSON è§£æå™¨
            step.final_answer = AgentJsonParser.parse(
                answer_text,
                default={"findings": [], "raw_answer": answer_text}
            )
            # ç¡®ä¿ findings æ ¼å¼æ­£ç¡®
            if "findings" in step.final_answer:
                step.final_answer["findings"] = [
                    f for f in step.final_answer["findings"]
                    if isinstance(f, dict)
                ]

            # ğŸ”¥ å¦‚æœæ²¡æœ‰æå–åˆ° thoughtï¼Œä½¿ç”¨ Final Answer å‰çš„å†…å®¹ä½œä¸ºæ€è€ƒ
            if not step.thought:
                before_final = response[:response.find('Final Answer:')].strip()
                if before_final:
                    before_final = re.sub(r'^Thought:\s*', '', before_final)
                    step.thought = before_final[:500] if len(before_final) > 500 else before_final

            return step

        # ğŸ”¥ æå– Action
        action_match = re.search(r'Action:\s*(\w+)', response)
        if action_match:
            step.action = action_match.group(1).strip()

            # ğŸ”¥ å¦‚æœæ²¡æœ‰æå–åˆ° thoughtï¼Œæå– Action ä¹‹å‰çš„å†…å®¹ä½œä¸ºæ€è€ƒ
            if not step.thought:
                action_pos = response.find('Action:')
                if action_pos > 0:
                    before_action = response[:action_pos].strip()
                    before_action = re.sub(r'^Thought:\s*', '', before_action)
                    if before_action:
                        step.thought = before_action[:500] if len(before_action) > 500 else before_action

        # ğŸ”¥ æå– Action Input
        input_match = re.search(r'Action Input:\s*(.*?)(?=Thought:|Action:|Observation:|$)', response, re.DOTALL)
        if input_match:
            input_text = input_match.group(1).strip()
            input_text = re.sub(r'```json\s*', '', input_text)
            input_text = re.sub(r'```\s*', '', input_text)
            # ä½¿ç”¨å¢å¼ºçš„ JSON è§£æå™¨
            step.action_input = AgentJsonParser.parse(
                input_text,
                default={"raw_input": input_text}
            )

        # ğŸ”¥ æœ€åçš„ fallbackï¼šå¦‚æœæ•´ä¸ªå“åº”æ²¡æœ‰ä»»ä½•æ ‡è®°ï¼Œæ•´ä½“ä½œä¸ºæ€è€ƒ
        if not step.thought and not step.action and not step.is_final:
            if response.strip():
                step.thought = response.strip()[:500]

        return step
    

    
    async def run(self, input_data: Dict[str, Any]) -> AgentResult:
        """
        æ‰§è¡Œæ¼æ´åˆ†æ - LLM å…¨ç¨‹å‚ä¸ï¼
        """
        import time
        start_time = time.time()
        
        project_info = input_data.get("project_info", {})
        config = input_data.get("config", {})
        plan = input_data.get("plan", {})
        previous_results = input_data.get("previous_results", {})
        task = input_data.get("task", "")
        task_context = input_data.get("task_context", "")
        
        # ğŸ”¥ å¤„ç†äº¤æ¥ä¿¡æ¯
        handoff = input_data.get("handoff")
        if handoff:
            from .base import TaskHandoff
            if isinstance(handoff, dict):
                handoff = TaskHandoff.from_dict(handoff)
            self.receive_handoff(handoff)
        
        # ä» Recon ç»“æœè·å–ä¸Šä¸‹æ–‡
        recon_data = previous_results.get("recon", {})
        if isinstance(recon_data, dict) and "data" in recon_data:
            recon_data = recon_data["data"]
        
        tech_stack = recon_data.get("tech_stack", {})
        entry_points = recon_data.get("entry_points", [])
        high_risk_areas = recon_data.get("high_risk_areas", plan.get("high_risk_areas", []))
        initial_findings = recon_data.get("initial_findings", [])
        
        # ğŸ”¥ æ„å»ºåŒ…å«äº¤æ¥ä¸Šä¸‹æ–‡çš„åˆå§‹æ¶ˆæ¯
        handoff_context = self.get_handoff_context()
        
        # ğŸ”¥ è·å–ç›®æ ‡æ–‡ä»¶åˆ—è¡¨
        target_files = config.get("target_files", [])
        
        initial_message = f"""è¯·å¼€å§‹å¯¹é¡¹ç›®è¿›è¡Œå®‰å…¨æ¼æ´åˆ†æã€‚

## é¡¹ç›®ä¿¡æ¯
- åç§°: {project_info.get('name', 'unknown')}
- è¯­è¨€: {tech_stack.get('languages', [])}
- æ¡†æ¶: {tech_stack.get('frameworks', [])}

"""
        # ğŸ”¥ å¦‚æœæŒ‡å®šäº†ç›®æ ‡æ–‡ä»¶ï¼Œæ˜ç¡®å‘ŠçŸ¥ Agent
        if target_files:
            initial_message += f"""## âš ï¸ å®¡è®¡èŒƒå›´
ç”¨æˆ·æŒ‡å®šäº† {len(target_files)} ä¸ªç›®æ ‡æ–‡ä»¶è¿›è¡Œå®¡è®¡ï¼š
"""
            for tf in target_files[:10]:
                initial_message += f"- {tf}\n"
            if len(target_files) > 10:
                initial_message += f"- ... è¿˜æœ‰ {len(target_files) - 10} ä¸ªæ–‡ä»¶\n"
            initial_message += """
è¯·ç›´æ¥åˆ†æè¿™äº›æŒ‡å®šçš„æ–‡ä»¶ï¼Œä¸è¦åˆ†æå…¶ä»–æ–‡ä»¶ã€‚

"""
        
        initial_message += f"""{handoff_context if handoff_context else f'''## ä¸Šä¸‹æ–‡ä¿¡æ¯
### âš ï¸ é«˜é£é™©åŒºåŸŸï¼ˆæ¥è‡ª Recon Agentï¼Œå¿…é¡»ä¼˜å…ˆåˆ†æï¼‰
ä»¥ä¸‹æ˜¯ Recon Agent è¯†åˆ«çš„é«˜é£é™©åŒºåŸŸï¼Œè¯·**åŠ¡å¿…ä¼˜å…ˆ**è¯»å–å’Œåˆ†æè¿™äº›æ–‡ä»¶ï¼š
{json.dumps(high_risk_areas[:20], ensure_ascii=False)}

**é‡è¦**: è¯·ä½¿ç”¨ read_file å·¥å…·è¯»å–ä¸Šè¿°é«˜é£é™©æ–‡ä»¶ï¼Œä¸è¦å‡è®¾æ–‡ä»¶è·¯å¾„æˆ–ä½¿ç”¨å…¶ä»–è·¯å¾„ã€‚

### å…¥å£ç‚¹ (å‰10ä¸ª)
{json.dumps(entry_points[:10], ensure_ascii=False, indent=2)}

### åˆæ­¥å‘ç° (å¦‚æœæœ‰)
{json.dumps(initial_findings[:5], ensure_ascii=False, indent=2) if initial_findings else "æ— "}'''}

## ä»»åŠ¡
{task_context or task or 'è¿›è¡Œå…¨é¢çš„å®‰å…¨æ¼æ´åˆ†æï¼Œå‘ç°ä»£ç ä¸­çš„å®‰å…¨é—®é¢˜ã€‚'}

## âš ï¸ åˆ†æç­–ç•¥è¦æ±‚
1. **é¦–å…ˆ**ï¼šä½¿ç”¨ read_file è¯»å–ä¸Šé¢åˆ—å‡ºçš„é«˜é£é™©æ–‡ä»¶
2. **ç„¶å**ï¼šåˆ†æè¿™äº›æ–‡ä»¶ä¸­çš„å®‰å…¨é—®é¢˜
3. **æœ€å**ï¼šå¦‚æœéœ€è¦ï¼Œä½¿ç”¨ smart_scan æˆ–å…¶ä»–å·¥å…·æ‰©å±•åˆ†æ

**ç¦æ­¢**ï¼šä¸è¦è·³è¿‡é«˜é£é™©åŒºåŸŸç›´æ¥åšå…¨å±€æ‰«æ

## ç›®æ ‡æ¼æ´ç±»å‹
{config.get('target_vulnerabilities', ['all'])}

## å¯ç”¨å·¥å…·
{self.get_tools_description()}

è¯·å¼€å§‹ä½ çš„å®‰å…¨åˆ†æã€‚é¦–å…ˆè¯»å–é«˜é£é™©åŒºåŸŸçš„æ–‡ä»¶ï¼Œç„¶å**ç«‹å³**åˆ†æå…¶ä¸­çš„å®‰å…¨é—®é¢˜ï¼ˆè¾“å‡º Actionï¼‰ã€‚"""
        
        # ğŸ”¥ è®°å½•å·¥ä½œå¼€å§‹
        self.record_work("å¼€å§‹å®‰å…¨æ¼æ´åˆ†æ")

        # åˆå§‹åŒ–å¯¹è¯å†å²
        self._conversation_history = [
            {"role": "system", "content": self.config.system_prompt},
            {"role": "user", "content": initial_message},
        ]
        
        self._steps = []
        all_findings = []
        error_message = None  # ğŸ”¥ è·Ÿè¸ªé”™è¯¯ä¿¡æ¯
        
        await self.emit_thinking("ğŸ”¬ Analysis Agent å¯åŠ¨ï¼ŒLLM å¼€å§‹è‡ªä¸»å®‰å…¨åˆ†æ...")
        
        try:
            for iteration in range(self.config.max_iterations):
                if self.is_cancelled:
                    break
                
                self._iteration = iteration + 1
                
                # ğŸ”¥ å†æ¬¡æ£€æŸ¥å–æ¶ˆæ ‡å¿—ï¼ˆåœ¨LLMè°ƒç”¨ä¹‹å‰ï¼‰
                if self.is_cancelled:
                    await self.emit_thinking("ğŸ›‘ ä»»åŠ¡å·²å–æ¶ˆï¼Œåœæ­¢æ‰§è¡Œ")
                    break
                
                # è°ƒç”¨ LLM è¿›è¡Œæ€è€ƒå’Œå†³ç­–ï¼ˆæµå¼è¾“å‡ºï¼‰
                # ğŸ”¥ å¢åŠ  max_tokens åˆ° 4096ï¼Œé¿å…é•¿è¾“å‡ºè¢«æˆªæ–­
                try:
                    llm_output, tokens_this_round = await self.stream_llm_call(
                        self._conversation_history,
                        temperature=0.1,
                        max_tokens=8192,
                    )
                except asyncio.CancelledError:
                    logger.info(f"[{self.name}] LLM call cancelled")
                    break
                
                self._total_tokens += tokens_this_round

                # ğŸ”¥ Enhanced: Handle empty LLM response with better diagnostics
                if not llm_output or not llm_output.strip():
                    empty_retry_count = getattr(self, '_empty_retry_count', 0) + 1
                    self._empty_retry_count = empty_retry_count
                    
                    # ğŸ”¥ è®°å½•æ›´è¯¦ç»†çš„è¯Šæ–­ä¿¡æ¯
                    logger.warning(
                        f"[{self.name}] Empty LLM response in iteration {self._iteration} "
                        f"(retry {empty_retry_count}/3, tokens_this_round={tokens_this_round})"
                    )
                    
                    if empty_retry_count >= 3:
                        logger.error(f"[{self.name}] Too many empty responses, generating fallback result")
                        error_message = "è¿ç»­æ”¶åˆ°ç©ºå“åº”ï¼Œä½¿ç”¨å›é€€ç»“æœ"
                        await self.emit_event("warning", error_message)
                        # ğŸ”¥ ä¸æ˜¯ç›´æ¥ breakï¼Œè€Œæ˜¯å°è¯•ç”Ÿæˆä¸€ä¸ªå›é€€ç»“æœ
                        break
                    
                    # ğŸ”¥ æ›´æœ‰é’ˆå¯¹æ€§çš„é‡è¯•æç¤º
                    retry_prompt = f"""æ”¶åˆ°ç©ºå“åº”ã€‚è¯·æ ¹æ®ä»¥ä¸‹æ ¼å¼è¾“å‡ºä½ çš„æ€è€ƒå’Œè¡ŒåŠ¨ï¼š

Thought: [ä½ å¯¹å½“å‰å®‰å…¨åˆ†ææƒ…å†µçš„æ€è€ƒ]
Action: [å·¥å…·åç§°ï¼Œå¦‚ read_file, search_code, pattern_match, semgrep_scan]
Action Input: {{"å‚æ•°å": "å‚æ•°å€¼"}}

å¯ç”¨å·¥å…·: {', '.join(self.tools.keys())}

å¦‚æœä½ å·²å®Œæˆåˆ†æï¼Œè¯·è¾“å‡ºï¼š
Thought: [æ€»ç»“æ‰€æœ‰å‘ç°]
Final Answer: {{"findings": [...], "summary": "..."}}"""
                    
                    self._conversation_history.append({
                        "role": "user",
                        "content": retry_prompt,
                    })
                    continue
                
                # é‡ç½®ç©ºå“åº”è®¡æ•°å™¨
                self._empty_retry_count = 0

                # è§£æ LLM å“åº”
                step = self._parse_llm_response(llm_output)
                self._steps.append(step)
                
                # ğŸ”¥ å‘å°„ LLM æ€è€ƒå†…å®¹äº‹ä»¶ - å±•ç¤ºå®‰å…¨åˆ†æçš„æ€è€ƒè¿‡ç¨‹
                if step.thought:
                    await self.emit_llm_thought(step.thought, iteration + 1)
                
                # æ·»åŠ  LLM å“åº”åˆ°å†å²
                self._conversation_history.append({
                    "role": "assistant",
                    "content": llm_output,
                })
                
                # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                if step.is_final:
                    await self.emit_llm_decision("å®Œæˆå®‰å…¨åˆ†æ", "LLM åˆ¤æ–­åˆ†æå·²å……åˆ†")
                    logger.info(f"[{self.name}] Received Final Answer: {step.final_answer}")
                    if step.final_answer and "findings" in step.final_answer:
                        all_findings = step.final_answer["findings"]
                        logger.info(f"[{self.name}] Final Answer contains {len(all_findings)} findings")
                        # ğŸ”¥ å‘å°„æ¯ä¸ªå‘ç°çš„äº‹ä»¶
                        for finding in all_findings[:5]:  # é™åˆ¶æ•°é‡
                            await self.emit_finding(
                                finding.get("title", "Unknown"),
                                finding.get("severity", "medium"),
                                finding.get("vulnerability_type", "other"),
                                finding.get("file_path", "")
                            )
                            # ğŸ”¥ è®°å½•æ´å¯Ÿ
                            self.add_insight(
                                f"å‘ç° {finding.get('severity', 'medium')} çº§åˆ«æ¼æ´: {finding.get('title', 'Unknown')}"
                            )
                    else:
                        logger.warning(f"[{self.name}] Final Answer has no 'findings' key or is None: {step.final_answer}")
                    
                    # ğŸ”¥ è®°å½•å·¥ä½œå®Œæˆ
                    self.record_work(f"å®Œæˆå®‰å…¨åˆ†æï¼Œå‘ç° {len(all_findings)} ä¸ªæ½œåœ¨æ¼æ´")
                    
                    await self.emit_llm_complete(
                        f"åˆ†æå®Œæˆï¼Œå‘ç° {len(all_findings)} ä¸ªæ½œåœ¨æ¼æ´",
                        self._total_tokens
                    )
                    break
                
                # æ‰§è¡Œå·¥å…·
                if step.action:
                    # ğŸ”¥ å‘å°„ LLM åŠ¨ä½œå†³ç­–äº‹ä»¶
                    await self.emit_llm_action(step.action, step.action_input or {})
                    
                    # ğŸ”¥ å¾ªç¯æ£€æµ‹ï¼šè¿½è¸ªå·¥å…·è°ƒç”¨å¤±è´¥å†å²
                    tool_call_key = f"{step.action}:{json.dumps(step.action_input or {}, sort_keys=True)}"
                    if not hasattr(self, '_failed_tool_calls'):
                        self._failed_tool_calls = {}
                    
                    observation = await self.execute_tool(
                        step.action,
                        step.action_input or {}
                    )
                    
                    # ğŸ”¥ æ£€æµ‹å·¥å…·è°ƒç”¨å¤±è´¥å¹¶è¿½è¸ª
                    is_tool_error = (
                        "å¤±è´¥" in observation or 
                        "é”™è¯¯" in observation or 
                        "ä¸å­˜åœ¨" in observation or
                        "æ–‡ä»¶è¿‡å¤§" in observation or
                        "Error" in observation
                    )
                    
                    if is_tool_error:
                        self._failed_tool_calls[tool_call_key] = self._failed_tool_calls.get(tool_call_key, 0) + 1
                        fail_count = self._failed_tool_calls[tool_call_key]
                        
                        # ğŸ”¥ å¦‚æœåŒä¸€è°ƒç”¨è¿ç»­å¤±è´¥3æ¬¡ï¼Œæ·»åŠ å¼ºåˆ¶è·³è¿‡æç¤º
                        if fail_count >= 3:
                            logger.warning(f"[{self.name}] Tool call failed {fail_count} times: {tool_call_key}")
                            observation += f"\n\nâš ï¸ **ç³»ç»Ÿæç¤º**: æ­¤å·¥å…·è°ƒç”¨å·²è¿ç»­å¤±è´¥ {fail_count} æ¬¡ã€‚è¯·ï¼š\n"
                            observation += "1. å°è¯•ä½¿ç”¨ä¸åŒçš„å‚æ•°ï¼ˆå¦‚æŒ‡å®šè¾ƒå°çš„è¡ŒèŒƒå›´ï¼‰\n"
                            observation += "2. ä½¿ç”¨ search_code å·¥å…·å®šä½å…³é”®ä»£ç ç‰‡æ®µ\n"
                            observation += "3. è·³è¿‡æ­¤æ–‡ä»¶ï¼Œç»§ç»­åˆ†æå…¶ä»–æ–‡ä»¶\n"
                            observation += "4. å¦‚æœå·²æœ‰è¶³å¤Ÿå‘ç°ï¼Œç›´æ¥è¾“å‡º Final Answer"
                            
                            # é‡ç½®è®¡æ•°å™¨ä½†ä¿ç•™è®°å½•
                            self._failed_tool_calls[tool_call_key] = 0
                    else:
                        # æˆåŠŸè°ƒç”¨ï¼Œé‡ç½®å¤±è´¥è®¡æ•°
                        if tool_call_key in self._failed_tool_calls:
                            del self._failed_tool_calls[tool_call_key]
                    
                    # ğŸ”¥ å·¥å…·æ‰§è¡Œåæ£€æŸ¥å–æ¶ˆçŠ¶æ€
                    if self.is_cancelled:
                        logger.info(f"[{self.name}] Cancelled after tool execution")
                        break
                    
                    step.observation = observation
                    
                    # ğŸ”¥ å‘å°„ LLM è§‚å¯Ÿäº‹ä»¶
                    await self.emit_llm_observation(observation)
                    
                    # æ·»åŠ è§‚å¯Ÿç»“æœåˆ°å†å²
                    self._conversation_history.append({
                        "role": "user",
                        "content": f"Observation:\n{observation}",
                    })
                else:
                    # LLM æ²¡æœ‰é€‰æ‹©å·¥å…·ï¼Œæç¤ºå®ƒç»§ç»­
                    await self.emit_llm_decision("ç»§ç»­åˆ†æ", "LLM éœ€è¦æ›´å¤šåˆ†æ")
                    self._conversation_history.append({
                        "role": "user",
                        "content": "è¯·ç»§ç»­åˆ†æã€‚ä½ è¾“å‡ºäº† Thought ä½†æ²¡æœ‰è¾“å‡º Actionã€‚è¯·**ç«‹å³**é€‰æ‹©ä¸€ä¸ªå·¥å…·æ‰§è¡Œï¼Œæˆ–è€…å¦‚æœåˆ†æå®Œæˆï¼Œè¾“å‡º Final Answer æ±‡æ€»æ‰€æœ‰å‘ç°ã€‚",
                    })
            
            # ğŸ”¥ å¦‚æœå¾ªç¯ç»“æŸä½†æ²¡æœ‰å‘ç°ï¼Œå¼ºåˆ¶ LLM æ€»ç»“
            if not all_findings and not self.is_cancelled and not error_message:
                await self.emit_thinking("ğŸ“ åˆ†æé˜¶æ®µç»“æŸï¼Œæ­£åœ¨ç”Ÿæˆæ¼æ´æ€»ç»“...")
                
                # æ·»åŠ å¼ºåˆ¶æ€»ç»“çš„æç¤º
                self._conversation_history.append({
                    "role": "user",
                    "content": """åˆ†æé˜¶æ®µå·²ç»“æŸã€‚è¯·ç«‹å³è¾“å‡º Final Answerï¼Œæ€»ç»“ä½ å‘ç°çš„æ‰€æœ‰å®‰å…¨é—®é¢˜ã€‚

å³ä½¿æ²¡æœ‰å‘ç°ä¸¥é‡æ¼æ´ï¼Œä¹Ÿè¯·æ€»ç»“ä½ çš„åˆ†æè¿‡ç¨‹å’Œè§‚å¯Ÿåˆ°çš„æ½œåœ¨é£é™©ç‚¹ã€‚

è¯·æŒ‰ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼š
```json
{
    "findings": [
        {
            "vulnerability_type": "sql_injection|xss|command_injection|path_traversal|ssrf|hardcoded_secret|other",
            "severity": "critical|high|medium|low",
            "title": "æ¼æ´æ ‡é¢˜",
            "description": "è¯¦ç»†æè¿°",
            "file_path": "æ–‡ä»¶è·¯å¾„",
            "line_start": è¡Œå·,
            "code_snippet": "ç›¸å…³ä»£ç ç‰‡æ®µ",
            "suggestion": "ä¿®å¤å»ºè®®"
        }
    ],
    "summary": "åˆ†ææ€»ç»“"
}
```

Final Answer:""",
                })
                
                try:
                    summary_output, _ = await self.stream_llm_call(
                        self._conversation_history,
                        temperature=0.1,
                        max_tokens=4096,
                    )
                    
                    if summary_output and summary_output.strip():
                        # è§£ææ€»ç»“è¾“å‡º
                        import re
                        summary_text = summary_output.strip()
                        summary_text = re.sub(r'```json\s*', '', summary_text)
                        summary_text = re.sub(r'```\s*', '', summary_text)
                        parsed_result = AgentJsonParser.parse(
                            summary_text,
                            default={"findings": [], "summary": ""}
                        )
                        if "findings" in parsed_result:
                            all_findings = parsed_result["findings"]
                except Exception as e:
                    logger.warning(f"[{self.name}] Failed to generate summary: {e}")
            
            # å¤„ç†ç»“æœ
            duration_ms = int((time.time() - start_time) * 1000)
            
            # ğŸ”¥ å¦‚æœè¢«å–æ¶ˆï¼Œè¿”å›å–æ¶ˆç»“æœ
            if self.is_cancelled:
                await self.emit_event(
                    "info",
                    f"ğŸ›‘ Analysis Agent å·²å–æ¶ˆ: {len(all_findings)} ä¸ªå‘ç°, {self._iteration} è½®è¿­ä»£"
                )
                return AgentResult(
                    success=False,
                    error="ä»»åŠ¡å·²å–æ¶ˆ",
                    data={"findings": all_findings},
                    iterations=self._iteration,
                    tool_calls=self._tool_calls,
                    tokens_used=self._total_tokens,
                    duration_ms=duration_ms,
                )
            
            # ğŸ”¥ å¦‚æœæœ‰é”™è¯¯ï¼Œè¿”å›å¤±è´¥ç»“æœ
            if error_message:
                await self.emit_event(
                    "error",
                    f"âŒ Analysis Agent å¤±è´¥: {error_message}"
                )
                return AgentResult(
                    success=False,
                    error=error_message,
                    data={"findings": all_findings},
                    iterations=self._iteration,
                    tool_calls=self._tool_calls,
                    tokens_used=self._total_tokens,
                    duration_ms=duration_ms,
                )
            
            # æ ‡å‡†åŒ–å‘ç°
            logger.info(f"[{self.name}] Standardizing {len(all_findings)} findings")
            standardized_findings = []
            for finding in all_findings:
                # ç¡®ä¿ finding æ˜¯å­—å…¸
                if not isinstance(finding, dict):
                    logger.warning(f"Skipping invalid finding (not a dict): {finding}")
                    continue
                    
                standardized = {
                    "vulnerability_type": finding.get("vulnerability_type", "other"),
                    "severity": finding.get("severity", "medium"),
                    "title": finding.get("title", "Unknown Finding"),
                    "description": finding.get("description", ""),
                    "file_path": finding.get("file_path", ""),
                    "line_start": finding.get("line_start") or finding.get("line", 0),
                    "code_snippet": finding.get("code_snippet", ""),
                    "source": finding.get("source", ""),
                    "sink": finding.get("sink", ""),
                    "suggestion": finding.get("suggestion", ""),
                    "confidence": finding.get("confidence", 0.7),
                    "needs_verification": finding.get("needs_verification", True),
                }
                standardized_findings.append(standardized)
            
            await self.emit_event(
                "info",
                f"Analysis Agent å®Œæˆ: {len(standardized_findings)} ä¸ªå‘ç°, {self._iteration} è½®è¿­ä»£, {self._tool_calls} æ¬¡å·¥å…·è°ƒç”¨"
            )

            # ğŸ”¥ CRITICAL: Log final findings count before returning
            logger.info(f"[{self.name}] Returning {len(standardized_findings)} standardized findings")

            return AgentResult(
                success=True,
                data={
                    "findings": standardized_findings,
                    "steps": [
                        {
                            "thought": s.thought,
                            "action": s.action,
                            "action_input": s.action_input,
                            "observation": s.observation[:500] if s.observation else None,
                        }
                        for s in self._steps
                    ],
                },
                iterations=self._iteration,
                tool_calls=self._tool_calls,
                tokens_used=self._total_tokens,
                duration_ms=duration_ms,
            )
            
        except Exception as e:
            logger.error(f"Analysis Agent failed: {e}", exc_info=True)
            return AgentResult(success=False, error=str(e))
    
    def get_conversation_history(self) -> List[Dict[str, str]]:
        """è·å–å¯¹è¯å†å²"""
        return self._conversation_history
    
    def get_steps(self) -> List[AnalysisStep]:
        """è·å–æ‰§è¡Œæ­¥éª¤"""
        return self._steps
