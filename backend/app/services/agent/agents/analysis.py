"""
Analysis Agent (æ¼æ´åˆ†æå±‚)
è´Ÿè´£ä»£ç å®¡è®¡ã€RAG æŸ¥è¯¢ã€æ¨¡å¼åŒ¹é…ã€æ•°æ®æµåˆ†æ

ç±»å‹: ReAct
"""

import asyncio
import logging
from typing import List, Dict, Any, Optional

from .base import BaseAgent, AgentConfig, AgentResult, AgentType, AgentPattern

logger = logging.getLogger(__name__)


ANALYSIS_SYSTEM_PROMPT = """ä½ æ˜¯ DeepAudit çš„æ¼æ´åˆ†æ Agentï¼Œè´Ÿè´£æ·±åº¦ä»£ç å®‰å…¨åˆ†æã€‚

## ä½ çš„èŒè´£
1. ä½¿ç”¨é™æ€åˆ†æå·¥å…·å¿«é€Ÿæ‰«æ
2. ä½¿ç”¨ RAG è¿›è¡Œè¯­ä¹‰ä»£ç æœç´¢
3. è¿½è¸ªæ•°æ®æµï¼ˆä»ç”¨æˆ·è¾“å…¥åˆ°å±é™©å‡½æ•°ï¼‰
4. åˆ†æä¸šåŠ¡é€»è¾‘æ¼æ´
5. è¯„ä¼°æ¼æ´ä¸¥é‡ç¨‹åº¦

## ä½ å¯ä»¥ä½¿ç”¨çš„å·¥å…·
### å¤–éƒ¨æ‰«æå·¥å…·
- semgrep_scan: Semgrep é™æ€åˆ†æï¼ˆæ¨èé¦–å…ˆä½¿ç”¨ï¼‰
- bandit_scan: Python å®‰å…¨æ‰«æ

### RAG è¯­ä¹‰æœç´¢
- rag_query: è¯­ä¹‰ä»£ç æœç´¢
- security_search: å®‰å…¨ç›¸å…³ä»£ç æœç´¢
- function_context: å‡½æ•°ä¸Šä¸‹æ–‡åˆ†æ

### æ·±åº¦åˆ†æ
- pattern_match: å±é™©æ¨¡å¼åŒ¹é…
- code_analysis: LLM æ·±åº¦ä»£ç åˆ†æ
- dataflow_analysis: æ•°æ®æµè¿½è¸ª
- vulnerability_validation: æ¼æ´éªŒè¯

### æ–‡ä»¶æ“ä½œ
- read_file: è¯»å–æ–‡ä»¶
- search_code: å…³é”®å­—æœç´¢

## åˆ†æç­–ç•¥
1. **å¿«é€Ÿæ‰«æ**: å…ˆç”¨ Semgrep å¿«é€Ÿå‘ç°é—®é¢˜
2. **è¯­ä¹‰æœç´¢**: ç”¨ RAG æ‰¾åˆ°ç›¸å…³ä»£ç 
3. **æ·±åº¦åˆ†æ**: å¯¹å¯ç–‘ä»£ç è¿›è¡Œ LLM åˆ†æ
4. **æ•°æ®æµè¿½è¸ª**: è¿½è¸ªç”¨æˆ·è¾“å…¥çš„æµå‘

## é‡ç‚¹å…³æ³¨
- SQL æ³¨å…¥ã€NoSQL æ³¨å…¥
- XSSï¼ˆåå°„å‹ã€å­˜å‚¨å‹ã€DOMå‹ï¼‰
- å‘½ä»¤æ³¨å…¥ã€ä»£ç æ³¨å…¥
- è·¯å¾„éå†ã€ä»»æ„æ–‡ä»¶è®¿é—®
- SSRFã€XXE
- ä¸å®‰å…¨çš„ååºåˆ—åŒ–
- è®¤è¯/æˆæƒç»•è¿‡
- æ•æ„Ÿä¿¡æ¯æ³„éœ²

## è¾“å‡ºæ ¼å¼
å‘ç°æ¼æ´æ—¶ï¼Œè¿”å›ç»“æ„åŒ–ä¿¡æ¯ï¼š
```json
{
    "findings": [
        {
            "vulnerability_type": "æ¼æ´ç±»å‹",
            "severity": "critical/high/medium/low",
            "title": "æ¼æ´æ ‡é¢˜",
            "description": "è¯¦ç»†æè¿°",
            "file_path": "æ–‡ä»¶è·¯å¾„",
            "line_start": è¡Œå·,
            "code_snippet": "ä»£ç ç‰‡æ®µ",
            "source": "æ±¡ç‚¹æº",
            "sink": "å±é™©å‡½æ•°",
            "suggestion": "ä¿®å¤å»ºè®®",
            "needs_verification": true/false
        }
    ]
}
```

è¯·ç³»ç»Ÿæ€§åœ°åˆ†æä»£ç ï¼Œå‘ç°çœŸå®çš„å®‰å…¨æ¼æ´ã€‚"""


class AnalysisAgent(BaseAgent):
    """
    æ¼æ´åˆ†æ Agent
    
    ä½¿ç”¨ ReAct æ¨¡å¼è¿›è¡Œè¿­ä»£åˆ†æ
    """
    
    def __init__(
        self,
        llm_service,
        tools: Dict[str, Any],
        event_emitter=None,
    ):
        config = AgentConfig(
            name="Analysis",
            agent_type=AgentType.ANALYSIS,
            pattern=AgentPattern.REACT,
            max_iterations=30,
            system_prompt=ANALYSIS_SYSTEM_PROMPT,
            tools=[
                "semgrep_scan", "bandit_scan",
                "rag_query", "security_search", "function_context",
                "pattern_match", "code_analysis", "dataflow_analysis",
                "vulnerability_validation",
                "read_file", "search_code",
            ],
        )
        super().__init__(config, llm_service, tools, event_emitter)
    
    async def run(self, input_data: Dict[str, Any]) -> AgentResult:
        """æ‰§è¡Œæ¼æ´åˆ†æ"""
        import time
        start_time = time.time()
        
        phase_name = input_data.get("phase_name", "analysis")
        project_info = input_data.get("project_info", {})
        config = input_data.get("config", {})
        plan = input_data.get("plan", {})
        previous_results = input_data.get("previous_results", {})
        
        # ä»ä¹‹å‰çš„ Recon ç»“æœè·å–ä¿¡æ¯
        recon_data = previous_results.get("recon", {}).get("data", {})
        high_risk_areas = recon_data.get("high_risk_areas", plan.get("high_risk_areas", []))
        tech_stack = recon_data.get("tech_stack", {})
        entry_points = recon_data.get("entry_points", [])
        
        try:
            all_findings = []
            
            # 1. é™æ€åˆ†æé˜¶æ®µ
            if phase_name in ["static_analysis", "analysis"]:
                await self.emit_thinking("æ‰§è¡Œé™æ€ä»£ç åˆ†æ...")
                static_findings = await self._run_static_analysis(tech_stack)
                all_findings.extend(static_findings)
            
            # 2. æ·±åº¦åˆ†æé˜¶æ®µ
            if phase_name in ["deep_analysis", "analysis"]:
                await self.emit_thinking("æ‰§è¡Œæ·±åº¦æ¼æ´åˆ†æ...")
                
                # åˆ†æå…¥å£ç‚¹
                deep_findings = await self._analyze_entry_points(entry_points)
                all_findings.extend(deep_findings)
                
                # åˆ†æé«˜é£é™©åŒºåŸŸï¼ˆç°åœ¨ä¼šè°ƒç”¨ LLMï¼‰
                risk_findings = await self._analyze_high_risk_areas(high_risk_areas)
                all_findings.extend(risk_findings)
                
                # è¯­ä¹‰æœç´¢å¸¸è§æ¼æ´ï¼ˆç°åœ¨ä¼šè°ƒç”¨ LLMï¼‰
                vuln_types = config.get("target_vulnerabilities", [
                    "sql_injection", "xss", "command_injection",
                    "path_traversal", "ssrf", "hardcoded_secret",
                ])
                
                for vuln_type in vuln_types[:5]:  # é™åˆ¶æ•°é‡
                    if self.is_cancelled:
                        break
                    
                    await self.emit_thinking(f"æœç´¢ {vuln_type} ç›¸å…³ä»£ç ...")
                    vuln_findings = await self._search_vulnerability_pattern(vuln_type)
                    all_findings.extend(vuln_findings)
                
                # ğŸ”¥ 3. å¦‚æœè¿˜æ²¡æœ‰å‘ç°ï¼Œä½¿ç”¨ LLM è¿›è¡Œå…¨é¢æ‰«æ
                if len(all_findings) < 3:
                    await self.emit_thinking("æ‰§è¡Œ LLM å…¨é¢ä»£ç æ‰«æ...")
                    llm_findings = await self._llm_comprehensive_scan(tech_stack)
                    all_findings.extend(llm_findings)
            
            # å»é‡
            all_findings = self._deduplicate_findings(all_findings)
            
            duration_ms = int((time.time() - start_time) * 1000)
            
            await self.emit_event(
                "info",
                f"åˆ†æå®Œæˆ: å‘ç° {len(all_findings)} ä¸ªæ½œåœ¨æ¼æ´"
            )
            
            return AgentResult(
                success=True,
                data={"findings": all_findings},
                iterations=self._iteration,
                tool_calls=self._tool_calls,
                tokens_used=self._total_tokens,
                duration_ms=duration_ms,
            )
            
        except Exception as e:
            logger.error(f"Analysis agent failed: {e}", exc_info=True)
            return AgentResult(success=False, error=str(e))
    
    async def _run_static_analysis(self, tech_stack: Dict) -> List[Dict]:
        """è¿è¡Œé™æ€åˆ†æå·¥å…·"""
        findings = []
        
        # Semgrep æ‰«æ
        semgrep_tool = self.tools.get("semgrep_scan")
        if semgrep_tool:
            await self.emit_tool_call("semgrep_scan", {"rules": "p/security-audit"})
            
            result = await semgrep_tool.execute(rules="p/security-audit", max_results=30)
            
            if result.success and result.metadata.get("findings_count", 0) > 0:
                for finding in result.metadata.get("findings", []):
                    findings.append({
                        "vulnerability_type": self._map_semgrep_rule(finding.get("check_id", "")),
                        "severity": self._map_semgrep_severity(finding.get("extra", {}).get("severity", "")),
                        "title": finding.get("check_id", "Semgrep Finding"),
                        "description": finding.get("extra", {}).get("message", ""),
                        "file_path": finding.get("path", ""),
                        "line_start": finding.get("start", {}).get("line", 0),
                        "code_snippet": finding.get("extra", {}).get("lines", ""),
                        "source": "semgrep",
                        "needs_verification": True,
                    })
        
        # Bandit æ‰«æ (Python)
        languages = tech_stack.get("languages", [])
        if "Python" in languages:
            bandit_tool = self.tools.get("bandit_scan")
            if bandit_tool:
                await self.emit_tool_call("bandit_scan", {})
                result = await bandit_tool.execute()
                
                if result.success and result.metadata.get("findings_count", 0) > 0:
                    for finding in result.metadata.get("findings", []):
                        findings.append({
                            "vulnerability_type": self._map_bandit_test(finding.get("test_id", "")),
                            "severity": finding.get("issue_severity", "medium").lower(),
                            "title": finding.get("test_name", "Bandit Finding"),
                            "description": finding.get("issue_text", ""),
                            "file_path": finding.get("filename", ""),
                            "line_start": finding.get("line_number", 0),
                            "code_snippet": finding.get("code", ""),
                            "source": "bandit",
                            "needs_verification": True,
                        })
        
        return findings
    
    async def _analyze_entry_points(self, entry_points: List[Dict]) -> List[Dict]:
        """åˆ†æå…¥å£ç‚¹"""
        findings = []
        
        code_analysis_tool = self.tools.get("code_analysis")
        read_tool = self.tools.get("read_file")
        
        if not code_analysis_tool or not read_tool:
            return findings
        
        # åˆ†æå‰å‡ ä¸ªå…¥å£ç‚¹
        for ep in entry_points[:10]:
            if self.is_cancelled:
                break
            
            file_path = ep.get("file", "")
            line = ep.get("line", 1)
            
            if not file_path:
                continue
            
            # è¯»å–æ–‡ä»¶å†…å®¹
            read_result = await read_tool.execute(
                file_path=file_path,
                start_line=max(1, line - 20),
                end_line=line + 50,
            )
            
            if not read_result.success:
                continue
            
            # æ·±åº¦åˆ†æ
            analysis_result = await code_analysis_tool.execute(
                code=read_result.data,
                file_path=file_path,
            )
            
            if analysis_result.success and analysis_result.metadata.get("issues"):
                for issue in analysis_result.metadata["issues"]:
                    findings.append({
                        "vulnerability_type": issue.get("type", "unknown"),
                        "severity": issue.get("severity", "medium"),
                        "title": issue.get("title", "Security Issue"),
                        "description": issue.get("description", ""),
                        "file_path": file_path,
                        "line_start": issue.get("line", line),
                        "code_snippet": issue.get("code_snippet", ""),
                        "suggestion": issue.get("suggestion", ""),
                        "source": "code_analysis",
                        "needs_verification": True,
                    })
        
        return findings
    
    async def _analyze_high_risk_areas(self, high_risk_areas: List[str]) -> List[Dict]:
        """åˆ†æé«˜é£é™©åŒºåŸŸ - ä½¿ç”¨ LLM æ·±åº¦åˆ†æ"""
        findings = []
        
        read_tool = self.tools.get("read_file")
        search_tool = self.tools.get("search_code")
        code_analysis_tool = self.tools.get("code_analysis")
        
        if not search_tool:
            return findings
        
        # åœ¨é«˜é£é™©åŒºåŸŸæœç´¢å±é™©æ¨¡å¼
        dangerous_patterns = [
            ("execute(", "sql_injection"),
            ("query(", "sql_injection"),
            ("eval(", "code_injection"),
            ("system(", "command_injection"),
            ("exec(", "command_injection"),
            ("subprocess", "command_injection"),
            ("innerHTML", "xss"),
            ("document.write", "xss"),
            ("open(", "path_traversal"),
            ("requests.get", "ssrf"),
        ]
        
        analyzed_files = set()
        
        for pattern, vuln_type in dangerous_patterns[:8]:
            if self.is_cancelled:
                break
            
            result = await search_tool.execute(keyword=pattern, max_results=10)
            
            if result.success and result.metadata.get("matches", 0) > 0:
                for match in result.metadata.get("results", [])[:5]:
                    file_path = match.get("file", "")
                    line = match.get("line", 0)
                    
                    # é¿å…é‡å¤åˆ†æåŒä¸€ä¸ªæ–‡ä»¶çš„åŒä¸€åŒºåŸŸ
                    file_key = f"{file_path}:{line // 50}"
                    if file_key in analyzed_files:
                        continue
                    analyzed_files.add(file_key)
                    
                    # ğŸ”¥ ä½¿ç”¨ LLM æ·±åº¦åˆ†ææ‰¾åˆ°çš„ä»£ç 
                    if read_tool and code_analysis_tool:
                        await self.emit_thinking(f"LLM åˆ†æ {file_path}:{line} çš„ {vuln_type} é£é™©...")
                        
                        # è¯»å–ä»£ç ä¸Šä¸‹æ–‡
                        read_result = await read_tool.execute(
                            file_path=file_path,
                            start_line=max(1, line - 15),
                            end_line=line + 25,
                        )
                        
                        if read_result.success:
                            # è°ƒç”¨ LLM åˆ†æ
                            analysis_result = await code_analysis_tool.execute(
                                code=read_result.data,
                                file_path=file_path,
                                focus=vuln_type,
                            )
                            
                            if analysis_result.success and analysis_result.metadata.get("issues"):
                                for issue in analysis_result.metadata["issues"]:
                                    findings.append({
                                        "vulnerability_type": issue.get("type", vuln_type),
                                        "severity": issue.get("severity", "medium"),
                                        "title": issue.get("title", f"LLM å‘ç°: {vuln_type}"),
                                        "description": issue.get("description", ""),
                                        "file_path": file_path,
                                        "line_start": issue.get("line", line),
                                        "code_snippet": issue.get("code_snippet", match.get("match", "")),
                                        "suggestion": issue.get("suggestion", ""),
                                        "ai_explanation": issue.get("ai_explanation", ""),
                                        "source": "llm_analysis",
                                        "needs_verification": True,
                                    })
                            elif analysis_result.success:
                                # LLM åˆ†æäº†ä½†æ²¡å‘ç°é—®é¢˜ï¼Œä»è®°å½•åŸå§‹å‘ç°
                                findings.append({
                                    "vulnerability_type": vuln_type,
                                    "severity": "low",
                                    "title": f"ç–‘ä¼¼ {vuln_type}: {pattern}",
                                    "description": f"åœ¨ {file_path} ä¸­å‘ç°å±é™©æ¨¡å¼ï¼Œä½† LLM åˆ†ææœªç¡®è®¤",
                                    "file_path": file_path,
                                    "line_start": line,
                                    "code_snippet": match.get("match", ""),
                                    "source": "pattern_search",
                                    "needs_verification": True,
                                })
                    else:
                        # æ²¡æœ‰ LLM å·¥å…·ï¼Œä½¿ç”¨åŸºç¡€æ¨¡å¼åŒ¹é…
                        findings.append({
                            "vulnerability_type": vuln_type,
                            "severity": "medium",
                            "title": f"ç–‘ä¼¼ {vuln_type}: {pattern}",
                            "description": f"åœ¨ {file_path} ä¸­å‘ç°å±é™©æ¨¡å¼ {pattern}",
                            "file_path": file_path,
                            "line_start": line,
                            "code_snippet": match.get("match", ""),
                            "source": "pattern_search",
                            "needs_verification": True,
                        })
        
        return findings
    
    async def _search_vulnerability_pattern(self, vuln_type: str) -> List[Dict]:
        """æœç´¢ç‰¹å®šæ¼æ´æ¨¡å¼ - ä½¿ç”¨ RAG + LLM"""
        findings = []
        
        security_tool = self.tools.get("security_search")
        code_analysis_tool = self.tools.get("code_analysis")
        read_tool = self.tools.get("read_file")
        
        if not security_tool:
            return findings
        
        result = await security_tool.execute(
            vulnerability_type=vuln_type,
            top_k=10,
        )
        
        if result.success and result.metadata.get("results_count", 0) > 0:
            for item in result.metadata.get("results", [])[:5]:
                file_path = item.get("file_path", "")
                line_start = item.get("line_start", 0)
                content = item.get("content", "")[:2000]
                
                # ğŸ”¥ ä½¿ç”¨ LLM éªŒè¯ RAG æœç´¢ç»“æœ
                if code_analysis_tool and content:
                    await self.emit_thinking(f"LLM éªŒè¯ RAG å‘ç°çš„ {vuln_type}...")
                    
                    analysis_result = await code_analysis_tool.execute(
                        code=content,
                        file_path=file_path,
                        focus=vuln_type,
                    )
                    
                    if analysis_result.success and analysis_result.metadata.get("issues"):
                        for issue in analysis_result.metadata["issues"]:
                            findings.append({
                                "vulnerability_type": issue.get("type", vuln_type),
                                "severity": issue.get("severity", "medium"),
                                "title": issue.get("title", f"LLM ç¡®è®¤: {vuln_type}"),
                                "description": issue.get("description", ""),
                                "file_path": file_path,
                                "line_start": issue.get("line", line_start),
                                "code_snippet": issue.get("code_snippet", content[:500]),
                                "suggestion": issue.get("suggestion", ""),
                                "ai_explanation": issue.get("ai_explanation", ""),
                                "source": "rag_llm_analysis",
                                "needs_verification": True,
                            })
                    else:
                        # RAG æ‰¾åˆ°ä½† LLM æœªç¡®è®¤
                        findings.append({
                            "vulnerability_type": vuln_type,
                            "severity": "low",
                            "title": f"ç–‘ä¼¼ {vuln_type} (å¾…ç¡®è®¤)",
                            "description": f"RAG æœç´¢å‘ç°å¯èƒ½å­˜åœ¨ {vuln_type}ï¼Œä½† LLM æœªç¡®è®¤",
                            "file_path": file_path,
                            "line_start": line_start,
                            "code_snippet": content[:500],
                            "source": "rag_search",
                            "needs_verification": True,
                        })
                else:
                    findings.append({
                        "vulnerability_type": vuln_type,
                        "severity": "medium",
                        "title": f"ç–‘ä¼¼ {vuln_type}",
                        "description": f"é€šè¿‡è¯­ä¹‰æœç´¢å‘ç°å¯èƒ½å­˜åœ¨ {vuln_type}",
                        "file_path": file_path,
                        "line_start": line_start,
                        "code_snippet": content[:500],
                        "source": "rag_search",
                        "needs_verification": True,
                    })
        
        return findings
    
    async def _llm_comprehensive_scan(self, tech_stack: Dict) -> List[Dict]:
        """
        LLM å…¨é¢ä»£ç æ‰«æ
        å½“å…¶ä»–æ–¹æ³•æ²¡æœ‰å‘ç°è¶³å¤Ÿçš„é—®é¢˜æ—¶ï¼Œä½¿ç”¨ LLM ç›´æ¥åˆ†æå…³é”®æ–‡ä»¶
        """
        findings = []
        
        list_tool = self.tools.get("list_files")
        read_tool = self.tools.get("read_file")
        code_analysis_tool = self.tools.get("code_analysis")
        
        if not all([list_tool, read_tool, code_analysis_tool]):
            return findings
        
        await self.emit_thinking("LLM å…¨é¢æ‰«æå…³é”®ä»£ç æ–‡ä»¶...")
        
        # ç¡®å®šè¦æ‰«æçš„æ–‡ä»¶ç±»å‹
        languages = tech_stack.get("languages", [])
        file_patterns = []
        
        if "Python" in languages:
            file_patterns.extend(["*.py"])
        if "JavaScript" in languages or "TypeScript" in languages:
            file_patterns.extend(["*.js", "*.ts"])
        if "Go" in languages:
            file_patterns.extend(["*.go"])
        if "Java" in languages:
            file_patterns.extend(["*.java"])
        if "PHP" in languages:
            file_patterns.extend(["*.php"])
        
        if not file_patterns:
            file_patterns = ["*.py", "*.js", "*.ts", "*.go", "*.java", "*.php"]
        
        # æ‰«æå…³é”®ç›®å½•
        key_dirs = ["src", "app", "api", "routes", "controllers", "handlers", "lib", "utils", "."]
        scanned_files = 0
        max_files_to_scan = 10
        
        for key_dir in key_dirs:
            if scanned_files >= max_files_to_scan or self.is_cancelled:
                break
            
            for pattern in file_patterns[:3]:
                if scanned_files >= max_files_to_scan or self.is_cancelled:
                    break
                
                # åˆ—å‡ºæ–‡ä»¶
                list_result = await list_tool.execute(
                    directory=key_dir,
                    pattern=pattern,
                    recursive=True,
                    max_files=20,
                )
                
                if not list_result.success:
                    continue
                
                # ä»è¾“å‡ºä¸­æå–æ–‡ä»¶è·¯å¾„
                output = list_result.data
                file_paths = []
                for line in output.split('\n'):
                    line = line.strip()
                    if line.startswith('ğŸ“„ '):
                        file_paths.append(line[2:].strip())
                
                # åˆ†ææ¯ä¸ªæ–‡ä»¶
                for file_path in file_paths[:5]:
                    if scanned_files >= max_files_to_scan or self.is_cancelled:
                        break
                    
                    # è·³è¿‡æµ‹è¯•æ–‡ä»¶å’Œé…ç½®æ–‡ä»¶
                    if any(skip in file_path.lower() for skip in ['test', 'spec', 'mock', '__pycache__', 'node_modules']):
                        continue
                    
                    await self.emit_thinking(f"LLM åˆ†ææ–‡ä»¶: {file_path}")
                    
                    # è¯»å–æ–‡ä»¶
                    read_result = await read_tool.execute(
                        file_path=file_path,
                        max_lines=200,
                    )
                    
                    if not read_result.success:
                        continue
                    
                    scanned_files += 1
                    
                    # ğŸ”¥ LLM æ·±åº¦åˆ†æ
                    analysis_result = await code_analysis_tool.execute(
                        code=read_result.data,
                        file_path=file_path,
                    )
                    
                    if analysis_result.success and analysis_result.metadata.get("issues"):
                        for issue in analysis_result.metadata["issues"]:
                            findings.append({
                                "vulnerability_type": issue.get("type", "other"),
                                "severity": issue.get("severity", "medium"),
                                "title": issue.get("title", "LLM å‘ç°çš„å®‰å…¨é—®é¢˜"),
                                "description": issue.get("description", ""),
                                "file_path": file_path,
                                "line_start": issue.get("line", 0),
                                "code_snippet": issue.get("code_snippet", ""),
                                "suggestion": issue.get("suggestion", ""),
                                "ai_explanation": issue.get("ai_explanation", ""),
                                "source": "llm_comprehensive_scan",
                                "needs_verification": True,
                            })
        
        await self.emit_thinking(f"LLM å…¨é¢æ‰«æå®Œæˆï¼Œåˆ†æäº† {scanned_files} ä¸ªæ–‡ä»¶")
        return findings

    def _deduplicate_findings(self, findings: List[Dict]) -> List[Dict]:
        """å»é‡å‘ç°"""
        seen = set()
        unique = []
        
        for finding in findings:
            key = (
                finding.get("file_path", ""),
                finding.get("line_start", 0),
                finding.get("vulnerability_type", ""),
            )
            
            if key not in seen:
                seen.add(key)
                unique.append(finding)
        
        return unique
    
    def _map_semgrep_rule(self, rule_id: str) -> str:
        """æ˜ å°„ Semgrep è§„åˆ™åˆ°æ¼æ´ç±»å‹"""
        rule_lower = rule_id.lower()
        
        if "sql" in rule_lower:
            return "sql_injection"
        elif "xss" in rule_lower:
            return "xss"
        elif "command" in rule_lower or "injection" in rule_lower:
            return "command_injection"
        elif "path" in rule_lower or "traversal" in rule_lower:
            return "path_traversal"
        elif "ssrf" in rule_lower:
            return "ssrf"
        elif "deserial" in rule_lower:
            return "deserialization"
        elif "secret" in rule_lower or "password" in rule_lower or "key" in rule_lower:
            return "hardcoded_secret"
        elif "crypto" in rule_lower:
            return "weak_crypto"
        else:
            return "other"
    
    def _map_semgrep_severity(self, severity: str) -> str:
        """æ˜ å°„ Semgrep ä¸¥é‡ç¨‹åº¦"""
        mapping = {
            "ERROR": "high",
            "WARNING": "medium",
            "INFO": "low",
        }
        return mapping.get(severity, "medium")
    
    def _map_bandit_test(self, test_id: str) -> str:
        """æ˜ å°„ Bandit æµ‹è¯•åˆ°æ¼æ´ç±»å‹"""
        mappings = {
            "B101": "assert_used",
            "B102": "exec_used",
            "B103": "hardcoded_password",
            "B104": "hardcoded_bind_all",
            "B105": "hardcoded_password",
            "B106": "hardcoded_password",
            "B107": "hardcoded_password",
            "B108": "hardcoded_tmp",
            "B301": "deserialization",
            "B302": "deserialization",
            "B303": "weak_crypto",
            "B304": "weak_crypto",
            "B305": "weak_crypto",
            "B306": "weak_crypto",
            "B307": "code_injection",
            "B308": "code_injection",
            "B310": "ssrf",
            "B311": "weak_random",
            "B312": "telnet",
            "B501": "ssl_verify",
            "B502": "ssl_verify",
            "B503": "ssl_verify",
            "B504": "ssl_verify",
            "B505": "weak_crypto",
            "B506": "yaml_load",
            "B507": "ssh_key",
            "B601": "command_injection",
            "B602": "command_injection",
            "B603": "command_injection",
            "B604": "command_injection",
            "B605": "command_injection",
            "B606": "command_injection",
            "B607": "command_injection",
            "B608": "sql_injection",
            "B609": "sql_injection",
            "B610": "sql_injection",
            "B611": "sql_injection",
            "B701": "xss",
            "B702": "xss",
            "B703": "xss",
        }
        return mappings.get(test_id, "other")

