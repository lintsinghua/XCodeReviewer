"""
Analysis Agent (æ¼æ´åˆ†æå±‚) - LLM é©±åŠ¨ç‰ˆ

LLM æ˜¯çœŸæ­£çš„å®‰å…¨åˆ†æå¤§è„‘ï¼
- LLM å†³å®šåˆ†æç­–ç•¥
- LLM é€‰æ‹©ä½¿ç”¨ä»€ä¹ˆå·¥å…·
- LLM å†³å®šæ·±å…¥åˆ†æå“ªäº›ä»£ç 
- LLM åˆ¤æ–­å‘ç°çš„é—®é¢˜æ˜¯å¦æ˜¯çœŸå®æ¼æ´

ç±»å‹: ReAct (çœŸæ­£çš„!)
"""

import json
import logging
import re
from typing import List, Dict, Any, Optional
from dataclasses import dataclass

from .base import BaseAgent, AgentConfig, AgentResult, AgentType, AgentPattern

logger = logging.getLogger(__name__)


ANALYSIS_SYSTEM_PROMPT = """ä½ æ˜¯ DeepAudit çš„æ¼æ´åˆ†æ Agentï¼Œä¸€ä¸ª**è‡ªä¸»**çš„å®‰å…¨ä¸“å®¶ã€‚

## ä½ çš„è§’è‰²
ä½ æ˜¯å®‰å…¨å®¡è®¡çš„**æ ¸å¿ƒå¤§è„‘**ï¼Œä¸æ˜¯å·¥å…·æ‰§è¡Œå™¨ã€‚ä½ éœ€è¦ï¼š
1. è‡ªä¸»åˆ¶å®šåˆ†æç­–ç•¥
2. é€‰æ‹©æœ€æœ‰æ•ˆçš„å·¥å…·å’Œæ–¹æ³•
3. æ·±å…¥åˆ†æå¯ç–‘ä»£ç 
4. åˆ¤æ–­æ˜¯å¦æ˜¯çœŸå®æ¼æ´
5. åŠ¨æ€è°ƒæ•´åˆ†ææ–¹å‘

## ä½ å¯ä»¥ä½¿ç”¨çš„å·¥å…·

### å¤–éƒ¨æ‰«æå·¥å…·
- **semgrep_scan**: Semgrep é™æ€åˆ†æï¼ˆæ¨èé¦–å…ˆä½¿ç”¨ï¼‰
  å‚æ•°: rules (str), max_results (int)
- **bandit_scan**: Python å®‰å…¨æ‰«æ

### RAG è¯­ä¹‰æœç´¢
- **rag_query**: è¯­ä¹‰ä»£ç æœç´¢
  å‚æ•°: query (str), top_k (int)
- **security_search**: å®‰å…¨ç›¸å…³ä»£ç æœç´¢
  å‚æ•°: vulnerability_type (str), top_k (int)
- **function_context**: å‡½æ•°ä¸Šä¸‹æ–‡åˆ†æ
  å‚æ•°: function_name (str)

### æ·±åº¦åˆ†æ
- **pattern_match**: å±é™©æ¨¡å¼åŒ¹é…
  å‚æ•°: pattern (str), file_types (list)
- **code_analysis**: LLM æ·±åº¦ä»£ç åˆ†æ â­
  å‚æ•°: code (str), file_path (str), focus (str)
- **dataflow_analysis**: æ•°æ®æµè¿½è¸ª
  å‚æ•°: source (str), sink (str)
- **vulnerability_validation**: æ¼æ´éªŒè¯
  å‚æ•°: code (str), vulnerability_type (str)

### æ–‡ä»¶æ“ä½œ
- **read_file**: è¯»å–æ–‡ä»¶å†…å®¹
  å‚æ•°: file_path (str), start_line (int), end_line (int)
- **search_code**: ä»£ç å…³é”®å­—æœç´¢
  å‚æ•°: keyword (str), max_results (int)
- **list_files**: åˆ—å‡ºç›®å½•æ–‡ä»¶
  å‚æ•°: directory (str), pattern (str)

## å·¥ä½œæ–¹å¼
æ¯ä¸€æ­¥ï¼Œä½ éœ€è¦è¾“å‡ºï¼š

```
Thought: [åˆ†æå½“å‰æƒ…å†µï¼Œæ€è€ƒä¸‹ä¸€æ­¥åº”è¯¥åšä»€ä¹ˆ]
Action: [å·¥å…·åç§°]
Action Input: [JSON æ ¼å¼çš„å‚æ•°]
```

å½“ä½ å®Œæˆåˆ†æåï¼Œè¾“å‡ºï¼š

```
Thought: [æ€»ç»“æ‰€æœ‰å‘ç°]
Final Answer: [JSON æ ¼å¼çš„æ¼æ´æŠ¥å‘Š]
```

## Final Answer æ ¼å¼
```json
{
    "findings": [
        {
            "vulnerability_type": "sql_injection",
            "severity": "high",
            "title": "SQL æ³¨å…¥æ¼æ´",
            "description": "è¯¦ç»†æè¿°",
            "file_path": "path/to/file.py",
            "line_start": 42,
            "code_snippet": "å±é™©ä»£ç ç‰‡æ®µ",
            "source": "æ±¡ç‚¹æ¥æº",
            "sink": "å±é™©å‡½æ•°",
            "suggestion": "ä¿®å¤å»ºè®®",
            "confidence": 0.9,
            "needs_verification": true
        }
    ],
    "summary": "åˆ†ææ€»ç»“"
}
```

## åˆ†æç­–ç•¥å»ºè®®
1. **å¿«é€Ÿæ‰«æ**: å…ˆç”¨ semgrep_scan è·å¾—æ¦‚è§ˆ
2. **é‡ç‚¹æ·±å…¥**: å¯¹å¯ç–‘æ–‡ä»¶ä½¿ç”¨ read_file + code_analysis
3. **æ¨¡å¼æœç´¢**: ç”¨ search_code æ‰¾å±é™©æ¨¡å¼ (eval, exec, query ç­‰)
4. **è¯­ä¹‰æœç´¢**: ç”¨ RAG æ‰¾ç›¸ä¼¼çš„æ¼æ´æ¨¡å¼
5. **æ•°æ®æµ**: ç”¨ dataflow_analysis è¿½è¸ªç”¨æˆ·è¾“å…¥

## é‡ç‚¹å…³æ³¨çš„æ¼æ´ç±»å‹
- SQL æ³¨å…¥ (query, execute, raw SQL)
- XSS (innerHTML, document.write, v-html)
- å‘½ä»¤æ³¨å…¥ (exec, system, subprocess)
- è·¯å¾„éå† (open, readFile, path æ‹¼æ¥)
- SSRF (requests, fetch, http client)
- ç¡¬ç¼–ç å¯†é’¥ (password, secret, api_key)
- ä¸å®‰å…¨çš„ååºåˆ—åŒ– (pickle, yaml.load, eval)

## é‡è¦åŸåˆ™
1. **è´¨é‡ä¼˜å…ˆ** - å®å¯æ·±å…¥åˆ†æå‡ ä¸ªçœŸå®æ¼æ´ï¼Œä¸è¦æµ…å°è¾„æ­¢æŠ¥å‘Šå¤§é‡è¯¯æŠ¥
2. **ä¸Šä¸‹æ–‡åˆ†æ** - çœ‹åˆ°å¯ç–‘ä»£ç è¦è¯»å–ä¸Šä¸‹æ–‡ï¼Œç†è§£å®Œæ•´é€»è¾‘
3. **è‡ªä¸»åˆ¤æ–­** - ä¸è¦æœºæ¢°ç›¸ä¿¡å·¥å…·è¾“å‡ºï¼Œè¦ç”¨ä½ çš„ä¸“ä¸šçŸ¥è¯†åˆ¤æ–­
4. **æŒç»­æ¢ç´¢** - å‘ç°ä¸€ä¸ªé—®é¢˜åï¼Œæ€è€ƒæ˜¯å¦æœ‰ç›¸å…³é—®é¢˜

ç°åœ¨å¼€å§‹ä½ çš„å®‰å…¨åˆ†æï¼"""


@dataclass
class AnalysisStep:
    """åˆ†ææ­¥éª¤"""
    thought: str
    action: Optional[str] = None
    action_input: Optional[Dict] = None
    observation: Optional[str] = None
    is_final: bool = False
    final_answer: Optional[Dict] = None


class AnalysisAgent(BaseAgent):
    """
    æ¼æ´åˆ†æ Agent - LLM é©±åŠ¨ç‰ˆ
    
    LLM å…¨ç¨‹å‚ä¸ï¼Œè‡ªä¸»å†³å®šï¼š
    1. åˆ†æä»€ä¹ˆ
    2. ä½¿ç”¨ä»€ä¹ˆå·¥å…·
    3. æ·±å…¥å“ªäº›ä»£ç 
    4. æŠ¥å‘Šä»€ä¹ˆå‘ç°
    """
    
    def __init__(
        self,
        llm_service,
        tools: Dict[str, Any],
        event_emitter=None,
    ):
        config = AgentConfig(
            name="Analysis",
            agent_type=AgentType.ANALYSIS,
            pattern=AgentPattern.REACT,
            max_iterations=30,
            system_prompt=ANALYSIS_SYSTEM_PROMPT,
        )
        super().__init__(config, llm_service, tools, event_emitter)
        
        self._conversation_history: List[Dict[str, str]] = []
        self._steps: List[AnalysisStep] = []
    
    def _get_tools_description(self) -> str:
        """ç”Ÿæˆå·¥å…·æè¿°"""
        tools_info = []
        for name, tool in self.tools.items():
            if name.startswith("_"):
                continue
            desc = f"- {name}: {getattr(tool, 'description', 'No description')}"
            tools_info.append(desc)
        return "\n".join(tools_info)
    
    def _parse_llm_response(self, response: str) -> AnalysisStep:
        """è§£æ LLM å“åº”"""
        step = AnalysisStep(thought="")
        
        # æå– Thought
        thought_match = re.search(r'Thought:\s*(.*?)(?=Action:|Final Answer:|$)', response, re.DOTALL)
        if thought_match:
            step.thought = thought_match.group(1).strip()
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ç»ˆç­”æ¡ˆ
        final_match = re.search(r'Final Answer:\s*(.*?)$', response, re.DOTALL)
        if final_match:
            step.is_final = True
            try:
                answer_text = final_match.group(1).strip()
                answer_text = re.sub(r'```json\s*', '', answer_text)
                answer_text = re.sub(r'```\s*', '', answer_text)
                step.final_answer = json.loads(answer_text)
            except json.JSONDecodeError:
                step.final_answer = {"findings": [], "raw_answer": final_match.group(1).strip()}
            return step
        
        # æå– Action
        action_match = re.search(r'Action:\s*(\w+)', response)
        if action_match:
            step.action = action_match.group(1).strip()
        
        # æå– Action Input
        input_match = re.search(r'Action Input:\s*(.*?)(?=Thought:|Action:|Observation:|$)', response, re.DOTALL)
        if input_match:
            input_text = input_match.group(1).strip()
            input_text = re.sub(r'```json\s*', '', input_text)
            input_text = re.sub(r'```\s*', '', input_text)
            try:
                step.action_input = json.loads(input_text)
            except json.JSONDecodeError:
                step.action_input = {"raw_input": input_text}
        
        return step
    
    async def _execute_tool(self, tool_name: str, tool_input: Dict) -> str:
        """æ‰§è¡Œå·¥å…·"""
        tool = self.tools.get(tool_name)
        
        if not tool:
            return f"é”™è¯¯: å·¥å…· '{tool_name}' ä¸å­˜åœ¨ã€‚å¯ç”¨å·¥å…·: {list(self.tools.keys())}"
        
        try:
            self._tool_calls += 1
            await self.emit_tool_call(tool_name, tool_input)
            
            import time
            start = time.time()
            
            result = await tool.execute(**tool_input)
            
            duration_ms = int((time.time() - start) * 1000)
            await self.emit_tool_result(tool_name, str(result.data)[:200], duration_ms)
            
            if result.success:
                output = str(result.data)
                
                # å¦‚æœæ˜¯ä»£ç åˆ†æå·¥å…·ï¼Œä¹ŸåŒ…å« metadata
                if result.metadata:
                    if "issues" in result.metadata:
                        output += f"\n\nå‘ç°çš„é—®é¢˜:\n{json.dumps(result.metadata['issues'], ensure_ascii=False, indent=2)}"
                    if "findings" in result.metadata:
                        output += f"\n\nå‘ç°:\n{json.dumps(result.metadata['findings'][:10], ensure_ascii=False, indent=2)}"
                
                if len(output) > 6000:
                    output = output[:6000] + f"\n\n... [è¾“å‡ºå·²æˆªæ–­ï¼Œå…± {len(str(result.data))} å­—ç¬¦]"
                return output
            else:
                return f"å·¥å…·æ‰§è¡Œå¤±è´¥: {result.error}"
                
        except Exception as e:
            logger.error(f"Tool execution error: {e}")
            return f"å·¥å…·æ‰§è¡Œé”™è¯¯: {str(e)}"
    
    async def run(self, input_data: Dict[str, Any]) -> AgentResult:
        """
        æ‰§è¡Œæ¼æ´åˆ†æ - LLM å…¨ç¨‹å‚ä¸ï¼
        """
        import time
        start_time = time.time()
        
        project_info = input_data.get("project_info", {})
        config = input_data.get("config", {})
        plan = input_data.get("plan", {})
        previous_results = input_data.get("previous_results", {})
        task = input_data.get("task", "")
        task_context = input_data.get("task_context", "")
        
        # ä» Recon ç»“æœè·å–ä¸Šä¸‹æ–‡
        recon_data = previous_results.get("recon", {})
        if isinstance(recon_data, dict) and "data" in recon_data:
            recon_data = recon_data["data"]
        
        tech_stack = recon_data.get("tech_stack", {})
        entry_points = recon_data.get("entry_points", [])
        high_risk_areas = recon_data.get("high_risk_areas", plan.get("high_risk_areas", []))
        initial_findings = recon_data.get("initial_findings", [])
        
        # æ„å»ºåˆå§‹æ¶ˆæ¯
        initial_message = f"""è¯·å¼€å§‹å¯¹é¡¹ç›®è¿›è¡Œå®‰å…¨æ¼æ´åˆ†æã€‚

## é¡¹ç›®ä¿¡æ¯
- åç§°: {project_info.get('name', 'unknown')}
- è¯­è¨€: {tech_stack.get('languages', [])}
- æ¡†æ¶: {tech_stack.get('frameworks', [])}

## ä¸Šä¸‹æ–‡ä¿¡æ¯
### é«˜é£é™©åŒºåŸŸ
{json.dumps(high_risk_areas[:20], ensure_ascii=False)}

### å…¥å£ç‚¹ (å‰10ä¸ª)
{json.dumps(entry_points[:10], ensure_ascii=False, indent=2)}

### åˆæ­¥å‘ç° (å¦‚æœæœ‰)
{json.dumps(initial_findings[:5], ensure_ascii=False, indent=2) if initial_findings else 'æ— '}

## ä»»åŠ¡
{task_context or task or 'è¿›è¡Œå…¨é¢çš„å®‰å…¨æ¼æ´åˆ†æï¼Œå‘ç°ä»£ç ä¸­çš„å®‰å…¨é—®é¢˜ã€‚'}

## ç›®æ ‡æ¼æ´ç±»å‹
{config.get('target_vulnerabilities', ['all'])}

## å¯ç”¨å·¥å…·
{self._get_tools_description()}

è¯·å¼€å§‹ä½ çš„å®‰å…¨åˆ†æã€‚é¦–å…ˆæ€è€ƒåˆ†æç­–ç•¥ï¼Œç„¶åé€‰æ‹©åˆé€‚çš„å·¥å…·å¼€å§‹åˆ†æã€‚"""

        # åˆå§‹åŒ–å¯¹è¯å†å²
        self._conversation_history = [
            {"role": "system", "content": self.config.system_prompt},
            {"role": "user", "content": initial_message},
        ]
        
        self._steps = []
        all_findings = []
        
        await self.emit_thinking("ğŸ”¬ Analysis Agent å¯åŠ¨ï¼ŒLLM å¼€å§‹è‡ªä¸»å®‰å…¨åˆ†æ...")
        
        try:
            for iteration in range(self.config.max_iterations):
                if self.is_cancelled:
                    break
                
                self._iteration = iteration + 1
                
                # ğŸ”¥ å‘å°„ LLM å¼€å§‹æ€è€ƒäº‹ä»¶
                await self.emit_llm_start(iteration + 1)
                
                # ğŸ”¥ è°ƒç”¨ LLM è¿›è¡Œæ€è€ƒå’Œå†³ç­–
                response = await self.llm_service.chat_completion_raw(
                    messages=self._conversation_history,
                    temperature=0.1,
                    max_tokens=2048,
                )
                
                llm_output = response.get("content", "")
                tokens_this_round = response.get("usage", {}).get("total_tokens", 0)
                self._total_tokens += tokens_this_round
                
                # è§£æ LLM å“åº”
                step = self._parse_llm_response(llm_output)
                self._steps.append(step)
                
                # ğŸ”¥ å‘å°„ LLM æ€è€ƒå†…å®¹äº‹ä»¶ - å±•ç¤ºå®‰å…¨åˆ†æçš„æ€è€ƒè¿‡ç¨‹
                if step.thought:
                    await self.emit_llm_thought(step.thought, iteration + 1)
                
                # æ·»åŠ  LLM å“åº”åˆ°å†å²
                self._conversation_history.append({
                    "role": "assistant",
                    "content": llm_output,
                })
                
                # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                if step.is_final:
                    await self.emit_llm_decision("å®Œæˆå®‰å…¨åˆ†æ", "LLM åˆ¤æ–­åˆ†æå·²å……åˆ†")
                    if step.final_answer and "findings" in step.final_answer:
                        all_findings = step.final_answer["findings"]
                        # ğŸ”¥ å‘å°„æ¯ä¸ªå‘ç°çš„äº‹ä»¶
                        for finding in all_findings[:5]:  # é™åˆ¶æ•°é‡
                            await self.emit_finding(
                                finding.get("title", "Unknown"),
                                finding.get("severity", "medium"),
                                finding.get("vulnerability_type", "other"),
                                finding.get("file_path", "")
                            )
                    await self.emit_llm_complete(
                        f"åˆ†æå®Œæˆï¼Œå‘ç° {len(all_findings)} ä¸ªæ½œåœ¨æ¼æ´",
                        self._total_tokens
                    )
                    break
                
                # æ‰§è¡Œå·¥å…·
                if step.action:
                    # ğŸ”¥ å‘å°„ LLM åŠ¨ä½œå†³ç­–äº‹ä»¶
                    await self.emit_llm_action(step.action, step.action_input or {})
                    
                    observation = await self._execute_tool(
                        step.action,
                        step.action_input or {}
                    )
                    
                    step.observation = observation
                    
                    # ğŸ”¥ å‘å°„ LLM è§‚å¯Ÿäº‹ä»¶
                    await self.emit_llm_observation(observation)
                    
                    # æ·»åŠ è§‚å¯Ÿç»“æœåˆ°å†å²
                    self._conversation_history.append({
                        "role": "user",
                        "content": f"Observation:\n{observation}",
                    })
                else:
                    # LLM æ²¡æœ‰é€‰æ‹©å·¥å…·ï¼Œæç¤ºå®ƒç»§ç»­
                    await self.emit_llm_decision("ç»§ç»­åˆ†æ", "LLM éœ€è¦æ›´å¤šåˆ†æ")
                    self._conversation_history.append({
                        "role": "user",
                        "content": "è¯·ç»§ç»­åˆ†æã€‚é€‰æ‹©ä¸€ä¸ªå·¥å…·æ‰§è¡Œï¼Œæˆ–è€…å¦‚æœåˆ†æå®Œæˆï¼Œè¾“å‡º Final Answer æ±‡æ€»æ‰€æœ‰å‘ç°ã€‚",
                    })
            
            # å¤„ç†ç»“æœ
            duration_ms = int((time.time() - start_time) * 1000)
            
            # æ ‡å‡†åŒ–å‘ç°
            standardized_findings = []
            for finding in all_findings:
                standardized = {
                    "vulnerability_type": finding.get("vulnerability_type", "other"),
                    "severity": finding.get("severity", "medium"),
                    "title": finding.get("title", "Unknown Finding"),
                    "description": finding.get("description", ""),
                    "file_path": finding.get("file_path", ""),
                    "line_start": finding.get("line_start") or finding.get("line", 0),
                    "code_snippet": finding.get("code_snippet", ""),
                    "source": finding.get("source", ""),
                    "sink": finding.get("sink", ""),
                    "suggestion": finding.get("suggestion", ""),
                    "confidence": finding.get("confidence", 0.7),
                    "needs_verification": finding.get("needs_verification", True),
                }
                standardized_findings.append(standardized)
            
            await self.emit_event(
                "info",
                f"ğŸ¯ Analysis Agent å®Œæˆ: {len(standardized_findings)} ä¸ªå‘ç°, {self._iteration} è½®è¿­ä»£, {self._tool_calls} æ¬¡å·¥å…·è°ƒç”¨"
            )
            
            return AgentResult(
                success=True,
                data={
                    "findings": standardized_findings,
                    "steps": [
                        {
                            "thought": s.thought,
                            "action": s.action,
                            "action_input": s.action_input,
                            "observation": s.observation[:500] if s.observation else None,
                        }
                        for s in self._steps
                    ],
                },
                iterations=self._iteration,
                tool_calls=self._tool_calls,
                tokens_used=self._total_tokens,
                duration_ms=duration_ms,
            )
            
        except Exception as e:
            logger.error(f"Analysis Agent failed: {e}", exc_info=True)
            return AgentResult(success=False, error=str(e))
    
    def get_conversation_history(self) -> List[Dict[str, str]]:
        """è·å–å¯¹è¯å†å²"""
        return self._conversation_history
    
    def get_steps(self) -> List[AnalysisStep]:
        """è·å–æ‰§è¡Œæ­¥éª¤"""
        return self._steps
