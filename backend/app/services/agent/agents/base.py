"""
Agent åŸºç±»
å®šä¹‰ Agent çš„åŸºæœ¬æ¥å£å’Œé€šç”¨åŠŸèƒ½

æ ¸å¿ƒåŸåˆ™ï¼šLLM æ˜¯ Agent çš„å¤§è„‘ï¼Œæ‰€æœ‰æ—¥å¿—åº”è¯¥åæ˜  LLM çš„å‚ä¸ï¼
"""

from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional, AsyncGenerator
from dataclasses import dataclass, field
from enum import Enum
import logging

logger = logging.getLogger(__name__)


class AgentType(Enum):
    """Agent ç±»å‹"""
    ORCHESTRATOR = "orchestrator"
    RECON = "recon"
    ANALYSIS = "analysis"
    VERIFICATION = "verification"


class AgentPattern(Enum):
    """Agent è¿è¡Œæ¨¡å¼"""
    REACT = "react"                    # ååº”å¼ï¼šæ€è€ƒ-è¡ŒåŠ¨-è§‚å¯Ÿå¾ªç¯
    PLAN_AND_EXECUTE = "plan_execute"  # è®¡åˆ’æ‰§è¡Œï¼šå…ˆè§„åˆ’åæ‰§è¡Œ


@dataclass
class AgentConfig:
    """Agent é…ç½®"""
    name: str
    agent_type: AgentType
    pattern: AgentPattern = AgentPattern.REACT
    
    # LLM é…ç½®
    model: Optional[str] = None
    temperature: float = 0.1
    max_tokens: int = 4096
    
    # æ‰§è¡Œé™åˆ¶
    max_iterations: int = 20
    timeout_seconds: int = 600
    
    # å·¥å…·é…ç½®
    tools: List[str] = field(default_factory=list)
    
    # ç³»ç»Ÿæç¤ºè¯
    system_prompt: Optional[str] = None
    
    # å…ƒæ•°æ®
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class AgentResult:
    """Agent æ‰§è¡Œç»“æœ"""
    success: bool
    data: Any = None
    error: Optional[str] = None
    
    # æ‰§è¡Œç»Ÿè®¡
    iterations: int = 0
    tool_calls: int = 0
    tokens_used: int = 0
    duration_ms: int = 0
    
    # ä¸­é—´ç»“æœ
    intermediate_steps: List[Dict[str, Any]] = field(default_factory=list)
    
    # å…ƒæ•°æ®
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "success": self.success,
            "data": self.data,
            "error": self.error,
            "iterations": self.iterations,
            "tool_calls": self.tool_calls,
            "tokens_used": self.tokens_used,
            "duration_ms": self.duration_ms,
            "metadata": self.metadata,
        }


class BaseAgent(ABC):
    """
    Agent åŸºç±»
    
    æ ¸å¿ƒåŸåˆ™ï¼š
    1. LLM æ˜¯ Agent çš„å¤§è„‘ï¼Œå…¨ç¨‹å‚ä¸å†³ç­–
    2. æ‰€æœ‰æ—¥å¿—åº”è¯¥åæ˜  LLM çš„æ€è€ƒè¿‡ç¨‹
    3. å·¥å…·è°ƒç”¨æ˜¯ LLM çš„å†³ç­–ç»“æœ
    """
    
    def __init__(
        self,
        config: AgentConfig,
        llm_service,
        tools: Dict[str, Any],
        event_emitter=None,
    ):
        """
        åˆå§‹åŒ– Agent
        
        Args:
            config: Agent é…ç½®
            llm_service: LLM æœåŠ¡
            tools: å¯ç”¨å·¥å…·å­—å…¸
            event_emitter: äº‹ä»¶å‘å°„å™¨
        """
        self.config = config
        self.llm_service = llm_service
        self.tools = tools
        self.event_emitter = event_emitter
        
        # è¿è¡ŒçŠ¶æ€
        self._iteration = 0
        self._total_tokens = 0
        self._tool_calls = 0
        self._cancelled = False
    
    @property
    def name(self) -> str:
        return self.config.name
    
    @property
    def agent_type(self) -> AgentType:
        return self.config.agent_type
    
    @abstractmethod
    async def run(self, input_data: Dict[str, Any]) -> AgentResult:
        """
        æ‰§è¡Œ Agent ä»»åŠ¡
        
        Args:
            input_data: è¾“å…¥æ•°æ®
            
        Returns:
            Agent æ‰§è¡Œç»“æœ
        """
        pass
    
    def cancel(self):
        """å–æ¶ˆæ‰§è¡Œ"""
        self._cancelled = True
    
    @property
    def is_cancelled(self) -> bool:
        return self._cancelled
    
    # ============ æ ¸å¿ƒäº‹ä»¶å‘å°„æ–¹æ³• ============
    
    async def emit_event(
        self,
        event_type: str,
        message: str,
        **kwargs
    ):
        """å‘å°„äº‹ä»¶"""
        if self.event_emitter:
            from ..event_manager import AgentEventData
            await self.event_emitter.emit(AgentEventData(
                event_type=event_type,
                message=message,
                **kwargs
            ))
    
    # ============ LLM æ€è€ƒç›¸å…³äº‹ä»¶ ============
    
    async def emit_thinking(self, message: str):
        """å‘å°„ LLM æ€è€ƒäº‹ä»¶"""
        await self.emit_event("thinking", f"ğŸ§  [{self.name}] {message}")
    
    async def emit_llm_start(self, iteration: int):
        """å‘å°„ LLM å¼€å§‹æ€è€ƒäº‹ä»¶"""
        await self.emit_event(
            "llm_start",
            f"ğŸ¤” [{self.name}] LLM å¼€å§‹ç¬¬ {iteration} è½®æ€è€ƒ...",
            metadata={"iteration": iteration}
        )
    
    async def emit_llm_thought(self, thought: str, iteration: int):
        """å‘å°„ LLM æ€è€ƒå†…å®¹äº‹ä»¶ - è¿™æ˜¯æ ¸å¿ƒï¼å±•ç¤º LLM åœ¨æƒ³ä»€ä¹ˆ"""
        # æˆªæ–­è¿‡é•¿çš„æ€è€ƒå†…å®¹
        display_thought = thought[:500] + "..." if len(thought) > 500 else thought
        await self.emit_event(
            "llm_thought",
            f"ğŸ’­ [{self.name}] LLM æ€è€ƒ:\n{display_thought}",
            metadata={
                "thought": thought,
                "iteration": iteration,
            }
        )
    
    async def emit_llm_decision(self, decision: str, reason: str = ""):
        """å‘å°„ LLM å†³ç­–äº‹ä»¶ - å±•ç¤º LLM åšäº†ä»€ä¹ˆå†³å®š"""
        await self.emit_event(
            "llm_decision",
            f"ğŸ’¡ [{self.name}] LLM å†³ç­–: {decision}" + (f" (ç†ç”±: {reason})" if reason else ""),
            metadata={
                "decision": decision,
                "reason": reason,
            }
        )
    
    async def emit_llm_action(self, action: str, action_input: Dict):
        """å‘å°„ LLM åŠ¨ä½œäº‹ä»¶ - LLM å†³å®šæ‰§è¡Œä»€ä¹ˆåŠ¨ä½œ"""
        import json
        input_str = json.dumps(action_input, ensure_ascii=False)[:200]
        await self.emit_event(
            "llm_action",
            f"âš¡ [{self.name}] LLM åŠ¨ä½œ: {action}\n   å‚æ•°: {input_str}",
            metadata={
                "action": action,
                "action_input": action_input,
            }
        )
    
    async def emit_llm_observation(self, observation: str):
        """å‘å°„ LLM è§‚å¯Ÿäº‹ä»¶ - LLM çœ‹åˆ°äº†ä»€ä¹ˆ"""
        display_obs = observation[:300] + "..." if len(observation) > 300 else observation
        await self.emit_event(
            "llm_observation",
            f"ğŸ‘ï¸ [{self.name}] LLM è§‚å¯Ÿåˆ°:\n{display_obs}",
            metadata={"observation": observation[:2000]}
        )
    
    async def emit_llm_complete(self, result_summary: str, tokens_used: int):
        """å‘å°„ LLM å®Œæˆäº‹ä»¶"""
        await self.emit_event(
            "llm_complete",
            f"âœ… [{self.name}] LLM å®Œæˆ: {result_summary} (æ¶ˆè€— {tokens_used} tokens)",
            metadata={
                "tokens_used": tokens_used,
            }
        )
    
    # ============ å·¥å…·è°ƒç”¨ç›¸å…³äº‹ä»¶ ============
    
    async def emit_tool_call(self, tool_name: str, tool_input: Dict):
        """å‘å°„å·¥å…·è°ƒç”¨äº‹ä»¶ - LLM å†³å®šè°ƒç”¨å·¥å…·"""
        import json
        input_str = json.dumps(tool_input, ensure_ascii=False)[:300]
        await self.emit_event(
            "tool_call",
            f"ğŸ”§ [{self.name}] LLM è°ƒç”¨å·¥å…·: {tool_name}\n   è¾“å…¥: {input_str}",
            tool_name=tool_name,
            tool_input=tool_input,
        )
    
    async def emit_tool_result(self, tool_name: str, result: str, duration_ms: int):
        """å‘å°„å·¥å…·ç»“æœäº‹ä»¶"""
        result_preview = result[:200] + "..." if len(result) > 200 else result
        await self.emit_event(
            "tool_result",
            f"ğŸ“¤ [{self.name}] å·¥å…· {tool_name} è¿”å› ({duration_ms}ms):\n   {result_preview}",
            tool_name=tool_name,
            tool_duration_ms=duration_ms,
        )
    
    # ============ å‘ç°ç›¸å…³äº‹ä»¶ ============
    
    async def emit_finding(self, title: str, severity: str, vuln_type: str, file_path: str = ""):
        """å‘å°„æ¼æ´å‘ç°äº‹ä»¶"""
        severity_emoji = {
            "critical": "ğŸ”´",
            "high": "ğŸŸ ",
            "medium": "ğŸŸ¡",
            "low": "ğŸŸ¢",
        }.get(severity.lower(), "âšª")
        
        await self.emit_event(
            "finding",
            f"{severity_emoji} [{self.name}] å‘ç°æ¼æ´: [{severity.upper()}] {title}\n   ç±»å‹: {vuln_type}\n   ä½ç½®: {file_path}",
            metadata={
                "title": title,
                "severity": severity,
                "vulnerability_type": vuln_type,
                "file_path": file_path,
            }
        )
    
    # ============ é€šç”¨å·¥å…·æ–¹æ³• ============
    
    async def call_tool(self, tool_name: str, **kwargs) -> Any:
        """
        è°ƒç”¨å·¥å…·
        
        Args:
            tool_name: å·¥å…·åç§°
            **kwargs: å·¥å…·å‚æ•°
            
        Returns:
            å·¥å…·æ‰§è¡Œç»“æœ
        """
        tool = self.tools.get(tool_name)
        if not tool:
            logger.warning(f"Tool not found: {tool_name}")
            return None
        
        self._tool_calls += 1
        await self.emit_tool_call(tool_name, kwargs)
        
        import time
        start = time.time()
        
        result = await tool.execute(**kwargs)
        
        duration_ms = int((time.time() - start) * 1000)
        await self.emit_tool_result(tool_name, str(result.data)[:500], duration_ms)
        
        return result
    
    async def call_llm(
        self,
        messages: List[Dict[str, str]],
        tools: Optional[List[Dict]] = None,
    ) -> Dict[str, Any]:
        """
        è°ƒç”¨ LLM
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            tools: å¯ç”¨å·¥å…·æè¿°
            
        Returns:
            LLM å“åº”
        """
        self._iteration += 1
        
        # å‘å°„ LLM å¼€å§‹äº‹ä»¶
        await self.emit_llm_start(self._iteration)
        
        try:
            response = await self.llm_service.chat_completion(
                messages=messages,
                temperature=self.config.temperature,
                max_tokens=self.config.max_tokens,
                tools=tools,
            )
            
            if response.get("usage"):
                self._total_tokens += response["usage"].get("total_tokens", 0)
            
            return response
            
        except Exception as e:
            logger.error(f"LLM call failed: {e}")
            raise
    
    def get_tool_descriptions(self) -> List[Dict[str, Any]]:
        """è·å–å·¥å…·æè¿°ï¼ˆç”¨äº LLMï¼‰"""
        descriptions = []
        
        for name, tool in self.tools.items():
            if name.startswith("_"):
                continue
            
            desc = {
                "type": "function",
                "function": {
                    "name": name,
                    "description": tool.description,
                }
            }
            
            # æ·»åŠ å‚æ•° schema
            if hasattr(tool, 'args_schema') and tool.args_schema:
                desc["function"]["parameters"] = tool.args_schema.schema()
            
            descriptions.append(desc)
        
        return descriptions
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–æ‰§è¡Œç»Ÿè®¡"""
        return {
            "agent": self.name,
            "type": self.agent_type.value,
            "iterations": self._iteration,
            "tool_calls": self._tool_calls,
            "tokens_used": self._total_tokens,
        }
