"""
Orchestrator Agent (ç¼–æ’å±‚) - LLM é©±åŠ¨ç‰ˆ

LLM æ˜¯çœŸæ­£çš„å¤§è„‘ï¼Œå…¨ç¨‹å‚ä¸å†³ç­–ï¼
- LLM å†³å®šä¸‹ä¸€æ­¥åšä»€ä¹ˆ
- LLM å†³å®šè°ƒåº¦å“ªä¸ªå­ Agent
- LLM å†³å®šä½•æ—¶å®Œæˆ
- LLM æ ¹æ®ä¸­é—´ç»“æœåŠ¨æ€è°ƒæ•´ç­–ç•¥

ç±»å‹: Autonomous Agent with Dynamic Planning
"""

import asyncio
import json
import logging
import re
from typing import List, Dict, Any, Optional
from dataclasses import dataclass

from .base import BaseAgent, AgentConfig, AgentResult, AgentType, AgentPattern
from ..json_parser import AgentJsonParser

logger = logging.getLogger(__name__)


ORCHESTRATOR_SYSTEM_PROMPT = """ä½ æ˜¯ DeepAudit çš„ç¼–æ’ Agentï¼Œè´Ÿè´£**è‡ªä¸»**åè°ƒæ•´ä¸ªå®‰å…¨å®¡è®¡æµç¨‹ã€‚

## ä½ çš„è§’è‰²
ä½ æ˜¯æ•´ä¸ªå®¡è®¡æµç¨‹çš„**å¤§è„‘**ï¼Œä¸æ˜¯ä¸€ä¸ªæœºæ¢°æ‰§è¡Œè€…ã€‚ä½ éœ€è¦ï¼š
1. è‡ªä¸»æ€è€ƒå’Œå†³ç­–
2. æ ¹æ®è§‚å¯Ÿç»“æœåŠ¨æ€è°ƒæ•´ç­–ç•¥
3. å†³å®šä½•æ—¶è°ƒç”¨å“ªä¸ªå­ Agent
4. åˆ¤æ–­ä½•æ—¶å®¡è®¡å®Œæˆ

## ä½ å¯ä»¥è°ƒåº¦çš„å­ Agent
1. **recon**: ä¿¡æ¯æ”¶é›† Agent - åˆ†æé¡¹ç›®ç»“æ„ã€æŠ€æœ¯æ ˆã€å…¥å£ç‚¹
2. **analysis**: åˆ†æ Agent - æ·±åº¦ä»£ç å®¡è®¡ã€æ¼æ´æ£€æµ‹
3. **verification**: éªŒè¯ Agent - éªŒè¯å‘ç°çš„æ¼æ´ã€ç”Ÿæˆ PoC

## ä½ å¯ä»¥ä½¿ç”¨çš„æ“ä½œ

### 1. è°ƒåº¦å­ Agent
```
Action: dispatch_agent
Action Input: {"agent": "recon|analysis|verification", "task": "å…·ä½“ä»»åŠ¡æè¿°", "context": "ä»»åŠ¡ä¸Šä¸‹æ–‡"}
```

### 2. æ±‡æ€»å‘ç°
```
Action: summarize
Action Input: {"findings": [...], "analysis": "ä½ çš„åˆ†æ"}
```

### 3. å®Œæˆå®¡è®¡
```
Action: finish
Action Input: {"conclusion": "å®¡è®¡ç»“è®º", "findings": [...], "recommendations": [...]}
```

## å·¥ä½œæ–¹å¼
æ¯ä¸€æ­¥ï¼Œä½ éœ€è¦ï¼š

1. **Thought**: åˆ†æå½“å‰çŠ¶æ€ï¼Œæ€è€ƒä¸‹ä¸€æ­¥åº”è¯¥åšä»€ä¹ˆ
   - ç›®å‰æ”¶é›†åˆ°äº†ä»€ä¹ˆä¿¡æ¯ï¼Ÿ
   - è¿˜éœ€è¦äº†è§£ä»€ä¹ˆï¼Ÿ
   - åº”è¯¥æ·±å…¥åˆ†æå“ªäº›åœ°æ–¹ï¼Ÿ
   - æœ‰ä»€ä¹ˆå‘ç°éœ€è¦éªŒè¯ï¼Ÿ

2. **Action**: é€‰æ‹©ä¸€ä¸ªæ“ä½œ
3. **Action Input**: æä¾›æ“ä½œå‚æ•°

## è¾“å‡ºæ ¼å¼
æ¯ä¸€æ­¥å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ï¼š

```
Thought: [ä½ çš„æ€è€ƒè¿‡ç¨‹]
Action: [dispatch_agent|summarize|finish]
Action Input: [JSON å‚æ•°]
```

## å®¡è®¡ç­–ç•¥å»ºè®®
- å…ˆç”¨ recon Agent äº†è§£é¡¹ç›®å…¨è²Œ
- æ ¹æ® recon ç»“æœï¼Œè®© analysis Agent é‡ç‚¹å®¡è®¡é«˜é£é™©åŒºåŸŸ
- å‘ç°å¯ç–‘æ¼æ´åï¼Œç”¨ verification Agent éªŒè¯
- éšæ—¶æ ¹æ®æ–°å‘ç°è°ƒæ•´ç­–ç•¥ï¼Œä¸è¦æœºæ¢°æ‰§è¡Œ
- å½“ä½ è®¤ä¸ºå®¡è®¡è¶³å¤Ÿå…¨é¢æ—¶ï¼Œé€‰æ‹© finish

## é‡è¦åŸåˆ™
1. **ä½ æ˜¯å¤§è„‘ï¼Œä¸æ˜¯æ‰§è¡Œå™¨** - æ¯ä¸€æ­¥éƒ½è¦æ€è€ƒ
2. **åŠ¨æ€è°ƒæ•´** - æ ¹æ®å‘ç°è°ƒæ•´ç­–ç•¥
3. **ä¸»åŠ¨å†³ç­–** - ä¸è¦ç­‰å¾…ï¼Œä¸»åŠ¨æ¨è¿›
4. **è´¨é‡ä¼˜å…ˆ** - å®å¯æ·±å…¥åˆ†æå‡ ä¸ªçœŸå®æ¼æ´ï¼Œä¸è¦æµ…å°è¾„æ­¢

ç°åœ¨ï¼ŒåŸºäºé¡¹ç›®ä¿¡æ¯å¼€å§‹ä½ çš„å®¡è®¡å·¥ä½œï¼"""


@dataclass
class AgentStep:
    """æ‰§è¡Œæ­¥éª¤"""
    thought: str
    action: str
    action_input: Dict[str, Any]
    observation: Optional[str] = None
    sub_agent_result: Optional[AgentResult] = None


class OrchestratorAgent(BaseAgent):
    """
    ç¼–æ’ Agent - LLM é©±åŠ¨ç‰ˆ
    
    LLM å…¨ç¨‹å‚ä¸å†³ç­–ï¼š
    1. LLM æ€è€ƒå½“å‰çŠ¶æ€
    2. LLM å†³å®šä¸‹ä¸€æ­¥æ“ä½œ
    3. æ‰§è¡Œæ“ä½œï¼Œè·å–ç»“æœ
    4. LLM åˆ†æç»“æœï¼Œå†³å®šä¸‹ä¸€æ­¥
    5. é‡å¤ç›´åˆ° LLM å†³å®šå®Œæˆ
    """
    
    def __init__(
        self,
        llm_service,
        tools: Dict[str, Any],
        event_emitter=None,
        sub_agents: Optional[Dict[str, BaseAgent]] = None,
    ):
        config = AgentConfig(
            name="Orchestrator",
            agent_type=AgentType.ORCHESTRATOR,
            pattern=AgentPattern.REACT,  # æ”¹ä¸º ReAct æ¨¡å¼ï¼
            max_iterations=20,
            system_prompt=ORCHESTRATOR_SYSTEM_PROMPT,
        )
        super().__init__(config, llm_service, tools, event_emitter)
        
        self.sub_agents = sub_agents or {}
        self._conversation_history: List[Dict[str, str]] = []
        self._steps: List[AgentStep] = []
        self._all_findings: List[Dict] = []
    
    def register_sub_agent(self, name: str, agent: BaseAgent):
        """æ³¨å†Œå­ Agent"""
        self.sub_agents[name] = agent
    
    async def run(self, input_data: Dict[str, Any]) -> AgentResult:
        """
        æ‰§è¡Œç¼–æ’ä»»åŠ¡ - LLM å…¨ç¨‹å‚ä¸ï¼
        
        Args:
            input_data: {
                "project_info": é¡¹ç›®ä¿¡æ¯,
                "config": å®¡è®¡é…ç½®,
            }
        """
        import time
        start_time = time.time()
        
        project_info = input_data.get("project_info", {})
        config = input_data.get("config", {})
        
        # æ„å»ºåˆå§‹æ¶ˆæ¯
        initial_message = self._build_initial_message(project_info, config)
        
        # åˆå§‹åŒ–å¯¹è¯å†å²
        self._conversation_history = [
            {"role": "system", "content": self.config.system_prompt},
            {"role": "user", "content": initial_message},
        ]
        
        self._steps = []
        self._all_findings = []
        final_result = None
        
        await self.emit_thinking("ğŸ§  Orchestrator Agent å¯åŠ¨ï¼ŒLLM å¼€å§‹è‡ªä¸»ç¼–æ’å†³ç­–...")
        
        try:
            for iteration in range(self.config.max_iterations):
                if self.is_cancelled:
                    break
                
                self._iteration = iteration + 1
                
                # ğŸ”¥ å†æ¬¡æ£€æŸ¥å–æ¶ˆæ ‡å¿—ï¼ˆåœ¨LLMè°ƒç”¨ä¹‹å‰ï¼‰
                if self.is_cancelled:
                    await self.emit_thinking("ğŸ›‘ ä»»åŠ¡å·²å–æ¶ˆï¼Œåœæ­¢æ‰§è¡Œ")
                    break
                
                # è°ƒç”¨ LLM è¿›è¡Œæ€è€ƒå’Œå†³ç­–ï¼ˆæµå¼è¾“å‡ºï¼‰
                try:
                    llm_output, tokens_this_round = await self.stream_llm_call(
                        self._conversation_history,
                        temperature=0.1,
                        max_tokens=2048,
                    )
                except asyncio.CancelledError:
                    logger.info(f"[{self.name}] LLM call cancelled")
                    break
                
                self._total_tokens += tokens_this_round
                
                # è§£æ LLM çš„å†³ç­–
                step = self._parse_llm_response(llm_output)
                
                if not step:
                    # LLM è¾“å‡ºæ ¼å¼ä¸æ­£ç¡®ï¼Œæç¤ºé‡è¯•
                    await self.emit_llm_decision("æ ¼å¼é”™è¯¯", "éœ€è¦é‡æ–°è¾“å‡º")
                    self._conversation_history.append({
                        "role": "assistant",
                        "content": llm_output,
                    })
                    self._conversation_history.append({
                        "role": "user",
                        "content": "è¯·æŒ‰ç…§è§„å®šæ ¼å¼è¾“å‡ºï¼šThought + Action + Action Input",
                    })
                    continue
                
                self._steps.append(step)
                
                # ğŸ”¥ å‘å°„ LLM æ€è€ƒå†…å®¹äº‹ä»¶ - å±•ç¤ºç¼–æ’å†³ç­–çš„æ€è€ƒè¿‡ç¨‹
                if step.thought:
                    await self.emit_llm_thought(step.thought, iteration + 1)
                
                # æ·»åŠ  LLM å“åº”åˆ°å†å²
                self._conversation_history.append({
                    "role": "assistant",
                    "content": llm_output,
                })
                
                # æ‰§è¡Œ LLM å†³å®šçš„æ“ä½œ
                if step.action == "finish":
                    # ğŸ”¥ LLM å†³å®šå®Œæˆå®¡è®¡
                    await self.emit_llm_decision("å®Œæˆå®¡è®¡", "LLM åˆ¤æ–­å®¡è®¡å·²å……åˆ†å®Œæˆ")
                    await self.emit_llm_complete(
                        f"ç¼–æ’å®Œæˆï¼Œå‘ç° {len(self._all_findings)} ä¸ªæ¼æ´",
                        self._total_tokens
                    )
                    final_result = step.action_input
                    break
                
                elif step.action == "dispatch_agent":
                    # ğŸ”¥ LLM å†³å®šè°ƒåº¦å­ Agent
                    agent_name = step.action_input.get("agent", "unknown")
                    task_desc = step.action_input.get("task", "")
                    await self.emit_llm_decision(
                        f"è°ƒåº¦ {agent_name} Agent",
                        f"ä»»åŠ¡: {task_desc[:100]}"
                    )
                    await self.emit_llm_action("dispatch_agent", step.action_input)
                    
                    observation = await self._dispatch_agent(step.action_input)
                    step.observation = observation
                    
                    # ğŸ”¥ å‘å°„è§‚å¯Ÿäº‹ä»¶
                    await self.emit_llm_observation(observation)
                    
                elif step.action == "summarize":
                    # LLM è¦æ±‚æ±‡æ€»
                    await self.emit_llm_decision("æ±‡æ€»å‘ç°", "LLM è¯·æ±‚æŸ¥çœ‹å½“å‰å‘ç°æ±‡æ€»")
                    observation = self._summarize_findings()
                    step.observation = observation
                    await self.emit_llm_observation(observation)
                    
                else:
                    observation = f"æœªçŸ¥æ“ä½œ: {step.action}ï¼Œå¯ç”¨æ“ä½œ: dispatch_agent, summarize, finish"
                    await self.emit_llm_decision("æœªçŸ¥æ“ä½œ", observation)
                
                # æ·»åŠ è§‚å¯Ÿç»“æœåˆ°å†å²
                self._conversation_history.append({
                    "role": "user",
                    "content": f"Observation:\n{step.observation}",
                })
            
            # ç”Ÿæˆæœ€ç»ˆç»“æœ
            duration_ms = int((time.time() - start_time) * 1000)
            
            await self.emit_event(
                "info",
                f"ğŸ¯ Orchestrator å®Œæˆ: {len(self._all_findings)} ä¸ªå‘ç°, {self._iteration} è½®å†³ç­–"
            )
            
            return AgentResult(
                success=True,
                data={
                    "findings": self._all_findings,
                    "summary": final_result or self._generate_default_summary(),
                    "steps": [
                        {
                            "thought": s.thought,
                            "action": s.action,
                            "action_input": s.action_input,
                            "observation": s.observation[:500] if s.observation else None,
                        }
                        for s in self._steps
                    ],
                },
                iterations=self._iteration,
                tool_calls=self._tool_calls,
                tokens_used=self._total_tokens,
                duration_ms=duration_ms,
            )
            
        except Exception as e:
            logger.error(f"Orchestrator failed: {e}", exc_info=True)
            return AgentResult(
                success=False,
                error=str(e),
            )
    
    def _build_initial_message(
        self,
        project_info: Dict[str, Any],
        config: Dict[str, Any],
    ) -> str:
        """æ„å»ºåˆå§‹æ¶ˆæ¯"""
        msg = f"""è¯·å¼€å§‹å¯¹ä»¥ä¸‹é¡¹ç›®è¿›è¡Œå®‰å…¨å®¡è®¡ã€‚

## é¡¹ç›®ä¿¡æ¯
- åç§°: {project_info.get('name', 'unknown')}
- è¯­è¨€: {project_info.get('languages', [])}
- æ–‡ä»¶æ•°é‡: {project_info.get('file_count', 0)}
- ç›®å½•ç»“æ„: {json.dumps(project_info.get('structure', {}), ensure_ascii=False, indent=2)}

## ç”¨æˆ·é…ç½®
- ç›®æ ‡æ¼æ´: {config.get('target_vulnerabilities', ['all'])}
- éªŒè¯çº§åˆ«: {config.get('verification_level', 'sandbox')}
- æ’é™¤æ¨¡å¼: {config.get('exclude_patterns', [])}

## å¯ç”¨å­ Agent
{', '.join(self.sub_agents.keys()) if self.sub_agents else '(æš‚æ— å­ Agent)'}

è¯·å¼€å§‹ä½ çš„å®¡è®¡å·¥ä½œã€‚é¦–å…ˆæ€è€ƒåº”è¯¥å¦‚ä½•å¼€å±•ï¼Œç„¶åå†³å®šç¬¬ä¸€æ­¥åšä»€ä¹ˆã€‚"""
        
        return msg
    
    def _parse_llm_response(self, response: str) -> Optional[AgentStep]:
        """è§£æ LLM å“åº”"""
        # æå– Thought
        thought_match = re.search(r'Thought:\s*(.*?)(?=Action:|$)', response, re.DOTALL)
        thought = thought_match.group(1).strip() if thought_match else ""
        
        # æå– Action
        action_match = re.search(r'Action:\s*(\w+)', response)
        if not action_match:
            return None
        action = action_match.group(1).strip()
        
        # æå– Action Input
        input_match = re.search(r'Action Input:\s*(.*?)(?=Thought:|Observation:|$)', response, re.DOTALL)
        if not input_match:
            return None
        
        input_text = input_match.group(1).strip()
        # ç§»é™¤ markdown ä»£ç å—
        input_text = re.sub(r'```json\s*', '', input_text)
        input_text = re.sub(r'```\s*', '', input_text)
        
        # ä½¿ç”¨å¢å¼ºçš„ JSON è§£æå™¨
        action_input = AgentJsonParser.parse(
            input_text,
            default={"raw": input_text}
        )
        
        return AgentStep(
            thought=thought,
            action=action,
            action_input=action_input,
        )
    
    async def _dispatch_agent(self, params: Dict[str, Any]) -> str:
        """è°ƒåº¦å­ Agent"""
        agent_name = params.get("agent", "")
        task = params.get("task", "")
        context = params.get("context", "")
        
        agent = self.sub_agents.get(agent_name)
        
        if not agent:
            available = list(self.sub_agents.keys())
            return f"é”™è¯¯: Agent '{agent_name}' ä¸å­˜åœ¨ã€‚å¯ç”¨çš„ Agent: {available}"
        
        await self.emit_event(
            "dispatch",
            f"ğŸ“¤ è°ƒåº¦ {agent_name} Agent: {task[:100]}...",
            agent=agent_name,
            task=task,
        )
        
        self._tool_calls += 1
        
        try:
            # æ„å»ºå­ Agent è¾“å…¥
            sub_input = {
                "task": task,
                "task_context": context,
                "project_info": {},  # ä»ä¸Šä¸‹æ–‡è·å–
                "config": {},
            }
            
            # æ‰§è¡Œå­ Agent
            result = await agent.run(sub_input)
            
            # æ”¶é›†å‘ç°
            if result.success and result.data:
                findings = result.data.get("findings", [])
                self._all_findings.extend(findings)
                
                await self.emit_event(
                    "dispatch_complete",
                    f"âœ… {agent_name} Agent å®Œæˆ: {len(findings)} ä¸ªå‘ç°",
                    agent=agent_name,
                    findings_count=len(findings),
                )
                
                # æ„å»ºè§‚å¯Ÿç»“æœ
                observation = f"""## {agent_name} Agent æ‰§è¡Œç»“æœ

**çŠ¶æ€**: æˆåŠŸ
**å‘ç°æ•°é‡**: {len(findings)}
**è¿­ä»£æ¬¡æ•°**: {result.iterations}
**è€—æ—¶**: {result.duration_ms}ms

### å‘ç°æ‘˜è¦
"""
                for i, f in enumerate(findings[:10]):  # æœ€å¤šæ˜¾ç¤º 10 ä¸ª
                    observation += f"""
{i+1}. [{f.get('severity', 'unknown')}] {f.get('title', 'Unknown')}
   - ç±»å‹: {f.get('vulnerability_type', 'unknown')}
   - æ–‡ä»¶: {f.get('file_path', 'unknown')}
   - æè¿°: {f.get('description', '')[:200]}...
"""
                
                if len(findings) > 10:
                    observation += f"\n... è¿˜æœ‰ {len(findings) - 10} ä¸ªå‘ç°"
                
                if result.data.get("summary"):
                    observation += f"\n\n### Agent æ€»ç»“\n{result.data['summary']}"
                
                return observation
            else:
                return f"## {agent_name} Agent æ‰§è¡Œå¤±è´¥\n\né”™è¯¯: {result.error}"
                
        except Exception as e:
            logger.error(f"Sub-agent dispatch failed: {e}", exc_info=True)
            return f"## è°ƒåº¦å¤±è´¥\n\né”™è¯¯: {str(e)}"
    
    def _summarize_findings(self) -> str:
        """æ±‡æ€»å½“å‰å‘ç°"""
        if not self._all_findings:
            return "ç›®å‰è¿˜æ²¡æœ‰å‘ç°ä»»ä½•æ¼æ´ã€‚"
        
        # ç»Ÿè®¡
        severity_counts = {"critical": 0, "high": 0, "medium": 0, "low": 0}
        type_counts = {}
        
        for f in self._all_findings:
            sev = f.get("severity", "low")
            severity_counts[sev] = severity_counts.get(sev, 0) + 1
            
            vtype = f.get("vulnerability_type", "other")
            type_counts[vtype] = type_counts.get(vtype, 0) + 1
        
        summary = f"""## å½“å‰å‘ç°æ±‡æ€»

**æ€»è®¡**: {len(self._all_findings)} ä¸ªæ¼æ´

### ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ
- Critical: {severity_counts['critical']}
- High: {severity_counts['high']}
- Medium: {severity_counts['medium']}
- Low: {severity_counts['low']}

### æ¼æ´ç±»å‹åˆ†å¸ƒ
"""
        for vtype, count in type_counts.items():
            summary += f"- {vtype}: {count}\n"
        
        summary += "\n### è¯¦ç»†åˆ—è¡¨\n"
        for i, f in enumerate(self._all_findings):
            summary += f"{i+1}. [{f.get('severity')}] {f.get('title')} ({f.get('file_path')})\n"
        
        return summary
    
    def _generate_default_summary(self) -> Dict[str, Any]:
        """ç”Ÿæˆé»˜è®¤æ‘˜è¦"""
        severity_counts = {"critical": 0, "high": 0, "medium": 0, "low": 0}
        
        for f in self._all_findings:
            sev = f.get("severity", "low")
            severity_counts[sev] = severity_counts.get(sev, 0) + 1
        
        return {
            "total_findings": len(self._all_findings),
            "severity_distribution": severity_counts,
            "conclusion": "å®¡è®¡å®Œæˆï¼ˆæœªé€šè¿‡ LLM ç”Ÿæˆç»“è®ºï¼‰",
        }
    
    def get_conversation_history(self) -> List[Dict[str, str]]:
        """è·å–å¯¹è¯å†å²"""
        return self._conversation_history
    
    def get_steps(self) -> List[AgentStep]:
        """è·å–æ‰§è¡Œæ­¥éª¤"""
        return self._steps
