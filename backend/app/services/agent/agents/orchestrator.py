"""
Orchestrator Agent (ç¼–æ’å±‚) - LLM é©±åŠ¨ç‰ˆ

LLM æ˜¯çœŸæ­£çš„å¤§è„‘ï¼Œå…¨ç¨‹å‚ä¸å†³ç­–ï¼
- LLM å†³å®šä¸‹ä¸€æ­¥åšä»€ä¹ˆ
- LLM å†³å®šè°ƒåº¦å“ªä¸ªå­ Agent
- LLM å†³å®šä½•æ—¶å®Œæˆ
- LLM æ ¹æ®ä¸­é—´ç»“æœåŠ¨æ€è°ƒæ•´ç­–ç•¥

ç±»å‹: Autonomous Agent with Dynamic Planning
"""

import asyncio
import json
import logging
import re
from typing import List, Dict, Any, Optional
from dataclasses import dataclass

from .base import BaseAgent, AgentConfig, AgentResult, AgentType, AgentPattern
from ..json_parser import AgentJsonParser

logger = logging.getLogger(__name__)


ORCHESTRATOR_SYSTEM_PROMPT = """ä½ æ˜¯ DeepAudit çš„ç¼–æ’ Agentï¼Œè´Ÿè´£**è‡ªä¸»**åè°ƒæ•´ä¸ªå®‰å…¨å®¡è®¡æµç¨‹ã€‚

## ä½ çš„è§’è‰²
ä½ æ˜¯æ•´ä¸ªå®¡è®¡æµç¨‹çš„**å¤§è„‘**ï¼Œä¸æ˜¯ä¸€ä¸ªæœºæ¢°æ‰§è¡Œè€…ã€‚ä½ éœ€è¦ï¼š
1. è‡ªä¸»æ€è€ƒå’Œå†³ç­–
2. æ ¹æ®è§‚å¯Ÿç»“æœåŠ¨æ€è°ƒæ•´ç­–ç•¥
3. å†³å®šä½•æ—¶è°ƒç”¨å“ªä¸ªå­ Agent
4. åˆ¤æ–­ä½•æ—¶å®¡è®¡å®Œæˆ

## ä½ å¯ä»¥è°ƒåº¦çš„å­ Agent
1. **recon**: ä¿¡æ¯æ”¶é›† Agent - åˆ†æé¡¹ç›®ç»“æ„ã€æŠ€æœ¯æ ˆã€å…¥å£ç‚¹
2. **analysis**: åˆ†æ Agent - æ·±åº¦ä»£ç å®¡è®¡ã€æ¼æ´æ£€æµ‹
3. **verification**: éªŒè¯ Agent - éªŒè¯å‘ç°çš„æ¼æ´ã€ç”Ÿæˆ PoC

## ä½ å¯ä»¥ä½¿ç”¨çš„æ“ä½œ

### 1. è°ƒåº¦å­ Agent
```
Action: dispatch_agent
Action Input: {"agent": "recon|analysis|verification", "task": "å…·ä½“ä»»åŠ¡æè¿°", "context": "ä»»åŠ¡ä¸Šä¸‹æ–‡"}
```

### 2. æ±‡æ€»å‘ç°
```
Action: summarize
Action Input: {"findings": [...], "analysis": "ä½ çš„åˆ†æ"}
```

### 3. å®Œæˆå®¡è®¡
```
Action: finish
Action Input: {"conclusion": "å®¡è®¡ç»“è®º", "findings": [...], "recommendations": [...]}
```

## å·¥ä½œæ–¹å¼
æ¯ä¸€æ­¥ï¼Œä½ éœ€è¦ï¼š

1. **Thought**: åˆ†æå½“å‰çŠ¶æ€ï¼Œæ€è€ƒä¸‹ä¸€æ­¥åº”è¯¥åšä»€ä¹ˆ
   - ç›®å‰æ”¶é›†åˆ°äº†ä»€ä¹ˆä¿¡æ¯ï¼Ÿ
   - è¿˜éœ€è¦äº†è§£ä»€ä¹ˆï¼Ÿ
   - åº”è¯¥æ·±å…¥åˆ†æå“ªäº›åœ°æ–¹ï¼Ÿ
   - æœ‰ä»€ä¹ˆå‘ç°éœ€è¦éªŒè¯ï¼Ÿ

2. **Action**: é€‰æ‹©ä¸€ä¸ªæ“ä½œ
3. **Action Input**: æä¾›æ“ä½œå‚æ•°

## è¾“å‡ºæ ¼å¼
æ¯ä¸€æ­¥å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ï¼š

```
Thought: [ä½ çš„æ€è€ƒè¿‡ç¨‹]
Action: [dispatch_agent|summarize|finish]
Action Input: [JSON å‚æ•°]
```

## å®¡è®¡ç­–ç•¥å»ºè®®
- å…ˆç”¨ recon Agent äº†è§£é¡¹ç›®å…¨è²Œï¼ˆåªéœ€è°ƒåº¦ä¸€æ¬¡ï¼‰
- æ ¹æ® recon ç»“æœï¼Œè®© analysis Agent é‡ç‚¹å®¡è®¡é«˜é£é™©åŒºåŸŸ
- å‘ç°å¯ç–‘æ¼æ´åï¼Œç”¨ verification Agent éªŒè¯
- éšæ—¶æ ¹æ®æ–°å‘ç°è°ƒæ•´ç­–ç•¥ï¼Œä¸è¦æœºæ¢°æ‰§è¡Œ
- å½“ä½ è®¤ä¸ºå®¡è®¡è¶³å¤Ÿå…¨é¢æ—¶ï¼Œé€‰æ‹© finish

## é‡è¦åŸåˆ™
1. **ä½ æ˜¯å¤§è„‘ï¼Œä¸æ˜¯æ‰§è¡Œå™¨** - æ¯ä¸€æ­¥éƒ½è¦æ€è€ƒ
2. **åŠ¨æ€è°ƒæ•´** - æ ¹æ®å‘ç°è°ƒæ•´ç­–ç•¥
3. **ä¸»åŠ¨å†³ç­–** - ä¸è¦ç­‰å¾…ï¼Œä¸»åŠ¨æ¨è¿›
4. **è´¨é‡ä¼˜å…ˆ** - å®å¯æ·±å…¥åˆ†æå‡ ä¸ªçœŸå®æ¼æ´ï¼Œä¸è¦æµ…å°è¾„æ­¢
5. **é¿å…é‡å¤** - æ¯ä¸ª Agent é€šå¸¸åªéœ€è¦è°ƒåº¦ä¸€æ¬¡ï¼Œå¦‚æœç»“æœä¸ç†æƒ³ï¼Œå°è¯•å…¶ä»– Agent æˆ–ç›´æ¥å®Œæˆå®¡è®¡

## å¤„ç†å­ Agent ç»“æœ
- å­ Agent è¿”å›çš„ Observation åŒ…å«å®ƒä»¬çš„åˆ†æç»“æœ
- å³ä½¿ç»“æœçœ‹èµ·æ¥ä¸å®Œæ•´ï¼Œä¹Ÿè¦åŸºäºå·²æœ‰ä¿¡æ¯ç»§ç»­æ¨è¿›
- ä¸è¦åå¤è°ƒåº¦åŒä¸€ä¸ª Agent æœŸæœ›å¾—åˆ°ä¸åŒç»“æœ
- å¦‚æœ recon å®Œæˆåï¼Œåº”è¯¥è°ƒåº¦ analysis è¿›è¡Œæ·±åº¦åˆ†æ
- å¦‚æœ analysis å®Œæˆåæœ‰å‘ç°ï¼Œå¯ä»¥è°ƒåº¦ verification éªŒè¯
- å¦‚æœæ²¡æœ‰æ›´å¤šå·¥ä½œè¦åšï¼Œä½¿ç”¨ finish ç»“æŸå®¡è®¡

ç°åœ¨ï¼ŒåŸºäºé¡¹ç›®ä¿¡æ¯å¼€å§‹ä½ çš„å®¡è®¡å·¥ä½œï¼"""


@dataclass
class AgentStep:
    """æ‰§è¡Œæ­¥éª¤"""
    thought: str
    action: str
    action_input: Dict[str, Any]
    observation: Optional[str] = None
    sub_agent_result: Optional[AgentResult] = None


class OrchestratorAgent(BaseAgent):
    """
    ç¼–æ’ Agent - LLM é©±åŠ¨ç‰ˆ
    
    LLM å…¨ç¨‹å‚ä¸å†³ç­–ï¼š
    1. LLM æ€è€ƒå½“å‰çŠ¶æ€
    2. LLM å†³å®šä¸‹ä¸€æ­¥æ“ä½œ
    3. æ‰§è¡Œæ“ä½œï¼Œè·å–ç»“æœ
    4. LLM åˆ†æç»“æœï¼Œå†³å®šä¸‹ä¸€æ­¥
    5. é‡å¤ç›´åˆ° LLM å†³å®šå®Œæˆ
    """
    
    def __init__(
        self,
        llm_service,
        tools: Dict[str, Any],
        event_emitter=None,
        sub_agents: Optional[Dict[str, BaseAgent]] = None,
    ):
        config = AgentConfig(
            name="Orchestrator",
            agent_type=AgentType.ORCHESTRATOR,
            pattern=AgentPattern.REACT,  # æ”¹ä¸º ReAct æ¨¡å¼ï¼
            max_iterations=20,
            system_prompt=ORCHESTRATOR_SYSTEM_PROMPT,
        )
        super().__init__(config, llm_service, tools, event_emitter)
        
        self.sub_agents = sub_agents or {}
        self._conversation_history: List[Dict[str, str]] = []
        self._steps: List[AgentStep] = []
        self._all_findings: List[Dict] = []
        
        # ğŸ”¥ å­˜å‚¨è¿è¡Œæ—¶ä¸Šä¸‹æ–‡ï¼Œç”¨äºä¼ é€’ç»™å­ Agent
        self._runtime_context: Dict[str, Any] = {}
        
        # ğŸ”¥ è·Ÿè¸ªå·²è°ƒåº¦çš„ Agent ä»»åŠ¡ï¼Œé¿å…é‡å¤è°ƒåº¦
        self._dispatched_tasks: Dict[str, int] = {}  # agent_name -> dispatch_count
    
    def register_sub_agent(self, name: str, agent: BaseAgent):
        """æ³¨å†Œå­ Agent"""
        self.sub_agents[name] = agent
    
    def cancel(self):
        """
        å–æ¶ˆæ‰§è¡Œ - åŒæ—¶å–æ¶ˆæ‰€æœ‰å­ Agent
        
        é‡å†™çˆ¶ç±»æ–¹æ³•ï¼Œç¡®ä¿å–æ¶ˆä¿¡å·ä¼ æ’­åˆ°æ‰€æœ‰å­ Agent
        """
        self._cancelled = True
        logger.info(f"[{self.name}] Cancel requested, propagating to {len(self.sub_agents)} sub-agents")
        
        # ğŸ”¥ ä¼ æ’­å–æ¶ˆä¿¡å·åˆ°æ‰€æœ‰å­ Agent
        for name, agent in self.sub_agents.items():
            if hasattr(agent, 'cancel'):
                agent.cancel()
                logger.info(f"[{self.name}] Cancelled sub-agent: {name}")
    
    async def run(self, input_data: Dict[str, Any]) -> AgentResult:
        """
        æ‰§è¡Œç¼–æ’ä»»åŠ¡ - LLM å…¨ç¨‹å‚ä¸ï¼
        
        Args:
            input_data: {
                "project_info": é¡¹ç›®ä¿¡æ¯,
                "config": å®¡è®¡é…ç½®,
                "project_root": é¡¹ç›®æ ¹ç›®å½•,
                "task_id": ä»»åŠ¡ID,
            }
        """
        import time
        start_time = time.time()
        
        project_info = input_data.get("project_info", {})
        config = input_data.get("config", {})
        
        # ğŸ”¥ ä¿å­˜è¿è¡Œæ—¶ä¸Šä¸‹æ–‡ï¼Œç”¨äºä¼ é€’ç»™å­ Agent
        self._runtime_context = {
            "project_info": project_info,
            "config": config,
            "project_root": input_data.get("project_root", project_info.get("root", ".")),
            "task_id": input_data.get("task_id"),
        }
        
        # æ„å»ºåˆå§‹æ¶ˆæ¯
        initial_message = self._build_initial_message(project_info, config)
        
        # åˆå§‹åŒ–å¯¹è¯å†å²
        self._conversation_history = [
            {"role": "system", "content": self.config.system_prompt},
            {"role": "user", "content": initial_message},
        ]
        
        self._steps = []
        self._all_findings = []
        final_result = None
        error_message = None  # ğŸ”¥ è·Ÿè¸ªé”™è¯¯ä¿¡æ¯
        
        await self.emit_thinking("ğŸ§  Orchestrator Agent å¯åŠ¨ï¼ŒLLM å¼€å§‹è‡ªä¸»ç¼–æ’å†³ç­–...")
        
        try:
            for iteration in range(self.config.max_iterations):
                if self.is_cancelled:
                    break
                
                self._iteration = iteration + 1
                
                # ğŸ”¥ å†æ¬¡æ£€æŸ¥å–æ¶ˆæ ‡å¿—ï¼ˆåœ¨LLMè°ƒç”¨ä¹‹å‰ï¼‰
                if self.is_cancelled:
                    await self.emit_thinking("ğŸ›‘ ä»»åŠ¡å·²å–æ¶ˆï¼Œåœæ­¢æ‰§è¡Œ")
                    break
                
                # è°ƒç”¨ LLM è¿›è¡Œæ€è€ƒå’Œå†³ç­–ï¼ˆæµå¼è¾“å‡ºï¼‰
                try:
                    llm_output, tokens_this_round = await self.stream_llm_call(
                        self._conversation_history,
                        temperature=0.1,
                        max_tokens=4096,  # ğŸ”¥ å¢åŠ åˆ° 4096ï¼Œé¿å…æˆªæ–­
                    )
                except asyncio.CancelledError:
                    logger.info(f"[{self.name}] LLM call cancelled")
                    break
                
                self._total_tokens += tokens_this_round
                
                # ğŸ”¥ æ£€æµ‹ç©ºå“åº”
                if not llm_output or not llm_output.strip():
                    logger.warning(f"[{self.name}] Empty LLM response")
                    empty_retry_count = getattr(self, '_empty_retry_count', 0) + 1
                    self._empty_retry_count = empty_retry_count
                    if empty_retry_count >= 3:
                        logger.error(f"[{self.name}] Too many empty responses, stopping")
                        error_message = "è¿ç»­æ”¶åˆ°ç©ºå“åº”ï¼Œåœæ­¢ç¼–æ’"
                        await self.emit_event("error", error_message)
                        break
                    self._conversation_history.append({
                        "role": "user",
                        "content": "Received empty response. Please output Thought + Action + Action Input.",
                    })
                    continue
                
                # é‡ç½®ç©ºå“åº”è®¡æ•°å™¨
                self._empty_retry_count = 0
                
                # è§£æ LLM çš„å†³ç­–
                step = self._parse_llm_response(llm_output)
                
                if not step:
                    # LLM è¾“å‡ºæ ¼å¼ä¸æ­£ç¡®ï¼Œæç¤ºé‡è¯•
                    format_retry_count = getattr(self, '_format_retry_count', 0) + 1
                    self._format_retry_count = format_retry_count
                    if format_retry_count >= 3:
                        logger.error(f"[{self.name}] Too many format errors, stopping")
                        error_message = "è¿ç»­æ ¼å¼é”™è¯¯ï¼Œåœæ­¢ç¼–æ’"
                        await self.emit_event("error", error_message)
                        break
                    await self.emit_llm_decision("æ ¼å¼é”™è¯¯", "éœ€è¦é‡æ–°è¾“å‡º")
                    self._conversation_history.append({
                        "role": "assistant",
                        "content": llm_output,
                    })
                    self._conversation_history.append({
                        "role": "user",
                        "content": "è¯·æŒ‰ç…§è§„å®šæ ¼å¼è¾“å‡ºï¼šThought + Action + Action Input",
                    })
                    continue
                
                # é‡ç½®æ ¼å¼é‡è¯•è®¡æ•°å™¨
                self._format_retry_count = 0
                
                self._steps.append(step)
                
                # ğŸ”¥ å‘å°„ LLM æ€è€ƒå†…å®¹äº‹ä»¶ - å±•ç¤ºç¼–æ’å†³ç­–çš„æ€è€ƒè¿‡ç¨‹
                if step.thought:
                    await self.emit_llm_thought(step.thought, iteration + 1)
                
                # æ·»åŠ  LLM å“åº”åˆ°å†å²
                self._conversation_history.append({
                    "role": "assistant",
                    "content": llm_output,
                })
                
                # æ‰§è¡Œ LLM å†³å®šçš„æ“ä½œ
                if step.action == "finish":
                    # ğŸ”¥ LLM å†³å®šå®Œæˆå®¡è®¡
                    await self.emit_llm_decision("å®Œæˆå®¡è®¡", "LLM åˆ¤æ–­å®¡è®¡å·²å……åˆ†å®Œæˆ")
                    await self.emit_llm_complete(
                        f"ç¼–æ’å®Œæˆï¼Œå‘ç° {len(self._all_findings)} ä¸ªæ¼æ´",
                        self._total_tokens
                    )
                    final_result = step.action_input
                    break
                
                elif step.action == "dispatch_agent":
                    # ğŸ”¥ LLM å†³å®šè°ƒåº¦å­ Agent
                    agent_name = step.action_input.get("agent", "unknown")
                    task_desc = step.action_input.get("task", "")
                    await self.emit_llm_decision(
                        f"è°ƒåº¦ {agent_name} Agent",
                        f"ä»»åŠ¡: {task_desc[:100]}"
                    )
                    await self.emit_llm_action("dispatch_agent", step.action_input)
                    
                    observation = await self._dispatch_agent(step.action_input)
                    step.observation = observation
                    
                    # ğŸ”¥ å­ Agent æ‰§è¡Œå®Œæˆåæ£€æŸ¥å–æ¶ˆçŠ¶æ€
                    if self.is_cancelled:
                        logger.info(f"[{self.name}] Cancelled after sub-agent dispatch")
                        break
                    
                    # ğŸ”¥ å‘å°„è§‚å¯Ÿäº‹ä»¶
                    await self.emit_llm_observation(observation)
                    
                elif step.action == "summarize":
                    # LLM è¦æ±‚æ±‡æ€»
                    await self.emit_llm_decision("æ±‡æ€»å‘ç°", "LLM è¯·æ±‚æŸ¥çœ‹å½“å‰å‘ç°æ±‡æ€»")
                    observation = self._summarize_findings()
                    step.observation = observation
                    await self.emit_llm_observation(observation)
                    
                else:
                    observation = f"æœªçŸ¥æ“ä½œ: {step.action}ï¼Œå¯ç”¨æ“ä½œ: dispatch_agent, summarize, finish"
                    await self.emit_llm_decision("æœªçŸ¥æ“ä½œ", observation)
                
                # æ·»åŠ è§‚å¯Ÿç»“æœåˆ°å†å²
                self._conversation_history.append({
                    "role": "user",
                    "content": f"Observation:\n{step.observation}",
                })
            
            # ç”Ÿæˆæœ€ç»ˆç»“æœ
            duration_ms = int((time.time() - start_time) * 1000)
            
            # ğŸ”¥ å¦‚æœè¢«å–æ¶ˆï¼Œè¿”å›å–æ¶ˆç»“æœ
            if self.is_cancelled:
                await self.emit_event(
                    "info",
                    f"ğŸ›‘ Orchestrator å·²å–æ¶ˆ: {len(self._all_findings)} ä¸ªå‘ç°, {self._iteration} è½®å†³ç­–"
                )
                return AgentResult(
                    success=False,
                    error="ä»»åŠ¡å·²å–æ¶ˆ",
                    data={
                        "findings": self._all_findings,
                        "steps": [
                            {
                                "thought": s.thought,
                                "action": s.action,
                                "action_input": s.action_input,
                                "observation": s.observation[:500] if s.observation else None,
                            }
                            for s in self._steps
                        ],
                    },
                    iterations=self._iteration,
                    tool_calls=self._tool_calls,
                    tokens_used=self._total_tokens,
                    duration_ms=duration_ms,
                )
            
            # ğŸ”¥ å¦‚æœæœ‰é”™è¯¯ï¼Œè¿”å›å¤±è´¥ç»“æœ
            if error_message:
                await self.emit_event(
                    "error",
                    f"âŒ Orchestrator å¤±è´¥: {error_message}"
                )
                return AgentResult(
                    success=False,
                    error=error_message,
                    data={
                        "findings": self._all_findings,
                        "steps": [
                            {
                                "thought": s.thought,
                                "action": s.action,
                                "action_input": s.action_input,
                                "observation": s.observation[:500] if s.observation else None,
                            }
                            for s in self._steps
                        ],
                    },
                    iterations=self._iteration,
                    tool_calls=self._tool_calls,
                    tokens_used=self._total_tokens,
                    duration_ms=duration_ms,
                )
            
            await self.emit_event(
                "info",
                f"ğŸ¯ Orchestrator å®Œæˆ: {len(self._all_findings)} ä¸ªå‘ç°, {self._iteration} è½®å†³ç­–"
            )
            
            return AgentResult(
                success=True,
                data={
                    "findings": self._all_findings,
                    "summary": final_result or self._generate_default_summary(),
                    "steps": [
                        {
                            "thought": s.thought,
                            "action": s.action,
                            "action_input": s.action_input,
                            "observation": s.observation[:500] if s.observation else None,
                        }
                        for s in self._steps
                    ],
                },
                iterations=self._iteration,
                tool_calls=self._tool_calls,
                tokens_used=self._total_tokens,
                duration_ms=duration_ms,
            )
            
        except Exception as e:
            logger.error(f"Orchestrator failed: {e}", exc_info=True)
            return AgentResult(
                success=False,
                error=str(e),
            )
    
    def _build_initial_message(
        self,
        project_info: Dict[str, Any],
        config: Dict[str, Any],
    ) -> str:
        """æ„å»ºåˆå§‹æ¶ˆæ¯"""
        msg = f"""è¯·å¼€å§‹å¯¹ä»¥ä¸‹é¡¹ç›®è¿›è¡Œå®‰å…¨å®¡è®¡ã€‚

## é¡¹ç›®ä¿¡æ¯
- åç§°: {project_info.get('name', 'unknown')}
- è¯­è¨€: {project_info.get('languages', [])}
- æ–‡ä»¶æ•°é‡: {project_info.get('file_count', 0)}
- ç›®å½•ç»“æ„: {json.dumps(project_info.get('structure', {}), ensure_ascii=False, indent=2)}

## ç”¨æˆ·é…ç½®
- ç›®æ ‡æ¼æ´: {config.get('target_vulnerabilities', ['all'])}
- éªŒè¯çº§åˆ«: {config.get('verification_level', 'sandbox')}
- æ’é™¤æ¨¡å¼: {config.get('exclude_patterns', [])}

## å¯ç”¨å­ Agent
{', '.join(self.sub_agents.keys()) if self.sub_agents else '(æš‚æ— å­ Agent)'}

è¯·å¼€å§‹ä½ çš„å®¡è®¡å·¥ä½œã€‚é¦–å…ˆæ€è€ƒåº”è¯¥å¦‚ä½•å¼€å±•ï¼Œç„¶åå†³å®šç¬¬ä¸€æ­¥åšä»€ä¹ˆã€‚"""
        
        return msg
    
    def _parse_llm_response(self, response: str) -> Optional[AgentStep]:
        """è§£æ LLM å“åº”"""
        # æå– Thought
        thought_match = re.search(r'Thought:\s*(.*?)(?=Action:|$)', response, re.DOTALL)
        thought = thought_match.group(1).strip() if thought_match else ""
        
        # æå– Action
        action_match = re.search(r'Action:\s*(\w+)', response)
        if not action_match:
            return None
        action = action_match.group(1).strip()
        
        # æå– Action Input
        input_match = re.search(r'Action Input:\s*(.*?)(?=Thought:|Observation:|$)', response, re.DOTALL)
        if not input_match:
            return None
        
        input_text = input_match.group(1).strip()
        # ç§»é™¤ markdown ä»£ç å—
        input_text = re.sub(r'```json\s*', '', input_text)
        input_text = re.sub(r'```\s*', '', input_text)
        
        # ä½¿ç”¨å¢å¼ºçš„ JSON è§£æå™¨
        action_input = AgentJsonParser.parse(
            input_text,
            default={"raw": input_text}
        )
        
        return AgentStep(
            thought=thought,
            action=action,
            action_input=action_input,
        )
    
    async def _dispatch_agent(self, params: Dict[str, Any]) -> str:
        """è°ƒåº¦å­ Agent"""
        agent_name = params.get("agent", "")
        task = params.get("task", "")
        context = params.get("context", "")
        
        agent = self.sub_agents.get(agent_name)
        
        if not agent:
            available = list(self.sub_agents.keys())
            return f"é”™è¯¯: Agent '{agent_name}' ä¸å­˜åœ¨ã€‚å¯ç”¨çš„ Agent: {available}"
        
        # ğŸ”¥ æ£€æŸ¥æ˜¯å¦é‡å¤è°ƒåº¦åŒä¸€ä¸ª Agent
        dispatch_count = self._dispatched_tasks.get(agent_name, 0)
        if dispatch_count >= 2:
            return f"""## âš ï¸ é‡å¤è°ƒåº¦è­¦å‘Š

ä½ å·²ç»è°ƒåº¦ {agent_name} Agent {dispatch_count} æ¬¡äº†ã€‚

å¦‚æœä¹‹å‰çš„è°ƒåº¦æ²¡æœ‰è¿”å›æœ‰ç”¨çš„ç»“æœï¼Œè¯·è€ƒè™‘ï¼š
1. å°è¯•è°ƒåº¦å…¶ä»– Agentï¼ˆå¦‚ analysis æˆ– verificationï¼‰
2. ä½¿ç”¨ finish æ“ä½œç»“æŸå®¡è®¡å¹¶æ±‡æ€»å·²æœ‰å‘ç°
3. æä¾›æ›´å…·ä½“çš„ä»»åŠ¡æè¿°

å½“å‰å·²æ”¶é›†çš„å‘ç°æ•°é‡: {len(self._all_findings)}
"""
        
        self._dispatched_tasks[agent_name] = dispatch_count + 1
        
        # ğŸ”¥ è®¾ç½®çˆ¶ Agent ID å¹¶æ³¨å†Œåˆ°æ³¨å†Œè¡¨ï¼ˆåŠ¨æ€ Agent æ ‘ï¼‰
        logger.info(f"[Orchestrator] å‡†å¤‡è°ƒåº¦ {agent_name} Agent, agent._registered={agent._registered}")
        agent.set_parent_id(self._agent_id)
        logger.info(f"[Orchestrator] è®¾ç½® parent_id å®Œæˆï¼Œå‡†å¤‡æ³¨å†Œ {agent_name}")
        agent._register_to_registry(task=task)
        logger.info(f"[Orchestrator] {agent_name} æ³¨å†Œå®Œæˆï¼Œagent._registered={agent._registered}")
        
        await self.emit_event(
            "dispatch",
            f"ğŸ“¤ è°ƒåº¦ {agent_name} Agent: {task[:100]}...",
            agent=agent_name,
            task=task,
        )
        
        self._tool_calls += 1
        
        try:
            # ğŸ”¥ æ„å»ºå­ Agent è¾“å…¥ - ä¼ é€’å®Œæ•´çš„è¿è¡Œæ—¶ä¸Šä¸‹æ–‡
            project_info = self._runtime_context.get("project_info", {}).copy()
            # ç¡®ä¿ project_info åŒ…å« root è·¯å¾„
            if "root" not in project_info:
                project_info["root"] = self._runtime_context.get("project_root", ".")
            
            sub_input = {
                "task": task,
                "task_context": context,
                "project_info": project_info,
                "config": self._runtime_context.get("config", {}),
                "project_root": self._runtime_context.get("project_root", "."),
                "previous_results": {
                    "findings": self._all_findings,  # ä¼ é€’å·²æ”¶é›†çš„å‘ç°
                },
            }
            
            # ğŸ”¥ æ‰§è¡Œå­ Agent å‰æ£€æŸ¥å–æ¶ˆçŠ¶æ€
            if self.is_cancelled:
                return f"## {agent_name} Agent æ‰§è¡Œå–æ¶ˆ\n\nä»»åŠ¡å·²è¢«ç”¨æˆ·å–æ¶ˆ"
            
            # æ‰§è¡Œå­ Agent
            result = await agent.run(sub_input)
            
            # ğŸ”¥ æ‰§è¡Œåå†æ¬¡æ£€æŸ¥å–æ¶ˆçŠ¶æ€
            if self.is_cancelled:
                return f"## {agent_name} Agent æ‰§è¡Œä¸­æ–­\n\nä»»åŠ¡å·²è¢«ç”¨æˆ·å–æ¶ˆ"
            
            # ğŸ”¥ å¤„ç†å­ Agent ç»“æœ - ä¸åŒ Agent è¿”å›ä¸åŒçš„æ•°æ®ç»“æ„
            if result.success and result.data:
                data = result.data
                
                # ğŸ”¥ æ”¶é›†å‘ç° - åªæ”¶é›†æ ¼å¼æ­£ç¡®çš„æ¼æ´å¯¹è±¡
                # findings å­—æ®µé€šå¸¸æ¥è‡ª Analysis/Verification Agentï¼Œæ˜¯æ¼æ´å¯¹è±¡æ•°ç»„
                # initial_findings æ¥è‡ª Recon Agentï¼Œå¯èƒ½æ˜¯å­—ç¬¦ä¸²æ•°ç»„ï¼ˆè§‚å¯Ÿï¼‰æˆ–å¯¹è±¡æ•°ç»„
                findings = data.get("findings", [])
                if findings:
                    # åªæ·»åŠ å­—å…¸æ ¼å¼çš„å‘ç°
                    valid_findings = [f for f in findings if isinstance(f, dict)]
                    self._all_findings.extend(valid_findings)
                
                await self.emit_event(
                    "dispatch_complete",
                    f"âœ… {agent_name} Agent å®Œæˆ",
                    agent=agent_name,
                    findings_count=len(findings),
                )
                
                # ğŸ”¥ æ ¹æ® Agent ç±»å‹æ„å»ºä¸åŒçš„è§‚å¯Ÿç»“æœ
                if agent_name == "recon":
                    # Recon Agent è¿”å›é¡¹ç›®ä¿¡æ¯
                    observation = f"""## Recon Agent æ‰§è¡Œç»“æœ

**çŠ¶æ€**: æˆåŠŸ
**è¿­ä»£æ¬¡æ•°**: {result.iterations}
**è€—æ—¶**: {result.duration_ms}ms

### é¡¹ç›®ç»“æ„
{json.dumps(data.get('project_structure', {}), ensure_ascii=False, indent=2)}

### æŠ€æœ¯æ ˆ
- è¯­è¨€: {data.get('tech_stack', {}).get('languages', [])}
- æ¡†æ¶: {data.get('tech_stack', {}).get('frameworks', [])}
- æ•°æ®åº“: {data.get('tech_stack', {}).get('databases', [])}

### å…¥å£ç‚¹ ({len(data.get('entry_points', []))} ä¸ª)
"""
                    for i, ep in enumerate(data.get('entry_points', [])[:10]):
                        if isinstance(ep, dict):
                            observation += f"{i+1}. [{ep.get('type', 'unknown')}] {ep.get('file', '')}:{ep.get('line', '')}\n"
                    
                    observation += f"""
### é«˜é£é™©åŒºåŸŸ
{data.get('high_risk_areas', [])}

### åˆæ­¥å‘ç° ({len(data.get('initial_findings', []))} ä¸ª)
"""
                    for finding in data.get('initial_findings', [])[:5]:
                        if isinstance(finding, str):
                            observation += f"- {finding}\n"
                        elif isinstance(finding, dict):
                            observation += f"- {finding.get('title', finding)}\n"
                    
                else:
                    # Analysis/Verification Agent è¿”å›æ¼æ´å‘ç°
                    observation = f"""## {agent_name} Agent æ‰§è¡Œç»“æœ

**çŠ¶æ€**: æˆåŠŸ
**å‘ç°æ•°é‡**: {len(findings)}
**è¿­ä»£æ¬¡æ•°**: {result.iterations}
**è€—æ—¶**: {result.duration_ms}ms

### å‘ç°æ‘˜è¦
"""
                    for i, f in enumerate(findings[:10]):
                        if not isinstance(f, dict):
                            continue
                        observation += f"""
{i+1}. [{f.get('severity', 'unknown')}] {f.get('title', 'Unknown')}
   - ç±»å‹: {f.get('vulnerability_type', 'unknown')}
   - æ–‡ä»¶: {f.get('file_path', 'unknown')}
   - æè¿°: {f.get('description', '')[:200]}...
"""
                    
                    if len(findings) > 10:
                        observation += f"\n... è¿˜æœ‰ {len(findings) - 10} ä¸ªå‘ç°"
                
                if data.get("summary"):
                    observation += f"\n\n### Agent æ€»ç»“\n{data['summary']}"
                
                return observation
            else:
                return f"## {agent_name} Agent æ‰§è¡Œå¤±è´¥\n\né”™è¯¯: {result.error}"
                
        except Exception as e:
            logger.error(f"Sub-agent dispatch failed: {e}", exc_info=True)
            return f"## è°ƒåº¦å¤±è´¥\n\né”™è¯¯: {str(e)}"
    
    def _summarize_findings(self) -> str:
        """æ±‡æ€»å½“å‰å‘ç°"""
        if not self._all_findings:
            return "ç›®å‰è¿˜æ²¡æœ‰å‘ç°ä»»ä½•æ¼æ´ã€‚"
        
        # ç»Ÿè®¡
        severity_counts = {"critical": 0, "high": 0, "medium": 0, "low": 0}
        type_counts = {}
        
        for f in self._all_findings:
            if not isinstance(f, dict):
                continue
                
            sev = f.get("severity", "low")
            severity_counts[sev] = severity_counts.get(sev, 0) + 1
            
            vtype = f.get("vulnerability_type", "other")
            type_counts[vtype] = type_counts.get(vtype, 0) + 1
        
        summary = f"""## å½“å‰å‘ç°æ±‡æ€»

**æ€»è®¡**: {len(self._all_findings)} ä¸ªæ¼æ´

### ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ
- Critical: {severity_counts['critical']}
- High: {severity_counts['high']}
- Medium: {severity_counts['medium']}
- Low: {severity_counts['low']}

### æ¼æ´ç±»å‹åˆ†å¸ƒ
"""
        for vtype, count in type_counts.items():
            summary += f"- {vtype}: {count}\n"
        
        summary += "\n### è¯¦ç»†åˆ—è¡¨\n"
        for i, f in enumerate(self._all_findings):
            if isinstance(f, dict):
                summary += f"{i+1}. [{f.get('severity')}] {f.get('title')} ({f.get('file_path')})\n"
        
        return summary
    
    def _generate_default_summary(self) -> Dict[str, Any]:
        """ç”Ÿæˆé»˜è®¤æ‘˜è¦"""
        severity_counts = {"critical": 0, "high": 0, "medium": 0, "low": 0}
        
        for f in self._all_findings:
            if isinstance(f, dict):
                sev = f.get("severity", "low")
                severity_counts[sev] = severity_counts.get(sev, 0) + 1
        
        return {
            "total_findings": len(self._all_findings),
            "severity_distribution": severity_counts,
            "conclusion": "å®¡è®¡å®Œæˆï¼ˆæœªé€šè¿‡ LLM ç”Ÿæˆç»“è®ºï¼‰",
        }
    
    def get_conversation_history(self) -> List[Dict[str, str]]:
        """è·å–å¯¹è¯å†å²"""
        return self._conversation_history
    
    def get_steps(self) -> List[AgentStep]:
        """è·å–æ‰§è¡Œæ­¥éª¤"""
        return self._steps
