"""
Orchestrator Agent (ç¼–æ’å±‚) - LLM é©±åŠ¨ç‰ˆ

LLM æ˜¯çœŸæ­£çš„å¤§è„‘ï¼Œå…¨ç¨‹å‚ä¸å†³ç­–ï¼
- LLM å†³å®šä¸‹ä¸€æ­¥åšä»€ä¹ˆ
- LLM å†³å®šè°ƒåº¦å“ªä¸ªå­ Agent
- LLM å†³å®šä½•æ—¶å®Œæˆ
- LLM æ ¹æ®ä¸­é—´ç»“æœåŠ¨æ€è°ƒæ•´ç­–ç•¥

ç±»å‹: Autonomous Agent with Dynamic Planning
"""

import asyncio
import json
import logging
import re
from typing import List, Dict, Any, Optional
from dataclasses import dataclass

from .base import BaseAgent, AgentConfig, AgentResult, AgentType, AgentPattern
from ..json_parser import AgentJsonParser
from ..prompts import MULTI_AGENT_RULES, CORE_SECURITY_PRINCIPLES

logger = logging.getLogger(__name__)


ORCHESTRATOR_SYSTEM_PROMPT = """ä½ æ˜¯ DeepAudit çš„ç¼–æ’ Agentï¼Œè´Ÿè´£**è‡ªä¸»**åè°ƒæ•´ä¸ªå®‰å…¨å®¡è®¡æµç¨‹ã€‚

## ä½ çš„è§’è‰²
ä½ æ˜¯æ•´ä¸ªå®¡è®¡æµç¨‹çš„**å¤§è„‘**ï¼Œä¸æ˜¯ä¸€ä¸ªæœºæ¢°æ‰§è¡Œè€…ã€‚ä½ éœ€è¦ï¼š
1. è‡ªä¸»æ€è€ƒå’Œå†³ç­–
2. æ ¹æ®è§‚å¯Ÿç»“æœåŠ¨æ€è°ƒæ•´ç­–ç•¥
3. å†³å®šä½•æ—¶è°ƒç”¨å“ªä¸ªå­ Agent
4. åˆ¤æ–­ä½•æ—¶å®¡è®¡å®Œæˆ

## ä½ å¯ä»¥è°ƒåº¦çš„å­ Agent
1. **recon**: ä¿¡æ¯æ”¶é›† Agent - åˆ†æé¡¹ç›®ç»“æ„ã€æŠ€æœ¯æ ˆã€å…¥å£ç‚¹
2. **analysis**: åˆ†æ Agent - æ·±åº¦ä»£ç å®¡è®¡ã€æ¼æ´æ£€æµ‹
3. **verification**: éªŒè¯ Agent - éªŒè¯å‘ç°çš„æ¼æ´ã€ç”Ÿæˆ PoC

## ä½ å¯ä»¥ä½¿ç”¨çš„æ“ä½œ

### 1. è°ƒåº¦å­ Agent
```
Action: dispatch_agent
Action Input: {"agent": "recon|analysis|verification", "task": "å…·ä½“ä»»åŠ¡æè¿°", "context": "ä»»åŠ¡ä¸Šä¸‹æ–‡"}
```

### 2. æ±‡æ€»å‘ç°
```
Action: summarize
Action Input: {"findings": [...], "analysis": "ä½ çš„åˆ†æ"}
```

### 3. å®Œæˆå®¡è®¡
```
Action: finish
Action Input: {"conclusion": "å®¡è®¡ç»“è®º", "findings": [...], "recommendations": [...]}
```

## å·¥ä½œæ–¹å¼
æ¯ä¸€æ­¥ï¼Œä½ éœ€è¦ï¼š

1. **Thought**: åˆ†æå½“å‰çŠ¶æ€ï¼Œæ€è€ƒä¸‹ä¸€æ­¥åº”è¯¥åšä»€ä¹ˆ
   - ç›®å‰æ”¶é›†åˆ°äº†ä»€ä¹ˆä¿¡æ¯ï¼Ÿ
   - è¿˜éœ€è¦äº†è§£ä»€ä¹ˆï¼Ÿ
   - åº”è¯¥æ·±å…¥åˆ†æå“ªäº›åœ°æ–¹ï¼Ÿ
   - æœ‰ä»€ä¹ˆå‘ç°éœ€è¦éªŒè¯ï¼Ÿ

2. **Action**: é€‰æ‹©ä¸€ä¸ªæ“ä½œ
3. **Action Input**: æä¾›æ“ä½œå‚æ•°

## è¾“å‡ºæ ¼å¼
æ¯ä¸€æ­¥å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ï¼š

```
Thought: [ä½ çš„æ€è€ƒè¿‡ç¨‹]
Action: [dispatch_agent|summarize|finish]
Action Input: [JSON å‚æ•°]
```

## å®¡è®¡ç­–ç•¥å»ºè®®
- å…ˆç”¨ recon Agent äº†è§£é¡¹ç›®å…¨è²Œï¼ˆåªéœ€è°ƒåº¦ä¸€æ¬¡ï¼‰
- æ ¹æ® recon ç»“æœï¼Œè®© analysis Agent é‡ç‚¹å®¡è®¡é«˜é£é™©åŒºåŸŸ
- å‘ç°å¯ç–‘æ¼æ´åï¼Œç”¨ verification Agent éªŒè¯
- éšæ—¶æ ¹æ®æ–°å‘ç°è°ƒæ•´ç­–ç•¥ï¼Œä¸è¦æœºæ¢°æ‰§è¡Œ
- å½“ä½ è®¤ä¸ºå®¡è®¡è¶³å¤Ÿå…¨é¢æ—¶ï¼Œé€‰æ‹© finish

## é‡è¦åŸåˆ™
1. **ä½ æ˜¯å¤§è„‘ï¼Œä¸æ˜¯æ‰§è¡Œå™¨** - æ¯ä¸€æ­¥éƒ½è¦æ€è€ƒ
2. **åŠ¨æ€è°ƒæ•´** - æ ¹æ®å‘ç°è°ƒæ•´ç­–ç•¥
3. **ä¸»åŠ¨å†³ç­–** - ä¸è¦ç­‰å¾…ï¼Œä¸»åŠ¨æ¨è¿›
4. **è´¨é‡ä¼˜å…ˆ** - å®å¯æ·±å…¥åˆ†æå‡ ä¸ªçœŸå®æ¼æ´ï¼Œä¸è¦æµ…å°è¾„æ­¢
5. **é¿å…é‡å¤** - æ¯ä¸ª Agent é€šå¸¸åªéœ€è¦è°ƒåº¦ä¸€æ¬¡ï¼Œå¦‚æœç»“æœä¸ç†æƒ³ï¼Œå°è¯•å…¶ä»– Agent æˆ–ç›´æ¥å®Œæˆå®¡è®¡

## å¤„ç†å­ Agent ç»“æœ
- å­ Agent è¿”å›çš„ Observation åŒ…å«å®ƒä»¬çš„åˆ†æç»“æœ
- å³ä½¿ç»“æœçœ‹èµ·æ¥ä¸å®Œæ•´ï¼Œä¹Ÿè¦åŸºäºå·²æœ‰ä¿¡æ¯ç»§ç»­æ¨è¿›
- ä¸è¦åå¤è°ƒåº¦åŒä¸€ä¸ª Agent æœŸæœ›å¾—åˆ°ä¸åŒç»“æœ
- å¦‚æœ recon å®Œæˆåï¼Œåº”è¯¥è°ƒåº¦ analysis è¿›è¡Œæ·±åº¦åˆ†æ
- å¦‚æœ analysis å®Œæˆåæœ‰å‘ç°ï¼Œå¯ä»¥è°ƒåº¦ verification éªŒè¯
- å¦‚æœæ²¡æœ‰æ›´å¤šå·¥ä½œè¦åšï¼Œä½¿ç”¨ finish ç»“æŸå®¡è®¡

ç°åœ¨ï¼ŒåŸºäºé¡¹ç›®ä¿¡æ¯å¼€å§‹ä½ çš„å®¡è®¡å·¥ä½œï¼"""


@dataclass
class AgentStep:
    """æ‰§è¡Œæ­¥éª¤"""
    thought: str
    action: str
    action_input: Dict[str, Any]
    observation: Optional[str] = None
    sub_agent_result: Optional[AgentResult] = None


class OrchestratorAgent(BaseAgent):
    """
    ç¼–æ’ Agent - LLM é©±åŠ¨ç‰ˆ
    
    LLM å…¨ç¨‹å‚ä¸å†³ç­–ï¼š
    1. LLM æ€è€ƒå½“å‰çŠ¶æ€
    2. LLM å†³å®šä¸‹ä¸€æ­¥æ“ä½œ
    3. æ‰§è¡Œæ“ä½œï¼Œè·å–ç»“æœ
    4. LLM åˆ†æç»“æœï¼Œå†³å®šä¸‹ä¸€æ­¥
    5. é‡å¤ç›´åˆ° LLM å†³å®šå®Œæˆ
    """
    
    def __init__(
        self,
        llm_service,
        tools: Dict[str, Any],
        event_emitter=None,
        sub_agents: Optional[Dict[str, BaseAgent]] = None,
        tracer=None,
    ):
        # ç»„åˆå¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯ï¼Œæ³¨å…¥å¤šAgentåä½œè§„åˆ™å’Œæ ¸å¿ƒå®‰å…¨åŸåˆ™
        full_system_prompt = f"{ORCHESTRATOR_SYSTEM_PROMPT}\n\n{CORE_SECURITY_PRINCIPLES}\n\n{MULTI_AGENT_RULES}"
        
        config = AgentConfig(
            name="Orchestrator",
            agent_type=AgentType.ORCHESTRATOR,
            pattern=AgentPattern.REACT,  # æ”¹ä¸º ReAct æ¨¡å¼ï¼
            max_iterations=20,
            system_prompt=full_system_prompt,
        )
        super().__init__(config, llm_service, tools, event_emitter)
        
        self.sub_agents = sub_agents or {}
        self._conversation_history: List[Dict[str, str]] = []
        self._steps: List[AgentStep] = []
        self._all_findings: List[Dict] = []
        
        # ğŸ”¥ Tracer é¥æµ‹æ”¯æŒ
        self.tracer = tracer
        
        # ğŸ”¥ å­˜å‚¨è¿è¡Œæ—¶ä¸Šä¸‹æ–‡ï¼Œç”¨äºä¼ é€’ç»™å­ Agent
        self._runtime_context: Dict[str, Any] = {}
        
        # ğŸ”¥ è·Ÿè¸ªå·²è°ƒåº¦çš„ Agent ä»»åŠ¡ï¼Œé¿å…é‡å¤è°ƒåº¦
        self._dispatched_tasks: Dict[str, int] = {}  # agent_name -> dispatch_count

        # ğŸ”¥ ä¿å­˜å„ä¸ª Agent çš„å®Œæ•´ç»“æœï¼Œç”¨äºä¼ é€’ç»™åç»­ Agent
        self._agent_results: Dict[str, Dict[str, Any]] = {}  # agent_name -> full result data
    
    def register_sub_agent(self, name: str, agent: BaseAgent):
        """æ³¨å†Œå­ Agent"""
        self.sub_agents[name] = agent
    
    def cancel(self):
        """
        å–æ¶ˆæ‰§è¡Œ - åŒæ—¶å–æ¶ˆæ‰€æœ‰å­ Agent
        
        é‡å†™çˆ¶ç±»æ–¹æ³•ï¼Œç¡®ä¿å–æ¶ˆä¿¡å·ä¼ æ’­åˆ°æ‰€æœ‰å­ Agent
        """
        self._cancelled = True
        logger.info(f"[{self.name}] Cancel requested, propagating to {len(self.sub_agents)} sub-agents")
        
        # ğŸ”¥ ä¼ æ’­å–æ¶ˆä¿¡å·åˆ°æ‰€æœ‰å­ Agent
        for name, agent in self.sub_agents.items():
            if hasattr(agent, 'cancel'):
                agent.cancel()
                logger.info(f"[{self.name}] Cancelled sub-agent: {name}")
    
    async def run(self, input_data: Dict[str, Any]) -> AgentResult:
        """
        æ‰§è¡Œç¼–æ’ä»»åŠ¡ - LLM å…¨ç¨‹å‚ä¸ï¼
        
        Args:
            input_data: {
                "project_info": é¡¹ç›®ä¿¡æ¯,
                "config": å®¡è®¡é…ç½®,
                "project_root": é¡¹ç›®æ ¹ç›®å½•,
                "task_id": ä»»åŠ¡ID,
            }
        """
        import time
        start_time = time.time()
        
        project_info = input_data.get("project_info", {})
        config = input_data.get("config", {})
        
        # ğŸ”¥ ä¿å­˜è¿è¡Œæ—¶ä¸Šä¸‹æ–‡ï¼Œç”¨äºä¼ é€’ç»™å­ Agent
        self._runtime_context = {
            "project_info": project_info,
            "config": config,
            "project_root": input_data.get("project_root", project_info.get("root", ".")),
            "task_id": input_data.get("task_id"),
        }
        
        # æ„å»ºåˆå§‹æ¶ˆæ¯
        initial_message = self._build_initial_message(project_info, config)
        
        # åˆå§‹åŒ–å¯¹è¯å†å²
        self._conversation_history = [
            {"role": "system", "content": self.config.system_prompt},
            {"role": "user", "content": initial_message},
        ]
        
        self._steps = []
        self._all_findings = []
        self._agent_results = {}  # ğŸ”¥ é‡ç½® Agent ç»“æœç¼“å­˜
        final_result = None
        error_message = None  # ğŸ”¥ è·Ÿè¸ªé”™è¯¯ä¿¡æ¯
        
        await self.emit_thinking("ğŸ§  Orchestrator Agent å¯åŠ¨ï¼ŒLLM å¼€å§‹è‡ªä¸»ç¼–æ’å†³ç­–...")
        
        try:
            for iteration in range(self.config.max_iterations):
                if self.is_cancelled:
                    break
                
                self._iteration = iteration + 1
                
                # ğŸ”¥ å†æ¬¡æ£€æŸ¥å–æ¶ˆæ ‡å¿—ï¼ˆåœ¨LLMè°ƒç”¨ä¹‹å‰ï¼‰
                if self.is_cancelled:
                    await self.emit_thinking("ğŸ›‘ ä»»åŠ¡å·²å–æ¶ˆï¼Œåœæ­¢æ‰§è¡Œ")
                    break
                
                # è°ƒç”¨ LLM è¿›è¡Œæ€è€ƒå’Œå†³ç­–ï¼ˆæµå¼è¾“å‡ºï¼‰
                try:
                    llm_output, tokens_this_round = await self.stream_llm_call(
                        self._conversation_history,
                        temperature=0.1,
                        max_tokens=4096,  # ğŸ”¥ å¢åŠ åˆ° 4096ï¼Œé¿å…æˆªæ–­
                    )
                except asyncio.CancelledError:
                    logger.info(f"[{self.name}] LLM call cancelled")
                    break
                
                self._total_tokens += tokens_this_round
                
                # ğŸ”¥ æ£€æµ‹ç©ºå“åº”
                if not llm_output or not llm_output.strip():
                    logger.warning(f"[{self.name}] Empty LLM response")
                    empty_retry_count = getattr(self, '_empty_retry_count', 0) + 1
                    self._empty_retry_count = empty_retry_count
                    if empty_retry_count >= 5:  # ğŸ”¥ å¢åŠ é‡è¯•æ¬¡æ•°åˆ°5æ¬¡
                        logger.error(f"[{self.name}] Too many empty responses, stopping")
                        error_message = "è¿ç»­æ”¶åˆ°ç©ºå“åº”ï¼Œåœæ­¢ç¼–æ’"
                        await self.emit_event("error", error_message)
                        break

                    # ğŸ”¥ æ·»åŠ çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…å¿«é€Ÿé‡è¯•
                    await asyncio.sleep(1.0)

                    # ğŸ”¥ æ›´è¯¦ç»†çš„é‡è¯•æç¤º
                    retry_prompt = f"""æ”¶åˆ°ç©ºå“åº”ï¼ˆç¬¬ {empty_retry_count} æ¬¡ï¼‰ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºä½ çš„å†³ç­–ï¼š

Thought: [ä½ å¯¹å½“å‰å®¡è®¡çŠ¶æ€çš„æ€è€ƒ]
Action: [dispatch_agent|summarize|finish]
Action Input: {{"å‚æ•°": "å€¼"}}

å½“å‰å¯è°ƒåº¦çš„å­ Agent: {list(self.sub_agents.keys())}
å½“å‰å·²æ”¶é›†å‘ç°: {len(self._all_findings)} ä¸ª

è¯·ç«‹å³è¾“å‡ºä½ çš„ä¸‹ä¸€æ­¥å†³ç­–ã€‚"""

                    self._conversation_history.append({
                        "role": "user",
                        "content": retry_prompt,
                    })
                    continue
                
                # é‡ç½®ç©ºå“åº”è®¡æ•°å™¨
                self._empty_retry_count = 0
                
                # è§£æ LLM çš„å†³ç­–
                step = self._parse_llm_response(llm_output)
                
                if not step:
                    # LLM è¾“å‡ºæ ¼å¼ä¸æ­£ç¡®ï¼Œæç¤ºé‡è¯•
                    format_retry_count = getattr(self, '_format_retry_count', 0) + 1
                    self._format_retry_count = format_retry_count
                    if format_retry_count >= 3:
                        logger.error(f"[{self.name}] Too many format errors, stopping")
                        error_message = "è¿ç»­æ ¼å¼é”™è¯¯ï¼Œåœæ­¢ç¼–æ’"
                        await self.emit_event("error", error_message)
                        break
                    await self.emit_llm_decision("æ ¼å¼é”™è¯¯", "éœ€è¦é‡æ–°è¾“å‡º")
                    self._conversation_history.append({
                        "role": "assistant",
                        "content": llm_output,
                    })
                    self._conversation_history.append({
                        "role": "user",
                        "content": "è¯·æŒ‰ç…§è§„å®šæ ¼å¼è¾“å‡ºï¼šThought + Action + Action Input",
                    })
                    continue
                
                # é‡ç½®æ ¼å¼é‡è¯•è®¡æ•°å™¨
                self._format_retry_count = 0
                
                self._steps.append(step)
                
                # ğŸ”¥ å‘å°„ LLM æ€è€ƒå†…å®¹äº‹ä»¶ - å±•ç¤ºç¼–æ’å†³ç­–çš„æ€è€ƒè¿‡ç¨‹
                if step.thought:
                    await self.emit_llm_thought(step.thought, iteration + 1)
                
                # æ·»åŠ  LLM å“åº”åˆ°å†å²
                self._conversation_history.append({
                    "role": "assistant",
                    "content": llm_output,
                })
                
                # æ‰§è¡Œ LLM å†³å®šçš„æ“ä½œ
                if step.action == "finish":
                    # ğŸ”¥ LLM å†³å®šå®Œæˆå®¡è®¡
                    await self.emit_llm_decision("å®Œæˆå®¡è®¡", "LLM åˆ¤æ–­å®¡è®¡å·²å……åˆ†å®Œæˆ")
                    await self.emit_llm_complete(
                        f"ç¼–æ’å®Œæˆï¼Œå‘ç° {len(self._all_findings)} ä¸ªæ¼æ´",
                        self._total_tokens
                    )
                    final_result = step.action_input
                    break
                
                elif step.action == "dispatch_agent":
                    # ğŸ”¥ LLM å†³å®šè°ƒåº¦å­ Agent
                    agent_name = step.action_input.get("agent", "unknown")
                    task_desc = step.action_input.get("task", "")
                    await self.emit_llm_decision(
                        f"è°ƒåº¦ {agent_name} Agent",
                        f"ä»»åŠ¡: {task_desc[:100]}"
                    )
                    await self.emit_llm_action("dispatch_agent", step.action_input)
                    
                    observation = await self._dispatch_agent(step.action_input)
                    step.observation = observation
                    
                    # ğŸ”¥ å­ Agent æ‰§è¡Œå®Œæˆåæ£€æŸ¥å–æ¶ˆçŠ¶æ€
                    if self.is_cancelled:
                        logger.info(f"[{self.name}] Cancelled after sub-agent dispatch")
                        break
                    
                    # ğŸ”¥ å‘å°„è§‚å¯Ÿäº‹ä»¶
                    await self.emit_llm_observation(observation)
                    
                elif step.action == "summarize":
                    # LLM è¦æ±‚æ±‡æ€»
                    await self.emit_llm_decision("æ±‡æ€»å‘ç°", "LLM è¯·æ±‚æŸ¥çœ‹å½“å‰å‘ç°æ±‡æ€»")
                    observation = self._summarize_findings()
                    step.observation = observation
                    await self.emit_llm_observation(observation)
                    
                else:
                    observation = f"æœªçŸ¥æ“ä½œ: {step.action}ï¼Œå¯ç”¨æ“ä½œ: dispatch_agent, summarize, finish"
                    await self.emit_llm_decision("æœªçŸ¥æ“ä½œ", observation)
                
                # æ·»åŠ è§‚å¯Ÿç»“æœåˆ°å†å²
                self._conversation_history.append({
                    "role": "user",
                    "content": f"Observation:\n{step.observation}",
                })
            
            # ç”Ÿæˆæœ€ç»ˆç»“æœ
            duration_ms = int((time.time() - start_time) * 1000)
            
            # ğŸ”¥ å¦‚æœè¢«å–æ¶ˆï¼Œè¿”å›å–æ¶ˆç»“æœ
            if self.is_cancelled:
                await self.emit_event(
                    "info",
                    f"ğŸ›‘ Orchestrator å·²å–æ¶ˆ: {len(self._all_findings)} ä¸ªå‘ç°, {self._iteration} è½®å†³ç­–"
                )
                return AgentResult(
                    success=False,
                    error="ä»»åŠ¡å·²å–æ¶ˆ",
                    data={
                        "findings": self._all_findings,
                        "steps": [
                            {
                                "thought": s.thought,
                                "action": s.action,
                                "action_input": s.action_input,
                                "observation": s.observation[:500] if s.observation else None,
                            }
                            for s in self._steps
                        ],
                    },
                    iterations=self._iteration,
                    tool_calls=self._tool_calls,
                    tokens_used=self._total_tokens,
                    duration_ms=duration_ms,
                )
            
            # ğŸ”¥ å¦‚æœæœ‰é”™è¯¯ï¼Œè¿”å›å¤±è´¥ç»“æœ
            if error_message:
                await self.emit_event(
                    "error",
                    f"âŒ Orchestrator å¤±è´¥: {error_message}"
                )
                return AgentResult(
                    success=False,
                    error=error_message,
                    data={
                        "findings": self._all_findings,
                        "steps": [
                            {
                                "thought": s.thought,
                                "action": s.action,
                                "action_input": s.action_input,
                                "observation": s.observation[:500] if s.observation else None,
                            }
                            for s in self._steps
                        ],
                    },
                    iterations=self._iteration,
                    tool_calls=self._tool_calls,
                    tokens_used=self._total_tokens,
                    duration_ms=duration_ms,
                )
            
            await self.emit_event(
                "info",
                f"ğŸ¯ Orchestrator å®Œæˆ: {len(self._all_findings)} ä¸ªå‘ç°, {self._iteration} è½®å†³ç­–"
            )

            # ğŸ”¥ CRITICAL: Log final findings count before returning
            logger.info(f"[Orchestrator] Final result: {len(self._all_findings)} findings collected")
            if len(self._all_findings) == 0:
                logger.warning(f"[Orchestrator] âš ï¸ No findings collected! Dispatched agents: {list(self._dispatched_tasks.keys())}, Iterations: {self._iteration}")
            for i, f in enumerate(self._all_findings[:5]):  # Log first 5 for debugging
                logger.debug(f"[Orchestrator] Finding {i+1}: {f.get('title', 'N/A')} - {f.get('vulnerability_type', 'N/A')}")

            return AgentResult(
                success=True,
                data={
                    "findings": self._all_findings,
                    "summary": final_result or self._generate_default_summary(),
                    "steps": [
                        {
                            "thought": s.thought,
                            "action": s.action,
                            "action_input": s.action_input,
                            "observation": s.observation[:500] if s.observation else None,
                        }
                        for s in self._steps
                    ],
                },
                iterations=self._iteration,
                tool_calls=self._tool_calls,
                tokens_used=self._total_tokens,
                duration_ms=duration_ms,
            )
            
        except Exception as e:
            logger.error(f"Orchestrator failed: {e}", exc_info=True)
            return AgentResult(
                success=False,
                error=str(e),
            )
    
    def _build_initial_message(
        self,
        project_info: Dict[str, Any],
        config: Dict[str, Any],
    ) -> str:
        """æ„å»ºåˆå§‹æ¶ˆæ¯"""
        structure = project_info.get('structure', {})
        
        # ğŸ”¥ æ£€æŸ¥æ˜¯å¦æ˜¯é™å®šèŒƒå›´çš„å®¡è®¡
        scope_limited = structure.get('scope_limited', False)
        scope_message = structure.get('scope_message', '')
        
        msg = f"""è¯·å¼€å§‹å¯¹ä»¥ä¸‹é¡¹ç›®è¿›è¡Œå®‰å…¨å®¡è®¡ã€‚

## é¡¹ç›®ä¿¡æ¯
- åç§°: {project_info.get('name', 'unknown')}
- è¯­è¨€: {project_info.get('languages', [])}
- æ–‡ä»¶æ•°é‡: {project_info.get('file_count', 0)}
"""
        
        # ğŸ”¥ æ ¹æ®æ˜¯å¦é™å®šèŒƒå›´æ˜¾ç¤ºä¸åŒçš„ç»“æ„ä¿¡æ¯
        if scope_limited:
            msg += f"""
## âš ï¸ å®¡è®¡èŒƒå›´é™å®š
**{scope_message}**

### ç›®æ ‡æ–‡ä»¶åˆ—è¡¨
"""
            for f in structure.get('files', []):
                msg += f"- {f}\n"
            
            if structure.get('directories'):
                msg += f"""
### ç›¸å…³ç›®å½•
{structure.get('directories', [])}
"""
        else:
            msg += f"""
## ç›®å½•ç»“æ„
{json.dumps(structure, ensure_ascii=False, indent=2)}
"""
        
        # ğŸ”¥ å¦‚æœé…ç½®äº† target_filesï¼Œä¹Ÿæ˜ç¡®æ˜¾ç¤º
        target_files = config.get('target_files', [])
        if target_files:
            msg += f"""
## âš ï¸ é‡è¦æç¤º
ç”¨æˆ·æŒ‡å®šäº† **{len(target_files)}** ä¸ªç›®æ ‡æ–‡ä»¶è¿›è¡Œå®¡è®¡ã€‚
è¯·ç¡®ä¿ä½ çš„åˆ†æé›†ä¸­åœ¨è¿™äº›æŒ‡å®šçš„æ–‡ä»¶ä¸Šï¼Œä¸è¦æµªè´¹æ—¶é—´åˆ†æå…¶ä»–æ–‡ä»¶ã€‚
"""
        
        msg += f"""
## ç”¨æˆ·é…ç½®
- ç›®æ ‡æ¼æ´: {config.get('target_vulnerabilities', ['all'])}
- éªŒè¯çº§åˆ«: {config.get('verification_level', 'sandbox')}
- æ’é™¤æ¨¡å¼: {config.get('exclude_patterns', [])}

## å¯ç”¨å­ Agent
{', '.join(self.sub_agents.keys()) if self.sub_agents else '(æš‚æ— å­ Agent)'}

è¯·å¼€å§‹ä½ çš„å®¡è®¡å·¥ä½œã€‚é¦–å…ˆæ€è€ƒåº”è¯¥å¦‚ä½•å¼€å±•ï¼Œç„¶åå†³å®šç¬¬ä¸€æ­¥åšä»€ä¹ˆã€‚"""
        
        return msg
    
    def _parse_llm_response(self, response: str) -> Optional[AgentStep]:
        """è§£æ LLM å“åº”"""
        # æå– Thought
        thought_match = re.search(r'Thought:\s*(.*?)(?=Action:|$)', response, re.DOTALL)
        thought = thought_match.group(1).strip() if thought_match else ""
        
        # æå– Action
        action_match = re.search(r'Action:\s*(\w+)', response)
        if not action_match:
            return None
        action = action_match.group(1).strip()
        
        # æå– Action Input
        input_match = re.search(r'Action Input:\s*(.*?)(?=Thought:|Observation:|$)', response, re.DOTALL)
        if not input_match:
            return None
        
        input_text = input_match.group(1).strip()
        # ç§»é™¤ markdown ä»£ç å—
        input_text = re.sub(r'```json\s*', '', input_text)
        input_text = re.sub(r'```\s*', '', input_text)
        
        # ä½¿ç”¨å¢å¼ºçš„ JSON è§£æå™¨
        action_input = AgentJsonParser.parse(
            input_text,
            default={"raw": input_text}
        )
        
        return AgentStep(
            thought=thought,
            action=action,
            action_input=action_input,
        )
    
    async def _dispatch_agent(self, params: Dict[str, Any]) -> str:
        """è°ƒåº¦å­ Agent"""
        agent_name = params.get("agent", "")
        task = params.get("task", "")
        context = params.get("context", "")
        
        logger.debug(f"[Orchestrator] _dispatch_agent è¢«è°ƒç”¨: agent_name='{agent_name}', task='{task[:50]}...'")
        
        # ğŸ”¥ å°è¯•å¤§å°å†™ä¸æ•æ„ŸåŒ¹é…
        agent = self.sub_agents.get(agent_name)
        if not agent:
            # å°è¯•å°å†™åŒ¹é…
            agent_name_lower = agent_name.lower()
            agent = self.sub_agents.get(agent_name_lower)
            if agent:
                agent_name = agent_name_lower
                logger.debug(f"[Orchestrator] ä½¿ç”¨å°å†™åŒ¹é…: {agent_name}")
        
        if not agent:
            available = list(self.sub_agents.keys())
            logger.warning(f"[Orchestrator] Agent '{agent_name}' ä¸å­˜åœ¨ï¼Œå¯ç”¨: {available}")
            return f"é”™è¯¯: Agent '{agent_name}' ä¸å­˜åœ¨ã€‚å¯ç”¨çš„ Agent: {available}"
        
        # ğŸ”¥ æ£€æŸ¥æ˜¯å¦é‡å¤è°ƒåº¦åŒä¸€ä¸ª Agent
        dispatch_count = self._dispatched_tasks.get(agent_name, 0)
        if dispatch_count >= 2:
            return f"""## âš ï¸ é‡å¤è°ƒåº¦è­¦å‘Š

ä½ å·²ç»è°ƒåº¦ {agent_name} Agent {dispatch_count} æ¬¡äº†ã€‚

å¦‚æœä¹‹å‰çš„è°ƒåº¦æ²¡æœ‰è¿”å›æœ‰ç”¨çš„ç»“æœï¼Œè¯·è€ƒè™‘ï¼š
1. å°è¯•è°ƒåº¦å…¶ä»– Agentï¼ˆå¦‚ analysis æˆ– verificationï¼‰
2. ä½¿ç”¨ finish æ“ä½œç»“æŸå®¡è®¡å¹¶æ±‡æ€»å·²æœ‰å‘ç°
3. æä¾›æ›´å…·ä½“çš„ä»»åŠ¡æè¿°

å½“å‰å·²æ”¶é›†çš„å‘ç°æ•°é‡: {len(self._all_findings)}
"""
        
        self._dispatched_tasks[agent_name] = dispatch_count + 1
        
        # ğŸ”¥ è®¾ç½®çˆ¶ Agent ID å¹¶æ³¨å†Œåˆ°æ³¨å†Œè¡¨ï¼ˆåŠ¨æ€ Agent æ ‘ï¼‰
        logger.debug(f"[Orchestrator] å‡†å¤‡è°ƒåº¦ {agent_name} Agent, agent._registered={agent._registered}")
        agent.set_parent_id(self._agent_id)
        logger.debug(f"[Orchestrator] è®¾ç½® parent_id å®Œæˆï¼Œå‡†å¤‡æ³¨å†Œ {agent_name}")
        agent._register_to_registry(task=task)
        logger.debug(f"[Orchestrator] {agent_name} æ³¨å†Œå®Œæˆï¼Œagent._registered={agent._registered}")
        
        await self.emit_event(
            "dispatch",
            f"ğŸ“¤ è°ƒåº¦ {agent_name} Agent: {task[:100]}...",
            agent=agent_name,
            task=task,
        )
        
        self._tool_calls += 1
        
        try:
            # ğŸ”¥ æ„å»ºå­ Agent è¾“å…¥ - ä¼ é€’å®Œæ•´çš„è¿è¡Œæ—¶ä¸Šä¸‹æ–‡
            project_info = self._runtime_context.get("project_info", {}).copy()
            # ç¡®ä¿ project_info åŒ…å« root è·¯å¾„
            if "root" not in project_info:
                project_info["root"] = self._runtime_context.get("project_root", ".")

            # ğŸ”¥ FIX: æ„å»ºå®Œæ•´çš„ previous_resultsï¼ŒåŒ…å«æ‰€æœ‰å·²æ‰§è¡Œ Agent çš„ç»“æœ
            previous_results = {
                "findings": self._all_findings,  # ä¼ é€’å·²æ”¶é›†çš„å‘ç°
            }

            # ğŸ”¥ å°†ä¹‹å‰ Agent çš„å®Œæ•´ç»“æœä¼ é€’ç»™åç»­ Agent
            for prev_agent, prev_data in self._agent_results.items():
                previous_results[prev_agent] = {"data": prev_data}

            sub_input = {
                "task": task,
                "task_context": context,
                "project_info": project_info,
                "config": self._runtime_context.get("config", {}),
                "project_root": self._runtime_context.get("project_root", "."),
                "previous_results": previous_results,
            }
            
            # ğŸ”¥ æ‰§è¡Œå­ Agent å‰æ£€æŸ¥å–æ¶ˆçŠ¶æ€
            if self.is_cancelled:
                return f"## {agent_name} Agent æ‰§è¡Œå–æ¶ˆ\n\nä»»åŠ¡å·²è¢«ç”¨æˆ·å–æ¶ˆ"
            
            # æ‰§è¡Œå­ Agent
            result = await agent.run(sub_input)
            
            # ğŸ”¥ æ‰§è¡Œåå†æ¬¡æ£€æŸ¥å–æ¶ˆçŠ¶æ€
            if self.is_cancelled:
                return f"## {agent_name} Agent æ‰§è¡Œä¸­æ–­\n\nä»»åŠ¡å·²è¢«ç”¨æˆ·å–æ¶ˆ"

            # ğŸ”¥ å¤„ç†å­ Agent ç»“æœ - ä¸åŒ Agent è¿”å›ä¸åŒçš„æ•°æ®ç»“æ„
            # ğŸ”¥ DEBUG: æ·»åŠ è¯Šæ–­æ—¥å¿—
            logger.info(f"[Orchestrator] Processing {agent_name} result: success={result.success}, data_type={type(result.data).__name__}, data_keys={list(result.data.keys()) if isinstance(result.data, dict) else 'N/A'}")

            if result.success and result.data:
                data = result.data

                # ğŸ”¥ FIX: ä¿å­˜ Agent çš„å®Œæ•´ç»“æœï¼Œä¾›åç»­ Agent ä½¿ç”¨
                self._agent_results[agent_name] = data
                logger.info(f"[Orchestrator] Saved {agent_name} result with keys: {list(data.keys())}")

                # ğŸ”¥ CRITICAL FIX: æ”¶é›†å‘ç° - æ”¯æŒå¤šç§å­—æ®µå
                # findings å­—æ®µé€šå¸¸æ¥è‡ª Analysis/Verification Agent
                # initial_findings æ¥è‡ª Recon Agent
                raw_findings = data.get("findings", [])
                logger.info(f"[Orchestrator] {agent_name} returned data with {len(raw_findings)} findings in 'findings' field")

                # ğŸ”¥ ENHANCED: Also check for initial_findings (from Recon) - æ”¹è¿›é€»è¾‘
                # å³ä½¿ findings ä¸ºç©ºåˆ—è¡¨ï¼Œä¹Ÿæ£€æŸ¥ initial_findings
                if "initial_findings" in data:
                    initial = data.get("initial_findings", [])
                    logger.info(f"[Orchestrator] {agent_name} has {len(initial)} initial_findings, types: {[type(f).__name__ for f in initial[:3]]}")
                    for f in initial:
                        if isinstance(f, dict):
                            # ğŸ”¥ Normalize finding format - å¤„ç† Recon è¿”å›çš„æ ¼å¼
                            normalized = self._normalize_finding(f)
                            if normalized not in raw_findings:
                                raw_findings.append(normalized)
                                logger.info(f"[Orchestrator] Added dict finding from initial_findings")
                        elif isinstance(f, str) and f.strip():
                            # ğŸ”¥ FIX: Convert string finding to dict format instead of skipping
                            # Recon Agent æœ‰æ—¶å€™ä¼šè¿”å›å­—ç¬¦ä¸²æ ¼å¼çš„å‘ç°
                            # å°è¯•ä»å­—ç¬¦ä¸²ä¸­æå–æ–‡ä»¶è·¯å¾„ï¼ˆæ ¼å¼å¦‚ "app.py:36 - æè¿°"ï¼‰
                            file_path = ""
                            line_start = 0
                            if ":" in f:
                                parts = f.split(":", 1)
                                potential_file = parts[0].strip()
                                # æ£€æŸ¥æ˜¯å¦åƒæ–‡ä»¶è·¯å¾„
                                if "." in potential_file and "/" not in potential_file[:3]:
                                    file_path = potential_file
                                    # å°è¯•æå–è¡Œå·
                                    if len(parts) > 1:
                                        remaining = parts[1].strip()
                                        line_match = remaining.split()[0] if remaining else ""
                                        if line_match.isdigit():
                                            line_start = int(line_match)

                            string_finding = {
                                "title": f[:100] if len(f) > 100 else f,
                                "description": f,
                                "file_path": file_path,
                                "line_start": line_start,
                                "severity": "medium",  # é»˜è®¤ä¸­ç­‰ä¸¥é‡åº¦ï¼ŒAnalysis ä¼šé‡æ–°è¯„ä¼°
                                "vulnerability_type": "potential_issue",
                                "source": "recon",
                                "needs_verification": True,
                                "confidence": 0.5,  # è¾ƒä½ç½®ä¿¡åº¦ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ†æ
                            }
                            logger.info(f"[Orchestrator] Converted string finding to dict: {f[:80]}... (file={file_path}, line={line_start})")
                            raw_findings.append(string_finding)
                else:
                    logger.info(f"[Orchestrator] {agent_name} has no 'initial_findings' key in data")

                # ğŸ”¥ Also check high_risk_areas from Recon for potential findings
                if agent_name == "recon" and "high_risk_areas" in data:
                    high_risk = data.get("high_risk_areas", [])
                    logger.info(f"[Orchestrator] {agent_name} identified {len(high_risk)} high risk areas")
                    # ğŸ”¥ FIX: å°† high_risk_areas ä¹Ÿè½¬æ¢ä¸ºå‘ç°
                    for area in high_risk:
                        if isinstance(area, str) and area.strip():
                            # å°è¯•ä»æè¿°ä¸­æå–æ–‡ä»¶è·¯å¾„å’Œæ¼æ´ç±»å‹
                            file_path = ""
                            line_start = 0
                            vuln_type = "potential_issue"

                            # ğŸ”¥ FIX: æ”¹è¿›æ–‡ä»¶è·¯å¾„æå–é€»è¾‘
                            # æ ¼å¼1: "file.py:36 - æè¿°" -> æå– file.py å’Œ 36
                            # æ ¼å¼2: "æè¿°æ€§æ–‡æœ¬" -> ä¸æå–æ–‡ä»¶è·¯å¾„
                            if ":" in area:
                                parts = area.split(":", 1)
                                potential_file = parts[0].strip()
                                # åªæœ‰å½“ parts[0] çœ‹èµ·æ¥åƒæ–‡ä»¶è·¯å¾„æ—¶æ‰æå–
                                # æ–‡ä»¶è·¯å¾„é€šå¸¸åŒ…å« . ä¸”æ²¡æœ‰ç©ºæ ¼ï¼ˆæˆ–åªåœ¨ç»“å°¾æœ‰æ‰©å±•åï¼‰
                                if ("." in potential_file and
                                    " " not in potential_file and
                                    len(potential_file) < 100 and
                                    any(potential_file.endswith(ext) for ext in ['.py', '.js', '.ts', '.java', '.go', '.php', '.rb', '.c', '.cpp', '.h'])):
                                    file_path = potential_file
                                    # å°è¯•æå–è¡Œå·
                                    if len(parts) > 1:
                                        remaining = parts[1].strip()
                                        line_match = remaining.split()[0] if remaining else ""
                                        if line_match.isdigit():
                                            line_start = int(line_match)

                            # æ¨æ–­æ¼æ´ç±»å‹
                            area_lower = area.lower()
                            if "command" in area_lower or "å‘½ä»¤" in area_lower or "subprocess" in area_lower:
                                vuln_type = "command_injection"
                            elif "sql" in area_lower:
                                vuln_type = "sql_injection"
                            elif "xss" in area_lower:
                                vuln_type = "xss"
                            elif "path" in area_lower or "traversal" in area_lower or "è·¯å¾„" in area_lower:
                                vuln_type = "path_traversal"
                            elif "ssrf" in area_lower:
                                vuln_type = "ssrf"
                            elif "secret" in area_lower or "å¯†é’¥" in area_lower or "key" in area_lower:
                                vuln_type = "hardcoded_secret"

                            high_risk_finding = {
                                "title": area[:100] if len(area) > 100 else area,
                                "description": area,
                                "file_path": file_path,
                                "line_start": line_start,
                                "severity": "high",  # é«˜é£é™©åŒºåŸŸé»˜è®¤é«˜ä¸¥é‡åº¦
                                "vulnerability_type": vuln_type,
                                "source": "recon_high_risk",
                                "needs_verification": True,
                                "confidence": 0.6,
                            }
                            raw_findings.append(high_risk_finding)
                            logger.info(f"[Orchestrator] Converted high_risk_area to finding: {area[:60]}... (file={file_path}, type={vuln_type})")

                # ğŸ”¥ åˆå§‹åŒ– valid_findingsï¼Œç¡®ä¿åç»­ä»£ç å¯ä»¥è®¿é—®
                valid_findings = []

                if raw_findings:
                    # åªæ·»åŠ å­—å…¸æ ¼å¼çš„å‘ç°
                    valid_findings = [f for f in raw_findings if isinstance(f, dict)]

                    logger.info(f"[Orchestrator] {agent_name} returned {len(valid_findings)} valid findings")

                    # ğŸ”¥ ENHANCED: Merge findings with better deduplication
                    for new_f in valid_findings:
                        # Normalize the finding first
                        normalized_new = self._normalize_finding(new_f)

                        # Create fingerprint for deduplication (file + description similarity)
                        new_file = normalized_new.get("file_path", "").lower().strip()
                        new_desc = (normalized_new.get("description", "") or "").lower()[:100]
                        new_type = (normalized_new.get("vulnerability_type", "") or "").lower()
                        new_line = normalized_new.get("line_start") or normalized_new.get("line", 0)

                        # Check if exists (more flexible matching)
                        found = False
                        for i, existing_f in enumerate(self._all_findings):
                            existing_file = (existing_f.get("file_path", "") or existing_f.get("file", "")).lower().strip()
                            existing_desc = (existing_f.get("description", "") or "").lower()[:100]
                            existing_type = (existing_f.get("vulnerability_type", "") or existing_f.get("type", "")).lower()
                            existing_line = existing_f.get("line_start") or existing_f.get("line", 0)

                            # Match if same file AND (same line OR similar description OR same vulnerability type)
                            same_file = new_file and existing_file and (
                                new_file == existing_file or
                                new_file.endswith(existing_file) or
                                existing_file.endswith(new_file)
                            )
                            same_line = new_line and existing_line and new_line == existing_line
                            similar_desc = new_desc and existing_desc and (
                                new_desc in existing_desc or existing_desc in new_desc
                            )
                            same_type = new_type and existing_type and (
                                new_type == existing_type or
                                (new_type in existing_type) or (existing_type in new_type)
                            )

                            if same_file and (same_line or similar_desc or same_type):
                                # Update existing with new info (e.g. verification results)
                                # Prefer verified data over unverified
                                merged = {**existing_f, **normalized_new}
                                # Keep the better title
                                if normalized_new.get("title") and len(normalized_new.get("title", "")) > len(existing_f.get("title", "")):
                                    merged["title"] = normalized_new["title"]
                                # Keep verified status if either is verified
                                if existing_f.get("is_verified") or normalized_new.get("is_verified"):
                                    merged["is_verified"] = True
                                self._all_findings[i] = merged
                                found = True
                                logger.info(f"[Orchestrator] Merged finding: {new_file}:{new_line} ({new_type})")
                                break

                        if not found:
                            self._all_findings.append(normalized_new)
                            logger.info(f"[Orchestrator] Added new finding: {new_file}:{new_line} ({new_type})")

                    logger.info(f"[Orchestrator] Total findings now: {len(self._all_findings)}")
                else:
                    logger.info(f"[Orchestrator] {agent_name} returned no findings")
                
                await self.emit_event(
                    "dispatch_complete",
                    f"âœ… {agent_name} Agent å®Œæˆ",
                    agent=agent_name,
                    findings_count=len(self._all_findings),  # ğŸ”¥ Use total findings count
                )
                
                # ğŸ”¥ æ ¹æ® Agent ç±»å‹æ„å»ºä¸åŒçš„è§‚å¯Ÿç»“æœ
                if agent_name == "recon":
                    # Recon Agent è¿”å›é¡¹ç›®ä¿¡æ¯
                    observation = f"""## Recon Agent æ‰§è¡Œç»“æœ

**çŠ¶æ€**: æˆåŠŸ
**è¿­ä»£æ¬¡æ•°**: {result.iterations}
**è€—æ—¶**: {result.duration_ms}ms

### é¡¹ç›®ç»“æ„
{json.dumps(data.get('project_structure', {}), ensure_ascii=False, indent=2)}

### æŠ€æœ¯æ ˆ
- è¯­è¨€: {data.get('tech_stack', {}).get('languages', [])}
- æ¡†æ¶: {data.get('tech_stack', {}).get('frameworks', [])}
- æ•°æ®åº“: {data.get('tech_stack', {}).get('databases', [])}

### å…¥å£ç‚¹ ({len(data.get('entry_points', []))} ä¸ª)
"""
                    for i, ep in enumerate(data.get('entry_points', [])[:10]):
                        if isinstance(ep, dict):
                            observation += f"{i+1}. [{ep.get('type', 'unknown')}] {ep.get('file', '')}:{ep.get('line', '')}\n"
                    
                    observation += f"""
### é«˜é£é™©åŒºåŸŸ
{data.get('high_risk_areas', [])}

### åˆæ­¥å‘ç° ({len(data.get('initial_findings', []))} ä¸ª)
"""
                    for finding in data.get('initial_findings', [])[:5]:
                        if isinstance(finding, str):
                            observation += f"- {finding}\n"
                        elif isinstance(finding, dict):
                            observation += f"- {finding.get('title', finding)}\n"
                    
                else:
                    # Analysis/Verification Agent è¿”å›æ¼æ´å‘ç°
                    observation = f"""## {agent_name} Agent æ‰§è¡Œç»“æœ

**çŠ¶æ€**: æˆåŠŸ
**å‘ç°æ•°é‡**: {len(valid_findings)}
**è¿­ä»£æ¬¡æ•°**: {result.iterations}
**è€—æ—¶**: {result.duration_ms}ms

### å‘ç°æ‘˜è¦
"""
                    for i, f in enumerate(valid_findings[:10]):
                        if not isinstance(f, dict):
                            continue
                        observation += f"""
{i+1}. [{f.get('severity', 'unknown')}] {f.get('title', 'Unknown')}
   - ç±»å‹: {f.get('vulnerability_type', 'unknown')}
   - æ–‡ä»¶: {f.get('file_path', 'unknown')}
   - æè¿°: {f.get('description', '')[:200]}...
"""

                    if len(valid_findings) > 10:
                        observation += f"\n... è¿˜æœ‰ {len(valid_findings) - 10} ä¸ªå‘ç°"
                
                if data.get("summary"):
                    observation += f"\n\n### Agent æ€»ç»“\n{data['summary']}"
                
                return observation
            else:
                return f"## {agent_name} Agent æ‰§è¡Œå¤±è´¥\n\né”™è¯¯: {result.error}"
                
        except Exception as e:
            logger.error(f"Sub-agent dispatch failed: {e}", exc_info=True)
            return f"## è°ƒåº¦å¤±è´¥\n\né”™è¯¯: {str(e)}"
    
    def _normalize_finding(self, finding: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ ‡å‡†åŒ–å‘ç°æ ¼å¼

        ä¸åŒ Agent å¯èƒ½è¿”å›ä¸åŒæ ¼å¼çš„å‘ç°ï¼Œè¿™ä¸ªæ–¹æ³•å°†å®ƒä»¬æ ‡å‡†åŒ–ä¸ºç»Ÿä¸€æ ¼å¼
        """
        normalized = dict(finding)  # å¤åˆ¶åŸå§‹æ•°æ®

        # ğŸ”¥ å¤„ç† location å­—æ®µ -> file_path + line_start
        if "location" in normalized and "file_path" not in normalized:
            location = normalized["location"]
            if isinstance(location, str) and ":" in location:
                parts = location.split(":")
                normalized["file_path"] = parts[0]
                try:
                    normalized["line_start"] = int(parts[1])
                except (ValueError, IndexError):
                    pass
            elif isinstance(location, str):
                normalized["file_path"] = location

        # ğŸ”¥ å¤„ç† file å­—æ®µ -> file_path
        if "file" in normalized and "file_path" not in normalized:
            normalized["file_path"] = normalized["file"]

        # ğŸ”¥ å¤„ç† line å­—æ®µ -> line_start
        if "line" in normalized and "line_start" not in normalized:
            normalized["line_start"] = normalized["line"]

        # ğŸ”¥ å¤„ç† type å­—æ®µ -> vulnerability_type
        if "type" in normalized and "vulnerability_type" not in normalized:
            # ä¸æ˜¯æ‰€æœ‰ type éƒ½æ˜¯æ¼æ´ç±»å‹ï¼Œæ¯”å¦‚ "Vulnerability" åªæ˜¯æ ‡è®°
            type_val = normalized["type"]
            if type_val and type_val.lower() not in ["vulnerability", "finding", "issue"]:
                normalized["vulnerability_type"] = type_val
            elif "description" in normalized:
                # å°è¯•ä»æè¿°ä¸­æ¨æ–­æ¼æ´ç±»å‹
                desc = normalized["description"].lower()
                if "command injection" in desc or "rce" in desc or "system(" in desc:
                    normalized["vulnerability_type"] = "command_injection"
                elif "sql injection" in desc or "sqli" in desc:
                    normalized["vulnerability_type"] = "sql_injection"
                elif "xss" in desc or "cross-site scripting" in desc:
                    normalized["vulnerability_type"] = "xss"
                elif "path traversal" in desc or "directory traversal" in desc:
                    normalized["vulnerability_type"] = "path_traversal"
                elif "ssrf" in desc:
                    normalized["vulnerability_type"] = "ssrf"
                elif "xxe" in desc:
                    normalized["vulnerability_type"] = "xxe"
                else:
                    normalized["vulnerability_type"] = "other"

        # ğŸ”¥ ç¡®ä¿ severity å­—æ®µå­˜åœ¨ä¸”ä¸ºå°å†™
        if "severity" in normalized:
            normalized["severity"] = str(normalized["severity"]).lower()
        else:
            normalized["severity"] = "medium"

        # ğŸ”¥ å¤„ç† risk å­—æ®µ -> severity
        if "risk" in normalized and "severity" not in normalized:
            normalized["severity"] = str(normalized["risk"]).lower()

        # ğŸ”¥ ç”Ÿæˆ title å¦‚æœä¸å­˜åœ¨
        if "title" not in normalized:
            vuln_type = normalized.get("vulnerability_type", "Unknown")
            file_path = normalized.get("file_path", "")
            if file_path:
                import os
                normalized["title"] = f"{vuln_type.replace('_', ' ').title()} in {os.path.basename(file_path)}"
            else:
                normalized["title"] = f"{vuln_type.replace('_', ' ').title()} Vulnerability"

        # ğŸ”¥ å¤„ç† code å­—æ®µ -> code_snippet
        if "code" in normalized and "code_snippet" not in normalized:
            normalized["code_snippet"] = normalized["code"]

        # ğŸ”¥ å¤„ç† recommendation -> suggestion
        if "recommendation" in normalized and "suggestion" not in normalized:
            normalized["suggestion"] = normalized["recommendation"]

        # ğŸ”¥ å¤„ç† impact -> æ·»åŠ åˆ° description
        if "impact" in normalized and normalized.get("description"):
            if "impact" not in normalized["description"].lower():
                normalized["description"] += f"\n\nImpact: {normalized['impact']}"

        return normalized

    def _summarize_findings(self) -> str:
        """æ±‡æ€»å½“å‰å‘ç°"""
        if not self._all_findings:
            return "ç›®å‰è¿˜æ²¡æœ‰å‘ç°ä»»ä½•æ¼æ´ã€‚"
        
        # ç»Ÿè®¡
        severity_counts = {"critical": 0, "high": 0, "medium": 0, "low": 0}
        type_counts = {}
        
        for f in self._all_findings:
            if not isinstance(f, dict):
                continue
                
            sev = f.get("severity", "low")
            severity_counts[sev] = severity_counts.get(sev, 0) + 1
            
            vtype = f.get("vulnerability_type", "other")
            type_counts[vtype] = type_counts.get(vtype, 0) + 1
        
        summary = f"""## å½“å‰å‘ç°æ±‡æ€»

**æ€»è®¡**: {len(self._all_findings)} ä¸ªæ¼æ´

### ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ
- Critical: {severity_counts['critical']}
- High: {severity_counts['high']}
- Medium: {severity_counts['medium']}
- Low: {severity_counts['low']}

### æ¼æ´ç±»å‹åˆ†å¸ƒ
"""
        for vtype, count in type_counts.items():
            summary += f"- {vtype}: {count}\n"
        
        summary += "\n### è¯¦ç»†åˆ—è¡¨\n"
        for i, f in enumerate(self._all_findings):
            if isinstance(f, dict):
                summary += f"{i+1}. [{f.get('severity')}] {f.get('title')} ({f.get('file_path')})\n"
        
        return summary
    
    def _generate_default_summary(self) -> Dict[str, Any]:
        """ç”Ÿæˆé»˜è®¤æ‘˜è¦"""
        severity_counts = {"critical": 0, "high": 0, "medium": 0, "low": 0}
        
        for f in self._all_findings:
            if isinstance(f, dict):
                sev = f.get("severity", "low")
                severity_counts[sev] = severity_counts.get(sev, 0) + 1
        
        return {
            "total_findings": len(self._all_findings),
            "severity_distribution": severity_counts,
            "conclusion": "å®¡è®¡å®Œæˆï¼ˆæœªé€šè¿‡ LLM ç”Ÿæˆç»“è®ºï¼‰",
        }
    
    def get_conversation_history(self) -> List[Dict[str, str]]:
        """è·å–å¯¹è¯å†å²"""
        return self._conversation_history
    
    def get_steps(self) -> List[AgentStep]:
        """è·å–æ‰§è¡Œæ­¥éª¤"""
        return self._steps
