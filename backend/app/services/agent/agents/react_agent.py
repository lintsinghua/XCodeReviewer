"""
çœŸæ­£çš„ ReAct Agent å®ç°
LLM æ˜¯å¤§è„‘ï¼Œå…¨ç¨‹å‚ä¸å†³ç­–ï¼

ReAct å¾ªç¯:
1. Thought: LLM æ€è€ƒå½“å‰çŠ¶æ€å’Œä¸‹ä¸€æ­¥
2. Action: LLM å†³å®šè°ƒç”¨å“ªä¸ªå·¥å…·
3. Observation: æ‰§è¡Œå·¥å…·ï¼Œè·å–ç»“æœ
4. é‡å¤ç›´åˆ° LLM å†³å®šå®Œæˆ
"""

import json
import logging
import re
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass

from .base import BaseAgent, AgentConfig, AgentResult, AgentType, AgentPattern

logger = logging.getLogger(__name__)


REACT_SYSTEM_PROMPT = """ä½ æ˜¯ DeepAudit å®‰å…¨å®¡è®¡ Agentï¼Œä¸€ä¸ªä¸“ä¸šçš„ä»£ç å®‰å…¨åˆ†æä¸“å®¶ã€‚

## ä½ çš„ä»»åŠ¡
å¯¹ç›®æ ‡é¡¹ç›®è¿›è¡Œå…¨é¢çš„å®‰å…¨å®¡è®¡ï¼Œå‘ç°æ½œåœ¨çš„å®‰å…¨æ¼æ´ã€‚

## ä½ çš„å·¥å…·
{tools_description}

## å·¥ä½œæ–¹å¼
ä½ éœ€è¦é€šè¿‡ **æ€è€ƒ-è¡ŒåŠ¨-è§‚å¯Ÿ** å¾ªç¯æ¥å®Œæˆä»»åŠ¡ï¼š

1. **Thought**: åˆ†æå½“å‰æƒ…å†µï¼Œæ€è€ƒä¸‹ä¸€æ­¥åº”è¯¥åšä»€ä¹ˆ
2. **Action**: é€‰æ‹©ä¸€ä¸ªå·¥å…·å¹¶æ‰§è¡Œ
3. **Observation**: è§‚å¯Ÿå·¥å…·è¿”å›çš„ç»“æœ
4. é‡å¤ä¸Šè¿°è¿‡ç¨‹ç›´åˆ°ä½ è®¤ä¸ºå®¡è®¡å®Œæˆ

## è¾“å‡ºæ ¼å¼
æ¯ä¸€æ­¥å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

```
Thought: [ä½ çš„æ€è€ƒè¿‡ç¨‹ï¼Œåˆ†æå½“å‰çŠ¶æ€ï¼Œå†³å®šä¸‹ä¸€æ­¥]
Action: [å·¥å…·åç§°]
Action Input: [å·¥å…·å‚æ•°ï¼ŒJSON æ ¼å¼]
```

å½“ä½ å®Œæˆåˆ†æåï¼Œè¾“å‡ºï¼š
```
Thought: [æ€»ç»“åˆ†æç»“æœ]
Final Answer: [JSON æ ¼å¼çš„æœ€ç»ˆå‘ç°]
```

## Final Answer æ ¼å¼
```json
{{
    "findings": [
        {{
            "vulnerability_type": "sql_injection",
            "severity": "high",
            "title": "SQL æ³¨å…¥æ¼æ´",
            "description": "è¯¦ç»†æè¿°",
            "file_path": "path/to/file.py",
            "line_start": 42,
            "code_snippet": "å±é™©ä»£ç ç‰‡æ®µ",
            "suggestion": "ä¿®å¤å»ºè®®"
        }}
    ],
    "summary": "å®¡è®¡æ€»ç»“"
}}
```

## å®¡è®¡ç­–ç•¥å»ºè®®
1. å…ˆç”¨ list_files äº†è§£é¡¹ç›®ç»“æ„
2. è¯†åˆ«å…³é”®æ–‡ä»¶ï¼ˆè·¯ç”±ã€æ§åˆ¶å™¨ã€æ•°æ®åº“æ“ä½œï¼‰
3. ä½¿ç”¨ search_code æœç´¢å±é™©æ¨¡å¼ï¼ˆeval, exec, query, innerHTML ç­‰ï¼‰
4. è¯»å–å¯ç–‘æ–‡ä»¶è¿›è¡Œæ·±åº¦åˆ†æ
5. å¦‚æœæœ‰ semgrepï¼Œç”¨å®ƒè¿›è¡Œå…¨é¢æ‰«æ

## é‡ç‚¹å…³æ³¨çš„æ¼æ´ç±»å‹
- SQL æ³¨å…¥ (query, execute, raw SQL)
- XSS (innerHTML, document.write, v-html)
- å‘½ä»¤æ³¨å…¥ (exec, system, subprocess, child_process)
- è·¯å¾„éå† (open, readFile, path concatenation)
- SSRF (requests, fetch, http client)
- ç¡¬ç¼–ç å¯†é’¥ (password, secret, api_key, token)
- ä¸å®‰å…¨çš„ååºåˆ—åŒ– (pickle, yaml.load, eval)

ç°åœ¨å¼€å§‹å®¡è®¡ï¼"""


@dataclass
class AgentStep:
    """Agent æ‰§è¡Œæ­¥éª¤"""
    thought: str
    action: Optional[str] = None
    action_input: Optional[Dict] = None
    observation: Optional[str] = None
    is_final: bool = False
    final_answer: Optional[Dict] = None


class ReActAgent(BaseAgent):
    """
    çœŸæ­£çš„ ReAct Agent
    
    LLM å…¨ç¨‹å‚ä¸å†³ç­–ï¼Œè‡ªä¸»é€‰æ‹©å·¥å…·å’Œåˆ†æç­–ç•¥
    """
    
    def __init__(
        self,
        llm_service,
        tools: Dict[str, Any],
        event_emitter=None,
        agent_type: AgentType = AgentType.ANALYSIS,
        max_iterations: int = 30,
    ):
        config = AgentConfig(
            name="ReActAgent",
            agent_type=agent_type,
            pattern=AgentPattern.REACT,
            max_iterations=max_iterations,
            system_prompt=REACT_SYSTEM_PROMPT,
        )
        super().__init__(config, llm_service, tools, event_emitter)
        
        self._conversation_history: List[Dict[str, str]] = []
        self._steps: List[AgentStep] = []
    
    def _get_tools_description(self) -> str:
        """ç”Ÿæˆå·¥å…·æè¿°"""
        descriptions = []
        
        for name, tool in self.tools.items():
            if name.startswith("_"):
                continue
            
            desc = f"### {name}\n"
            desc += f"{tool.description}\n"
            
            # æ·»åŠ å‚æ•°è¯´æ˜
            if hasattr(tool, 'args_schema') and tool.args_schema:
                schema = tool.args_schema.schema()
                properties = schema.get("properties", {})
                if properties:
                    desc += "å‚æ•°:\n"
                    for param_name, param_info in properties.items():
                        param_desc = param_info.get("description", "")
                        param_type = param_info.get("type", "string")
                        desc += f"  - {param_name} ({param_type}): {param_desc}\n"
            
            descriptions.append(desc)
        
        return "\n".join(descriptions)
    
    def _build_system_prompt(self, project_info: Dict, task_context: str = "") -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        tools_desc = self._get_tools_description()
        prompt = self.config.system_prompt.format(tools_description=tools_desc)
        
        if project_info:
            prompt += f"\n\n## é¡¹ç›®ä¿¡æ¯\n"
            prompt += f"- åç§°: {project_info.get('name', 'unknown')}\n"
            prompt += f"- è¯­è¨€: {', '.join(project_info.get('languages', ['unknown']))}\n"
            prompt += f"- æ–‡ä»¶æ•°: {project_info.get('file_count', 'unknown')}\n"
        
        if task_context:
            prompt += f"\n\n## ä»»åŠ¡ä¸Šä¸‹æ–‡\n{task_context}"
        
        return prompt
    
    def _parse_llm_response(self, response: str) -> AgentStep:
        """è§£æ LLM å“åº”"""
        step = AgentStep(thought="")
        
        # æå– Thought
        thought_match = re.search(r'Thought:\s*(.*?)(?=Action:|Final Answer:|$)', response, re.DOTALL)
        if thought_match:
            step.thought = thought_match.group(1).strip()
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ç»ˆç­”æ¡ˆ
        final_match = re.search(r'Final Answer:\s*(.*?)$', response, re.DOTALL)
        if final_match:
            step.is_final = True
            try:
                # å°è¯•æå– JSON
                answer_text = final_match.group(1).strip()
                # ç§»é™¤ markdown ä»£ç å—
                answer_text = re.sub(r'```json\s*', '', answer_text)
                answer_text = re.sub(r'```\s*', '', answer_text)
                step.final_answer = json.loads(answer_text)
            except json.JSONDecodeError:
                step.final_answer = {"raw_answer": final_match.group(1).strip()}
            return step
        
        # æå– Action
        action_match = re.search(r'Action:\s*(\w+)', response)
        if action_match:
            step.action = action_match.group(1).strip()
        
        # æå– Action Input
        input_match = re.search(r'Action Input:\s*(.*?)(?=Thought:|Action:|Observation:|$)', response, re.DOTALL)
        if input_match:
            input_text = input_match.group(1).strip()
            # ç§»é™¤ markdown ä»£ç å—
            input_text = re.sub(r'```json\s*', '', input_text)
            input_text = re.sub(r'```\s*', '', input_text)
            try:
                step.action_input = json.loads(input_text)
            except json.JSONDecodeError:
                # å°è¯•ç®€å•è§£æ
                step.action_input = {"raw_input": input_text}
        
        return step
    
    async def _execute_tool(self, tool_name: str, tool_input: Dict) -> str:
        """æ‰§è¡Œå·¥å…·"""
        tool = self.tools.get(tool_name)
        
        if not tool:
            return f"é”™è¯¯: å·¥å…· '{tool_name}' ä¸å­˜åœ¨ã€‚å¯ç”¨å·¥å…·: {list(self.tools.keys())}"
        
        try:
            self._tool_calls += 1
            await self.emit_tool_call(tool_name, tool_input)
            
            import time
            start = time.time()
            
            result = await tool.execute(**tool_input)
            
            duration_ms = int((time.time() - start) * 1000)
            await self.emit_tool_result(tool_name, str(result.data)[:200], duration_ms)
            
            if result.success:
                # æˆªæ–­è¿‡é•¿çš„è¾“å‡º
                output = str(result.data)
                if len(output) > 4000:
                    output = output[:4000] + "\n\n... [è¾“å‡ºå·²æˆªæ–­ï¼Œå…± {} å­—ç¬¦]".format(len(str(result.data)))
                return output
            else:
                return f"å·¥å…·æ‰§è¡Œå¤±è´¥: {result.error}"
                
        except Exception as e:
            logger.error(f"Tool execution error: {e}")
            return f"å·¥å…·æ‰§è¡Œé”™è¯¯: {str(e)}"
    
    async def run(self, input_data: Dict[str, Any]) -> AgentResult:
        """
        æ‰§è¡Œ ReAct Agent
        
        LLM å…¨ç¨‹å‚ä¸ï¼Œè‡ªä¸»å†³ç­–ï¼
        """
        import time
        start_time = time.time()
        
        project_info = input_data.get("project_info", {})
        task_context = input_data.get("task_context", "")
        config = input_data.get("config", {})
        
        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = self._build_system_prompt(project_info, task_context)
        
        # åˆå§‹åŒ–å¯¹è¯å†å²
        self._conversation_history = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": "è¯·å¼€å§‹å¯¹é¡¹ç›®è¿›è¡Œå®‰å…¨å®¡è®¡ã€‚é¦–å…ˆäº†è§£é¡¹ç›®ç»“æ„ï¼Œç„¶åç³»ç»Ÿæ€§åœ°æœç´¢å’Œåˆ†ææ½œåœ¨çš„å®‰å…¨æ¼æ´ã€‚"},
        ]
        
        self._steps = []
        all_findings = []
        
        await self.emit_thinking("ğŸ¤– ReAct Agent å¯åŠ¨ï¼ŒLLM å¼€å§‹è‡ªä¸»åˆ†æ...")
        
        try:
            for iteration in range(self.config.max_iterations):
                if self.is_cancelled:
                    break
                
                self._iteration = iteration + 1
                
                await self.emit_thinking(f"ğŸ’­ ç¬¬ {iteration + 1} è½®æ€è€ƒ...")
                
                # ğŸ”¥ è°ƒç”¨ LLM è¿›è¡Œæ€è€ƒå’Œå†³ç­–
                response = await self.llm_service.chat_completion_raw(
                    messages=self._conversation_history,
                    temperature=0.1,
                    max_tokens=2048,
                )
                
                llm_output = response.get("content", "")
                self._total_tokens += response.get("usage", {}).get("total_tokens", 0)
                
                # å‘å°„æ€è€ƒäº‹ä»¶
                await self.emit_event("thinking", f"LLM: {llm_output[:500]}...")
                
                # è§£æ LLM å“åº”
                step = self._parse_llm_response(llm_output)
                self._steps.append(step)
                
                # æ·»åŠ  LLM å“åº”åˆ°å†å²
                self._conversation_history.append({
                    "role": "assistant",
                    "content": llm_output,
                })
                
                # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                if step.is_final:
                    await self.emit_thinking("âœ… LLM å®Œæˆåˆ†æï¼Œç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
                    
                    if step.final_answer and "findings" in step.final_answer:
                        all_findings = step.final_answer["findings"]
                    break
                
                # æ‰§è¡Œå·¥å…·
                if step.action:
                    await self.emit_thinking(f"ğŸ”§ LLM å†³å®šè°ƒç”¨å·¥å…·: {step.action}")
                    
                    observation = await self._execute_tool(
                        step.action,
                        step.action_input or {}
                    )
                    
                    step.observation = observation
                    
                    # æ·»åŠ è§‚å¯Ÿç»“æœåˆ°å†å²
                    self._conversation_history.append({
                        "role": "user",
                        "content": f"Observation: {observation}",
                    })
                else:
                    # LLM æ²¡æœ‰é€‰æ‹©å·¥å…·ï¼Œæç¤ºå®ƒç»§ç»­
                    self._conversation_history.append({
                        "role": "user",
                        "content": "è¯·ç»§ç»­åˆ†æï¼Œé€‰æ‹©ä¸€ä¸ªå·¥å…·æ‰§è¡Œï¼Œæˆ–è€…å¦‚æœåˆ†æå®Œæˆï¼Œè¾“å‡º Final Answerã€‚",
                    })
            
            duration_ms = int((time.time() - start_time) * 1000)
            
            await self.emit_event(
                "info",
                f"ğŸ¯ ReAct Agent å®Œæˆ: {len(all_findings)} ä¸ªå‘ç°, {self._iteration} è½®è¿­ä»£, {self._tool_calls} æ¬¡å·¥å…·è°ƒç”¨"
            )
            
            return AgentResult(
                success=True,
                data={
                    "findings": all_findings,
                    "steps": [
                        {
                            "thought": s.thought,
                            "action": s.action,
                            "action_input": s.action_input,
                            "observation": s.observation[:500] if s.observation else None,
                        }
                        for s in self._steps
                    ],
                },
                iterations=self._iteration,
                tool_calls=self._tool_calls,
                tokens_used=self._total_tokens,
                duration_ms=duration_ms,
            )
            
        except Exception as e:
            logger.error(f"ReAct Agent failed: {e}", exc_info=True)
            return AgentResult(success=False, error=str(e))
    
    def get_conversation_history(self) -> List[Dict[str, str]]:
        """è·å–å¯¹è¯å†å²"""
        return self._conversation_history
    
    def get_steps(self) -> List[AgentStep]:
        """è·å–æ‰§è¡Œæ­¥éª¤"""
        return self._steps
