"""
Verification Agent (æ¼æ´éªŒè¯å±‚) - LLM é©±åŠ¨ç‰ˆ

LLM æ˜¯éªŒè¯çš„å¤§è„‘ï¼
- LLM å†³å®šå¦‚ä½•éªŒè¯æ¯ä¸ªæ¼æ´
- LLM æ„é€ éªŒè¯ç­–ç•¥
- LLM åˆ†æéªŒè¯ç»“æœ
- LLM åˆ¤æ–­æ˜¯å¦ä¸ºçœŸå®æ¼æ´

ç±»å‹: ReAct (çœŸæ­£çš„!)
"""

import asyncio
import json
import logging
import re
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from datetime import datetime, timezone

from .base import BaseAgent, AgentConfig, AgentResult, AgentType, AgentPattern
from ..json_parser import AgentJsonParser
from ..prompts import CORE_SECURITY_PRINCIPLES, VULNERABILITY_PRIORITIES

logger = logging.getLogger(__name__)



VERIFICATION_SYSTEM_PROMPT = """ä½ æ˜¯ DeepAudit çš„æ¼æ´éªŒè¯ Agentï¼Œä¸€ä¸ª**è‡ªä¸»**çš„å®‰å…¨éªŒè¯ä¸“å®¶ã€‚

## ä½ çš„è§’è‰²
ä½ æ˜¯æ¼æ´éªŒè¯çš„**å¤§è„‘**ï¼Œä¸æ˜¯æœºæ¢°éªŒè¯å™¨ã€‚ä½ éœ€è¦ï¼š
1. ç†è§£æ¯ä¸ªæ¼æ´çš„ä¸Šä¸‹æ–‡
2. è®¾è®¡åˆé€‚çš„éªŒè¯ç­–ç•¥
3. **ç¼–å†™æµ‹è¯•ä»£ç è¿›è¡ŒåŠ¨æ€éªŒè¯**
4. åˆ¤æ–­æ¼æ´æ˜¯å¦çœŸå®å­˜åœ¨
5. è¯„ä¼°å®é™…å½±å“å¹¶ç”Ÿæˆ PoC

## æ ¸å¿ƒç†å¿µï¼šFuzzing Harness
å³ä½¿æ•´ä¸ªé¡¹ç›®æ— æ³•è¿è¡Œï¼Œä½ ä¹Ÿåº”è¯¥èƒ½å¤ŸéªŒè¯æ¼æ´ï¼æ–¹æ³•æ˜¯ï¼š
1. **æå–ç›®æ ‡å‡½æ•°** - ä»ä»£ç ä¸­æå–å­˜åœ¨æ¼æ´çš„å‡½æ•°
2. **æ„å»º Mock** - æ¨¡æ‹Ÿå‡½æ•°ä¾èµ–ï¼ˆæ•°æ®åº“ã€HTTPã€æ–‡ä»¶ç³»ç»Ÿç­‰ï¼‰
3. **ç¼–å†™æµ‹è¯•è„šæœ¬** - æ„é€ å„ç§æ¶æ„è¾“å…¥æµ‹è¯•å‡½æ•°
4. **åˆ†ææ‰§è¡Œç»“æœ** - åˆ¤æ–­æ˜¯å¦è§¦å‘æ¼æ´

## ä½ å¯ä»¥ä½¿ç”¨çš„å·¥å…·

### ğŸ”¥ æ ¸å¿ƒéªŒè¯å·¥å…·ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
- **run_code**: æ‰§è¡Œä½ ç¼–å†™çš„æµ‹è¯•ä»£ç ï¼ˆæ”¯æŒ Python/PHP/JS/Ruby/Go/Java/Bashï¼‰
  - ç”¨äºè¿è¡Œ Fuzzing Harnessã€PoC è„šæœ¬
  - ä½ å¯ä»¥å®Œå…¨æ§åˆ¶æµ‹è¯•é€»è¾‘
  - å‚æ•°: code (str), language (str), timeout (int), description (str)

- **extract_function**: ä»æºæ–‡ä»¶æå–æŒ‡å®šå‡½æ•°ä»£ç 
  - ç”¨äºè·å–ç›®æ ‡å‡½æ•°ï¼Œæ„å»º Fuzzing Harness
  - å‚æ•°: file_path (str), function_name (str), include_imports (bool)

### æ–‡ä»¶æ“ä½œ
- **read_file**: è¯»å–ä»£ç æ–‡ä»¶è·å–ä¸Šä¸‹æ–‡
  å‚æ•°: file_path (str), start_line (int), end_line (int)

### æ²™ç®±å·¥å…·
- **sandbox_exec**: åœ¨æ²™ç®±ä¸­æ‰§è¡Œå‘½ä»¤ï¼ˆç”¨äºéªŒè¯å‘½ä»¤æ‰§è¡Œç±»æ¼æ´ï¼‰
- **sandbox_http**: å‘é€ HTTP è¯·æ±‚ï¼ˆå¦‚æœæœ‰è¿è¡Œçš„æœåŠ¡ï¼‰

## ğŸ”¥ Fuzzing Harness ç¼–å†™æŒ‡å—

### åŸåˆ™
1. **ä½ æ˜¯å¤§è„‘** - ä½ å†³å®šæµ‹è¯•ç­–ç•¥ã€payloadã€æ£€æµ‹æ–¹æ³•
2. **ä¸ä¾èµ–å®Œæ•´é¡¹ç›®** - æå–å‡½æ•°ï¼Œmock ä¾èµ–ï¼Œéš”ç¦»æµ‹è¯•
3. **å¤šç§ payload** - è®¾è®¡å¤šç§æ¶æ„è¾“å…¥ï¼Œä¸è¦åªæµ‹ä¸€ä¸ª
4. **æ£€æµ‹æ¼æ´ç‰¹å¾** - æ ¹æ®æ¼æ´ç±»å‹è®¾è®¡æ£€æµ‹é€»è¾‘

### å‘½ä»¤æ³¨å…¥ Fuzzing Harness ç¤ºä¾‹ (Python)
```python
import os
import subprocess

# === Mock å±é™©å‡½æ•°æ¥æ£€æµ‹è°ƒç”¨ ===
executed_commands = []
original_system = os.system

def mock_system(cmd):
    print(f"[DETECTED] os.system called: {cmd}")
    executed_commands.append(cmd)
    return 0

os.system = mock_system

# === ç›®æ ‡å‡½æ•°ï¼ˆä»é¡¹ç›®ä»£ç å¤åˆ¶ï¼‰ ===
def vulnerable_function(user_input):
    os.system(f"echo {user_input}")

# === Fuzzing æµ‹è¯• ===
payloads = [
    "test",           # æ­£å¸¸è¾“å…¥
    "; id",           # å‘½ä»¤è¿æ¥ç¬¦
    "| whoami",       # ç®¡é“
    "$(cat /etc/passwd)",  # å‘½ä»¤æ›¿æ¢
    "`id`",           # åå¼•å·
    "&& ls -la",      # AND è¿æ¥
]

print("=== Fuzzing Start ===")
for payload in payloads:
    print(f"\\nPayload: {payload}")
    executed_commands.clear()
    try:
        vulnerable_function(payload)
        if executed_commands:
            print(f"[VULN] Detected! Commands: {executed_commands}")
    except Exception as e:
        print(f"[ERROR] {e}")
```

### SQL æ³¨å…¥ Fuzzing Harness ç¤ºä¾‹ (Python)
```python
# === Mock æ•°æ®åº“ ===
class MockCursor:
    def __init__(self):
        self.queries = []

    def execute(self, query, params=None):
        print(f"[SQL] Query: {query}")
        print(f"[SQL] Params: {params}")
        self.queries.append((query, params))

        # æ£€æµ‹ SQL æ³¨å…¥ç‰¹å¾
        if params is None and ("'" in query or "OR" in query.upper() or "--" in query):
            print("[VULN] Possible SQL injection - no parameterized query!")

class MockDB:
    def cursor(self):
        return MockCursor()

# === ç›®æ ‡å‡½æ•° ===
def get_user(db, user_id):
    cursor = db.cursor()
    cursor.execute(f"SELECT * FROM users WHERE id = '{user_id}'")  # æ¼æ´ï¼

# === Fuzzing ===
db = MockDB()
payloads = ["1", "1'", "1' OR '1'='1", "1'; DROP TABLE users--", "1 UNION SELECT * FROM admin"]

for p in payloads:
    print(f"\\n=== Testing: {p} ===")
    get_user(db, p)
```

### PHP å‘½ä»¤æ³¨å…¥ Fuzzing Harness ç¤ºä¾‹
```php
// æ³¨æ„ï¼šphp -r ä¸éœ€è¦ <?php æ ‡ç­¾

// Mock $_GET
$_GET['cmd'] = '; id';
$_POST['cmd'] = '; id';
$_REQUEST['cmd'] = '; id';

// ç›®æ ‡ä»£ç ï¼ˆä»é¡¹ç›®å¤åˆ¶ï¼‰
$output = shell_exec($_GET['cmd']);
echo "Output: " . $output;

// å¦‚æœæœ‰è¾“å‡ºï¼Œè¯´æ˜å‘½ä»¤è¢«æ‰§è¡Œ
if ($output) {
    echo "\\n[VULN] Command executed!";
}
```

### XSS æ£€æµ‹ Harness ç¤ºä¾‹ (Python)
```python
def vulnerable_render(user_input):
    # æ¨¡æ‹Ÿæ¨¡æ¿æ¸²æŸ“
    return f"<div>Hello, {user_input}!</div>"

payloads = [
    "test",
    "<script>alert(1)</script>",
    "<img src=x onerror=alert(1)>",
    "{{7*7}}",  # SSTI
]

for p in payloads:
    output = vulnerable_render(p)
    print(f"Input: {p}")
    print(f"Output: {output}")
    # æ£€æµ‹ï¼špayload æ˜¯å¦åŸæ ·å‡ºç°åœ¨è¾“å‡ºä¸­
    if p in output and ("<" in p or "{{" in p):
        print("[VULN] XSS - input not escaped!")
```

## éªŒè¯ç­–ç•¥

### å¯¹äºå¯æ‰§è¡Œçš„æ¼æ´ï¼ˆå‘½ä»¤æ³¨å…¥ã€ä»£ç æ³¨å…¥ç­‰ï¼‰
1. ä½¿ç”¨ `extract_function` æˆ– `read_file` è·å–ç›®æ ‡ä»£ç 
2. ç¼–å†™ Fuzzing Harnessï¼Œmock å±é™©å‡½æ•°æ¥æ£€æµ‹è°ƒç”¨
3. ä½¿ç”¨ `run_code` æ‰§è¡Œ Harness
4. åˆ†æè¾“å‡ºï¼Œç¡®è®¤æ¼æ´æ˜¯å¦è§¦å‘

### å¯¹äºæ•°æ®æ³„éœ²å‹æ¼æ´ï¼ˆSQLæ³¨å…¥ã€è·¯å¾„éå†ç­‰ï¼‰
1. è·å–ç›®æ ‡ä»£ç 
2. ç¼–å†™ Harnessï¼Œmock æ•°æ®åº“/æ–‡ä»¶ç³»ç»Ÿ
3. æ£€æŸ¥æ˜¯å¦èƒ½æ„é€ æ¶æ„æŸ¥è¯¢/è·¯å¾„
4. åˆ†æè¾“å‡º

### å¯¹äºé…ç½®ç±»æ¼æ´ï¼ˆç¡¬ç¼–ç å¯†é’¥ç­‰ï¼‰
1. ä½¿ç”¨ `read_file` ç›´æ¥è¯»å–é…ç½®æ–‡ä»¶
2. éªŒè¯æ•æ„Ÿä¿¡æ¯æ˜¯å¦å­˜åœ¨
3. è¯„ä¼°å½±å“ï¼ˆå¯†é’¥æ˜¯å¦æœ‰æ•ˆã€æƒé™èŒƒå›´ç­‰ï¼‰

## å·¥ä½œæµç¨‹
ä½ å°†æ”¶åˆ°ä¸€æ‰¹å¾…éªŒè¯çš„æ¼æ´å‘ç°ã€‚å¯¹äºæ¯ä¸ªå‘ç°ï¼š

```
Thought: [åˆ†ææ¼æ´ç±»å‹ï¼Œè®¾è®¡éªŒè¯ç­–ç•¥]
Action: [å·¥å…·åç§°]
Action Input: [å‚æ•°]
```

éªŒè¯å®Œæ‰€æœ‰å‘ç°åï¼Œè¾“å‡ºï¼š

```
Thought: [æ€»ç»“éªŒè¯ç»“æœ]
Final Answer: [JSON æ ¼å¼çš„éªŒè¯æŠ¥å‘Š]
```

## âš ï¸ è¾“å‡ºæ ¼å¼è¦æ±‚ï¼ˆä¸¥æ ¼éµå®ˆï¼‰

**ç¦æ­¢ä½¿ç”¨ Markdown æ ¼å¼æ ‡è®°ï¼** ä½ çš„è¾“å‡ºå¿…é¡»æ˜¯çº¯æ–‡æœ¬æ ¼å¼ï¼š

âœ… æ­£ç¡®æ ¼å¼ï¼š
```
Thought: æˆ‘éœ€è¦è¯»å– search.php æ–‡ä»¶æ¥éªŒè¯ SQL æ³¨å…¥æ¼æ´ã€‚
Action: read_file
Action Input: {"file_path": "search.php"}
```

âŒ é”™è¯¯æ ¼å¼ï¼ˆç¦æ­¢ä½¿ç”¨ï¼‰ï¼š
```
**Thought:** æˆ‘éœ€è¦è¯»å–æ–‡ä»¶
**Action:** read_file
**Action Input:** {"file_path": "search.php"}
```

è§„åˆ™ï¼š
1. ä¸è¦åœ¨ Thought:ã€Action:ã€Action Input:ã€Final Answer: å‰åæ·»åŠ  `**`
2. ä¸è¦ä½¿ç”¨å…¶ä»– Markdown æ ¼å¼ï¼ˆå¦‚ `###`ã€`*æ–œä½“*` ç­‰ï¼‰
3. Action Input å¿…é¡»æ˜¯å®Œæ•´çš„ JSON å¯¹è±¡ï¼Œä¸èƒ½ä¸ºç©ºæˆ–æˆªæ–­

## Final Answer æ ¼å¼
```json
{
    "findings": [
        {
            ...åŸå§‹å‘ç°å­—æ®µ...,
            "verdict": "confirmed/likely/uncertain/false_positive",
            "confidence": 0.0-1.0,
            "is_verified": true/false,
            "verification_method": "æè¿°éªŒè¯æ–¹æ³•",
            "verification_details": "éªŒè¯è¿‡ç¨‹å’Œç»“æœè¯¦æƒ…",
            "poc": {
                "description": "PoC æè¿°",
                "steps": ["æ­¥éª¤1", "æ­¥éª¤2"],
                "payload": "å®Œæ•´å¯æ‰§è¡Œçš„ PoC ä»£ç æˆ–å‘½ä»¤",
                "harness_code": "Fuzzing Harness ä»£ç ï¼ˆå¦‚æœä½¿ç”¨ï¼‰"
            },
            "impact": "å®é™…å½±å“åˆ†æ",
            "recommendation": "ä¿®å¤å»ºè®®"
        }
    ],
    "summary": {
        "total": æ•°é‡,
        "confirmed": æ•°é‡,
        "likely": æ•°é‡,
        "false_positive": æ•°é‡
    }
}
```

## éªŒè¯åˆ¤å®šæ ‡å‡†
- **confirmed**: æ¼æ´ç¡®è®¤å­˜åœ¨ä¸”å¯åˆ©ç”¨ï¼Œæœ‰æ˜ç¡®è¯æ®ï¼ˆå¦‚ Harness æˆåŠŸè§¦å‘ï¼‰
- **likely**: é«˜åº¦å¯èƒ½å­˜åœ¨æ¼æ´ï¼Œä»£ç åˆ†ææ˜ç¡®ä½†æ— æ³•åŠ¨æ€éªŒè¯
- **uncertain**: éœ€è¦æ›´å¤šä¿¡æ¯æ‰èƒ½åˆ¤æ–­
- **false_positive**: ç¡®è®¤æ˜¯è¯¯æŠ¥ï¼Œæœ‰æ˜ç¡®ç†ç”±

## âš ï¸ å…³é”®çº¦æŸ
1. **å¿…é¡»å…ˆè°ƒç”¨å·¥å…·éªŒè¯** - ä¸å…è®¸ä»…å‡­å·²çŸ¥ä¿¡æ¯ç›´æ¥åˆ¤æ–­
2. **ä¼˜å…ˆä½¿ç”¨ run_code** - ç¼–å†™ Harness è¿›è¡ŒåŠ¨æ€éªŒè¯
3. **PoC å¿…é¡»å®Œæ•´å¯æ‰§è¡Œ** - poc.payload åº”è¯¥æ˜¯å¯ç›´æ¥è¿è¡Œçš„ä»£ç 
4. **ä¸è¦å‡è®¾ç¯å¢ƒ** - æ²™ç®±ä¸­æ²¡æœ‰è¿è¡Œçš„æœåŠ¡ï¼Œéœ€è¦ mock

## é‡è¦åŸåˆ™
1. **ä½ æ˜¯éªŒè¯çš„å¤§è„‘** - ä½ å†³å®šå¦‚ä½•æµ‹è¯•ï¼Œå·¥å…·åªæä¾›æ‰§è¡Œèƒ½åŠ›
2. **åŠ¨æ€éªŒè¯ä¼˜å…ˆ** - èƒ½è¿è¡Œä»£ç éªŒè¯çš„å°±ä¸è¦ä»…é é™æ€åˆ†æ
3. **è´¨é‡ä¼˜å…ˆ** - å®å¯æ¼æŠ¥ä¹Ÿä¸è¦è¯¯æŠ¥å¤ªå¤š
4. **è¯æ®æ”¯æ’‘** - æ¯ä¸ªåˆ¤å®šéƒ½éœ€è¦æœ‰ä¾æ®

ç°åœ¨å¼€å§‹éªŒè¯æ¼æ´å‘ç°ï¼"""


@dataclass
class VerificationStep:
    """éªŒè¯æ­¥éª¤"""
    thought: str
    action: Optional[str] = None
    action_input: Optional[Dict] = None
    observation: Optional[str] = None
    is_final: bool = False
    final_answer: Optional[Dict] = None


class VerificationAgent(BaseAgent):
    """
    æ¼æ´éªŒè¯ Agent - LLM é©±åŠ¨ç‰ˆ
    
    LLM å…¨ç¨‹å‚ä¸ï¼Œè‡ªä¸»å†³å®šï¼š
    1. å¦‚ä½•éªŒè¯æ¯ä¸ªæ¼æ´
    2. ä½¿ç”¨ä»€ä¹ˆå·¥å…·
    3. åˆ¤æ–­çœŸå‡
    """
    
    def __init__(
        self,
        llm_service,
        tools: Dict[str, Any],
        event_emitter=None,
    ):
        # ç»„åˆå¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯
        full_system_prompt = f"{VERIFICATION_SYSTEM_PROMPT}\n\n{CORE_SECURITY_PRINCIPLES}\n\n{VULNERABILITY_PRIORITIES}"
        
        config = AgentConfig(
            name="Verification",
            agent_type=AgentType.VERIFICATION,
            pattern=AgentPattern.REACT,
            max_iterations=25,
            system_prompt=full_system_prompt,
        )
        super().__init__(config, llm_service, tools, event_emitter)
        
        self._conversation_history: List[Dict[str, str]] = []
        self._steps: List[VerificationStep] = []



    
    def _parse_llm_response(self, response: str) -> VerificationStep:
        """è§£æ LLM å“åº” - å¢å¼ºç‰ˆï¼Œæ›´å¥å£®åœ°æå–æ€è€ƒå†…å®¹"""
        step = VerificationStep(thought="")

        # ğŸ”¥ v2.1: é¢„å¤„ç† - ç§»é™¤ Markdown æ ¼å¼æ ‡è®°ï¼ˆLLM æœ‰æ—¶ä¼šè¾“å‡º **Action:** è€Œé Action:ï¼‰
        cleaned_response = response
        cleaned_response = re.sub(r'\*\*Action:\*\*', 'Action:', cleaned_response)
        cleaned_response = re.sub(r'\*\*Action Input:\*\*', 'Action Input:', cleaned_response)
        cleaned_response = re.sub(r'\*\*Thought:\*\*', 'Thought:', cleaned_response)
        cleaned_response = re.sub(r'\*\*Final Answer:\*\*', 'Final Answer:', cleaned_response)
        cleaned_response = re.sub(r'\*\*Observation:\*\*', 'Observation:', cleaned_response)

        # ğŸ”¥ é¦–å…ˆå°è¯•æå–æ˜ç¡®çš„ Thought æ ‡è®°
        thought_match = re.search(r'Thought:\s*(.*?)(?=Action:|Final Answer:|$)', cleaned_response, re.DOTALL)
        if thought_match:
            step.thought = thought_match.group(1).strip()

        # ğŸ”¥ æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ç»ˆç­”æ¡ˆ
        final_match = re.search(r'Final Answer:\s*(.*?)$', cleaned_response, re.DOTALL)
        if final_match:
            step.is_final = True
            answer_text = final_match.group(1).strip()
            answer_text = re.sub(r'```json\s*', '', answer_text)
            answer_text = re.sub(r'```\s*', '', answer_text)
            # ä½¿ç”¨å¢å¼ºçš„ JSON è§£æå™¨
            step.final_answer = AgentJsonParser.parse(
                answer_text,
                default={"findings": [], "raw_answer": answer_text}
            )
            # ç¡®ä¿ findings æ ¼å¼æ­£ç¡®
            if "findings" in step.final_answer:
                step.final_answer["findings"] = [
                    f for f in step.final_answer["findings"]
                    if isinstance(f, dict)
                ]

            # ğŸ”¥ å¦‚æœæ²¡æœ‰æå–åˆ° thoughtï¼Œä½¿ç”¨ Final Answer å‰çš„å†…å®¹ä½œä¸ºæ€è€ƒ
            if not step.thought:
                before_final = cleaned_response[:cleaned_response.find('Final Answer:')].strip()
                if before_final:
                    before_final = re.sub(r'^Thought:\s*', '', before_final)
                    step.thought = before_final[:500] if len(before_final) > 500 else before_final

            return step

        # ğŸ”¥ æå– Action
        action_match = re.search(r'Action:\s*(\w+)', cleaned_response)
        if action_match:
            step.action = action_match.group(1).strip()

            # ğŸ”¥ å¦‚æœæ²¡æœ‰æå–åˆ° thoughtï¼Œæå– Action ä¹‹å‰çš„å†…å®¹ä½œä¸ºæ€è€ƒ
            if not step.thought:
                action_pos = cleaned_response.find('Action:')
                if action_pos > 0:
                    before_action = cleaned_response[:action_pos].strip()
                    before_action = re.sub(r'^Thought:\s*', '', before_action)
                    if before_action:
                        step.thought = before_action[:500] if len(before_action) > 500 else before_action

        # ğŸ”¥ æå– Action Input - å¢å¼ºç‰ˆï¼Œå¤„ç†å¤šç§æ ¼å¼
        input_match = re.search(r'Action Input:\s*(.*?)(?=Thought:|Action:|Observation:|$)', cleaned_response, re.DOTALL)
        if input_match:
            input_text = input_match.group(1).strip()
            input_text = re.sub(r'```json\s*', '', input_text)
            input_text = re.sub(r'```\s*', '', input_text)

            # ğŸ”¥ v2.1: å¦‚æœ Action Input ä¸ºç©ºæˆ–åªæœ‰ **ï¼Œè®°å½•è­¦å‘Š
            if not input_text or input_text == '**' or input_text.strip() == '':
                logger.warning(f"[Verification] Action Input is empty or malformed: '{input_text}'")
                step.action_input = {}
            else:
                # ä½¿ç”¨å¢å¼ºçš„ JSON è§£æå™¨
                step.action_input = AgentJsonParser.parse(
                    input_text,
                    default={"raw_input": input_text}
                )
        elif step.action:
            # ğŸ”¥ v2.1: æœ‰ Action ä½†æ²¡æœ‰ Action Inputï¼Œè®°å½•è­¦å‘Š
            logger.warning(f"[Verification] Action '{step.action}' found but no Action Input")
            step.action_input = {}

        # ğŸ”¥ æœ€åçš„ fallbackï¼šå¦‚æœæ•´ä¸ªå“åº”æ²¡æœ‰ä»»ä½•æ ‡è®°ï¼Œæ•´ä½“ä½œä¸ºæ€è€ƒ
        if not step.thought and not step.action and not step.is_final:
            if response.strip():
                step.thought = response.strip()[:500]

        return step
    
    async def run(self, input_data: Dict[str, Any]) -> AgentResult:
        """
        æ‰§è¡Œæ¼æ´éªŒè¯ - LLM å…¨ç¨‹å‚ä¸ï¼
        """
        import time
        start_time = time.time()
        
        previous_results = input_data.get("previous_results", {})
        config = input_data.get("config", {})
        task = input_data.get("task", "")
        task_context = input_data.get("task_context", "")
        
        # ğŸ”¥ å¤„ç†äº¤æ¥ä¿¡æ¯
        handoff = input_data.get("handoff")
        if handoff:
            from .base import TaskHandoff
            if isinstance(handoff, dict):
                handoff = TaskHandoff.from_dict(handoff)
            self.receive_handoff(handoff)
        
        # æ”¶é›†æ‰€æœ‰å¾…éªŒè¯çš„å‘ç°
        findings_to_verify = []
        
        # ğŸ”¥ ä¼˜å…ˆä»äº¤æ¥ä¿¡æ¯è·å–å‘ç°
        if self._incoming_handoff and self._incoming_handoff.key_findings:
            findings_to_verify = self._incoming_handoff.key_findings.copy()
            logger.info(f"[Verification] ä»äº¤æ¥ä¿¡æ¯è·å– {len(findings_to_verify)} ä¸ªå‘ç°")
        else:
            # ğŸ”¥ ä¿®å¤ï¼šå¤„ç† Orchestrator ä¼ é€’çš„å¤šç§æ•°æ®æ ¼å¼
            
            # æ ¼å¼1: Orchestrator ç›´æ¥ä¼ é€’ {"findings": [...]}
            if isinstance(previous_results, dict) and "findings" in previous_results:
                direct_findings = previous_results.get("findings", [])
                if isinstance(direct_findings, list):
                    for f in direct_findings:
                        if isinstance(f, dict):
                            # ğŸ”¥ Always verify Critical/High findings to generate PoC, even if Analysis sets needs_verification=False
                            severity = str(f.get("severity", "")).lower()
                            needs_verify = f.get("needs_verification", True)
                            
                            if needs_verify or severity in ["critical", "high"]:
                                findings_to_verify.append(f)
                    logger.info(f"[Verification] ä» previous_results.findings è·å– {len(findings_to_verify)} ä¸ªå‘ç°")
            
            # æ ¼å¼2: ä¼ ç»Ÿæ ¼å¼ {"phase_name": {"data": {"findings": [...]}}}
            if not findings_to_verify:
                for phase_name, result in previous_results.items():
                    if phase_name == "findings":
                        continue  # å·²å¤„ç†
                    
                    if isinstance(result, dict):
                        data = result.get("data", {})
                    else:
                        data = result.data if hasattr(result, 'data') else {}
                    
                    if isinstance(data, dict):
                        phase_findings = data.get("findings", [])
                        for f in phase_findings:
                            if isinstance(f, dict):
                                severity = str(f.get("severity", "")).lower()
                                needs_verify = f.get("needs_verification", True)
                                
                                if needs_verify or severity in ["critical", "high"]:
                                    findings_to_verify.append(f)
                
                if findings_to_verify:
                    logger.info(f"[Verification] ä»ä¼ ç»Ÿæ ¼å¼è·å– {len(findings_to_verify)} ä¸ªå‘ç°")
        
        # ğŸ”¥ å¦‚æœä»ç„¶æ²¡æœ‰å‘ç°ï¼Œå°è¯•ä» input_data çš„å…¶ä»–å­—æ®µæå–
        if not findings_to_verify:
            # å°è¯•ä» task æˆ– task_context ä¸­æå–æè¿°çš„æ¼æ´
            if task and ("å‘ç°" in task or "æ¼æ´" in task or "findings" in task.lower()):
                logger.warning(f"[Verification] æ— æ³•ä»ç»“æ„åŒ–æ•°æ®è·å–å‘ç°ï¼Œä»»åŠ¡æè¿°: {task[:200]}")
                # åˆ›å»ºä¸€ä¸ªæç¤º LLM ä»ä»»åŠ¡æè¿°ä¸­ç†è§£æ¼æ´çš„ç‰¹æ®Šå¤„ç†
                await self.emit_event("warning", f"æ— æ³•ä»ç»“æ„åŒ–æ•°æ®è·å–å‘ç°åˆ—è¡¨ï¼Œå°†åŸºäºä»»åŠ¡æè¿°è¿›è¡ŒéªŒè¯")
        
        # å»é‡
        findings_to_verify = self._deduplicate(findings_to_verify)

        # ğŸ”¥ FIX: ä¼˜å…ˆå¤„ç†æœ‰æ˜ç¡®æ–‡ä»¶è·¯å¾„çš„å‘ç°ï¼Œå°†æ²¡æœ‰æ–‡ä»¶è·¯å¾„çš„å‘ç°æ”¾åˆ°åé¢
        # è¿™ç¡®ä¿ Analysis çš„å…·ä½“å‘ç°ä¼˜å…ˆäº Recon çš„æ³›åŒ–æè¿°
        def has_valid_file_path(finding: Dict) -> bool:
            file_path = finding.get("file_path", "")
            return bool(file_path and file_path.strip() and file_path.lower() not in ["unknown", "n/a", ""])

        findings_with_path = [f for f in findings_to_verify if has_valid_file_path(f)]
        findings_without_path = [f for f in findings_to_verify if not has_valid_file_path(f)]

        # åˆå¹¶ï¼šæœ‰è·¯å¾„çš„åœ¨å‰ï¼Œæ²¡è·¯å¾„çš„åœ¨å
        findings_to_verify = findings_with_path + findings_without_path

        if findings_with_path:
            logger.info(f"[Verification] ä¼˜å…ˆå¤„ç† {len(findings_with_path)} ä¸ªæœ‰æ˜ç¡®æ–‡ä»¶è·¯å¾„çš„å‘ç°")
        if findings_without_path:
            logger.info(f"[Verification] è¿˜æœ‰ {len(findings_without_path)} ä¸ªå‘ç°éœ€è¦è‡ªè¡Œå®šä½æ–‡ä»¶")

        if not findings_to_verify:
            logger.warning(f"[Verification] æ²¡æœ‰éœ€è¦éªŒè¯çš„å‘ç°! previous_results keys: {list(previous_results.keys()) if isinstance(previous_results, dict) else 'not dict'}")
            await self.emit_event("warning", "æ²¡æœ‰éœ€è¦éªŒè¯çš„å‘ç° - å¯èƒ½æ˜¯æ•°æ®æ ¼å¼é—®é¢˜")
            return AgentResult(
                success=True,
                data={"findings": [], "verified_count": 0, "note": "æœªæ”¶åˆ°å¾…éªŒè¯çš„å‘ç°"},
            )
        
        # é™åˆ¶æ•°é‡
        findings_to_verify = findings_to_verify[:20]
        
        await self.emit_event(
            "info",
            f"å¼€å§‹éªŒè¯ {len(findings_to_verify)} ä¸ªå‘ç°"
        )
        
        # ğŸ”¥ è®°å½•å·¥ä½œå¼€å§‹
        self.record_work(f"å¼€å§‹éªŒè¯ {len(findings_to_verify)} ä¸ªæ¼æ´å‘ç°")
        
        # ğŸ”¥ æ„å»ºåŒ…å«äº¤æ¥ä¸Šä¸‹æ–‡çš„åˆå§‹æ¶ˆæ¯
        handoff_context = self.get_handoff_context()
        
        findings_summary = []
        for i, f in enumerate(findings_to_verify):
            # ğŸ”¥ FIX: æ­£ç¡®å¤„ç† file_path æ ¼å¼ï¼Œå¯èƒ½åŒ…å«è¡Œå· (å¦‚ "app.py:36")
            file_path = f.get('file_path', 'unknown')
            line_start = f.get('line_start', 0)

            # å¦‚æœ file_path å·²åŒ…å«è¡Œå·ï¼Œæå–å‡ºæ¥
            if isinstance(file_path, str) and ':' in file_path:
                parts = file_path.split(':', 1)
                if len(parts) == 2 and parts[1].split()[0].isdigit():
                    file_path = parts[0]
                    try:
                        line_start = int(parts[1].split()[0])
                    except ValueError:
                        pass

            findings_summary.append(f"""
### å‘ç° {i+1}: {f.get('title', 'Unknown')}
- ç±»å‹: {f.get('vulnerability_type', 'unknown')}
- ä¸¥é‡åº¦: {f.get('severity', 'medium')}
- æ–‡ä»¶: {file_path} (è¡Œ {line_start})
- ä»£ç :
```
{f.get('code_snippet', 'N/A')[:500]}
```
- æè¿°: {f.get('description', 'N/A')[:300]}
""")
        
        initial_message = f"""è¯·éªŒè¯ä»¥ä¸‹ {len(findings_to_verify)} ä¸ªå®‰å…¨å‘ç°ã€‚

{handoff_context if handoff_context else ''}

## å¾…éªŒè¯å‘ç°
{''.join(findings_summary)}

## âš ï¸ é‡è¦éªŒè¯æŒ‡å—
1. **ç›´æ¥ä½¿ç”¨ä¸Šé¢åˆ—å‡ºçš„æ–‡ä»¶è·¯å¾„** - ä¸è¦çŒœæµ‹æˆ–æœç´¢å…¶ä»–è·¯å¾„
2. **å¦‚æœæ–‡ä»¶è·¯å¾„åŒ…å«å†’å·å’Œè¡Œå·** (å¦‚ "app.py:36"), è¯·æå–æ–‡ä»¶å "app.py" å¹¶ä½¿ç”¨ read_file è¯»å–
3. **å…ˆè¯»å–æ–‡ä»¶å†…å®¹ï¼Œå†åˆ¤æ–­æ¼æ´æ˜¯å¦å­˜åœ¨**
4. **ä¸è¦å‡è®¾æ–‡ä»¶åœ¨å­ç›®å½•ä¸­** - ä½¿ç”¨å‘ç°ä¸­æä¾›çš„ç²¾ç¡®è·¯å¾„

## éªŒè¯è¦æ±‚
- éªŒè¯çº§åˆ«: {config.get('verification_level', 'standard')}

## å¯ç”¨å·¥å…·
{self.get_tools_description()}

è¯·å¼€å§‹éªŒè¯ã€‚å¯¹äºæ¯ä¸ªå‘ç°ï¼š
1. é¦–å…ˆä½¿ç”¨ read_file è¯»å–å‘ç°ä¸­æŒ‡å®šçš„æ–‡ä»¶ï¼ˆä½¿ç”¨ç²¾ç¡®è·¯å¾„ï¼‰
2. åˆ†æä»£ç ä¸Šä¸‹æ–‡
3. åˆ¤æ–­æ˜¯å¦ä¸ºçœŸå®æ¼æ´
{f"ç‰¹åˆ«æ³¨æ„ Analysis Agent æåˆ°çš„å…³æ³¨ç‚¹ã€‚" if handoff_context else ""}"""

        # åˆå§‹åŒ–å¯¹è¯å†å²
        self._conversation_history = [
            {"role": "system", "content": self.config.system_prompt},
            {"role": "user", "content": initial_message},
        ]
        
        self._steps = []
        final_result = None
        
        await self.emit_thinking("ğŸ” Verification Agent å¯åŠ¨ï¼ŒLLM å¼€å§‹è‡ªä¸»éªŒè¯æ¼æ´...")
        
        try:
            for iteration in range(self.config.max_iterations):
                if self.is_cancelled:
                    break
                
                self._iteration = iteration + 1
                
                # ğŸ”¥ å†æ¬¡æ£€æŸ¥å–æ¶ˆæ ‡å¿—ï¼ˆåœ¨LLMè°ƒç”¨ä¹‹å‰ï¼‰
                if self.is_cancelled:
                    await self.emit_thinking("ğŸ›‘ ä»»åŠ¡å·²å–æ¶ˆï¼Œåœæ­¢æ‰§è¡Œ")
                    break
                
                # è°ƒç”¨ LLM è¿›è¡Œæ€è€ƒå’Œå†³ç­–ï¼ˆæµå¼è¾“å‡ºï¼‰
                try:
                    llm_output, tokens_this_round = await self.stream_llm_call(
                        self._conversation_history,
                        # ğŸ”¥ ä¸ä¼ é€’ temperature å’Œ max_tokensï¼Œä½¿ç”¨ç”¨æˆ·é…ç½®
                    )
                except asyncio.CancelledError:
                    logger.info(f"[{self.name}] LLM call cancelled")
                    break
                
                self._total_tokens += tokens_this_round

                # ğŸ”¥ Handle empty LLM response to prevent loops
                if not llm_output or not llm_output.strip():
                    logger.warning(f"[{self.name}] Empty LLM response in iteration {self._iteration}")
                    await self.emit_llm_decision("æ”¶åˆ°ç©ºå“åº”", "LLM è¿”å›å†…å®¹ä¸ºç©ºï¼Œå°è¯•é‡è¯•é€šè¿‡æç¤º")
                    self._conversation_history.append({
                        "role": "user",
                        "content": "Received empty response. Please output your Thought and Action.",
                    })
                    continue

                # è§£æ LLM å“åº”
                step = self._parse_llm_response(llm_output)
                self._steps.append(step)
                
                # ğŸ”¥ å‘å°„ LLM æ€è€ƒå†…å®¹äº‹ä»¶ - å±•ç¤ºéªŒè¯çš„æ€è€ƒè¿‡ç¨‹
                if step.thought:
                    await self.emit_llm_thought(step.thought, iteration + 1)
                
                # æ·»åŠ  LLM å“åº”åˆ°å†å²
                self._conversation_history.append({
                    "role": "assistant",
                    "content": llm_output,
                })
                
                # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                if step.is_final:
                    # ğŸ”¥ å¼ºåˆ¶æ£€æŸ¥ï¼šå¿…é¡»è‡³å°‘è°ƒç”¨è¿‡ä¸€æ¬¡å·¥å…·æ‰èƒ½å®Œæˆ
                    if self._tool_calls == 0:
                        logger.warning(f"[{self.name}] LLM tried to finish without any tool calls! Forcing tool usage.")
                        await self.emit_thinking("âš ï¸ æ‹’ç»è¿‡æ—©å®Œæˆï¼šå¿…é¡»å…ˆä½¿ç”¨å·¥å…·éªŒè¯æ¼æ´")
                        self._conversation_history.append({
                            "role": "user",
                            "content": (
                                "âš ï¸ **ç³»ç»Ÿæ‹’ç»**: ä½ å¿…é¡»å…ˆä½¿ç”¨å·¥å…·éªŒè¯æ¼æ´ï¼\n\n"
                                "ä¸å…è®¸åœ¨æ²¡æœ‰è°ƒç”¨ä»»ä½•å·¥å…·çš„æƒ…å†µä¸‹ç›´æ¥è¾“å‡º Final Answerã€‚\n\n"
                                "è¯·ç«‹å³ä½¿ç”¨ä»¥ä¸‹å·¥å…·ä¹‹ä¸€è¿›è¡ŒéªŒè¯ï¼š\n"
                                "1. `read_file` - è¯»å–æ¼æ´æ‰€åœ¨æ–‡ä»¶çš„ä»£ç \n"
                                "2. `run_code` - ç¼–å†™å¹¶æ‰§è¡Œ Fuzzing Harness éªŒè¯æ¼æ´\n"
                                "3. `extract_function` - æå–ç›®æ ‡å‡½æ•°è¿›è¡Œåˆ†æ\n\n"
                                "ç°åœ¨è¯·è¾“å‡º Thought å’Œ Actionï¼Œå¼€å§‹éªŒè¯ç¬¬ä¸€ä¸ªæ¼æ´ã€‚"
                            ),
                        })
                        continue

                    await self.emit_llm_decision("å®Œæˆæ¼æ´éªŒè¯", "LLM åˆ¤æ–­éªŒè¯å·²å……åˆ†")
                    final_result = step.final_answer
                    
                    # ğŸ”¥ è®°å½•æ´å¯Ÿå’Œå·¥ä½œ
                    if final_result and "findings" in final_result:
                        verified_count = len([f for f in final_result["findings"] if f.get("is_verified")])
                        fp_count = len([f for f in final_result["findings"] if f.get("verdict") == "false_positive"])
                        self.add_insight(f"éªŒè¯äº† {len(final_result['findings'])} ä¸ªå‘ç°ï¼Œ{verified_count} ä¸ªç¡®è®¤ï¼Œ{fp_count} ä¸ªè¯¯æŠ¥")
                        self.record_work(f"å®Œæˆæ¼æ´éªŒè¯: {verified_count} ä¸ªç¡®è®¤, {fp_count} ä¸ªè¯¯æŠ¥")
                    
                    await self.emit_llm_complete(
                        f"éªŒè¯å®Œæˆ",
                        self._total_tokens
                    )
                    break
                
                # æ‰§è¡Œå·¥å…·
                if step.action:
                    # ğŸ”¥ å‘å°„ LLM åŠ¨ä½œå†³ç­–äº‹ä»¶
                    await self.emit_llm_action(step.action, step.action_input or {})
                    
                    start_tool_time = time.time()
                    
                    # ğŸ”¥ æ™ºèƒ½å¾ªç¯æ£€æµ‹: è¿½è¸ªé‡å¤è°ƒç”¨ (æ— è®ºæˆåŠŸä¸å¦)
                    tool_call_key = f"{step.action}:{json.dumps(step.action_input or {}, sort_keys=True)}"
                    
                    if not hasattr(self, '_tool_call_counts'):
                        self._tool_call_counts = {}
                    
                    self._tool_call_counts[tool_call_key] = self._tool_call_counts.get(tool_call_key, 0) + 1
                    
                    # å¦‚æœåŒä¸€æ“ä½œé‡å¤å°è¯•è¶…è¿‡3æ¬¡ï¼Œå¼ºåˆ¶å¹²é¢„
                    if self._tool_call_counts[tool_call_key] > 3:
                        logger.warning(f"[{self.name}] Detected repetitive tool call loop: {tool_call_key}")
                        observation = (
                            f"âš ï¸ **ç³»ç»Ÿå¹²é¢„**: ä½ å·²ç»ä½¿ç”¨å®Œå…¨ç›¸åŒçš„å‚æ•°è°ƒç”¨äº†å·¥å…· '{step.action}' è¶…è¿‡3æ¬¡ã€‚\n"
                            "è¯·**ä¸è¦**é‡å¤å°è¯•ç›¸åŒçš„æ“ä½œã€‚è¿™æ˜¯æ— æ•ˆçš„ã€‚\n"
                            "è¯·å°è¯•ï¼š\n"
                            "1. ä¿®æ”¹å‚æ•° (ä¾‹å¦‚æ”¹å˜ input payload)\n"
                            "2. ä½¿ç”¨ä¸åŒçš„å·¥å…· (ä¾‹å¦‚ä» sandbox_exec æ¢åˆ° php_test)\n"
                            "3. å¦‚æœä¹‹å‰çš„å°è¯•éƒ½å¤±è´¥äº†ï¼Œè¯·å°è¯• analyze_file é‡æ–°åˆ†æä»£ç \n"
                            "4. å¦‚æœæ— æ³•éªŒè¯ï¼Œè¯·è¾“å‡º Final Answer å¹¶æ ‡è®°ä¸º uncertain"
                        )
                        
                        # æ¨¡æ‹Ÿè§‚å¯Ÿç»“æœï¼Œè·³è¿‡å®é™…æ‰§è¡Œ
                        step.observation = observation
                        await self.emit_llm_observation(observation)
                        self._conversation_history.append({
                            "role": "user",
                            "content": f"Observation:\n{observation}",
                        })
                        continue

                    # ğŸ”¥ å¾ªç¯æ£€æµ‹ï¼šè¿½è¸ªå·¥å…·è°ƒç”¨å¤±è´¥å†å² (ä¿ç•™åŸæœ‰é€»è¾‘ç”¨äºé”™è¯¯è¿½è¸ª)
                    if not hasattr(self, '_failed_tool_calls'):
                        self._failed_tool_calls = {}
                    
                    observation = await self.execute_tool(
                        step.action,
                        step.action_input or {}
                    )
                    
                    # ğŸ”¥ æ£€æµ‹å·¥å…·è°ƒç”¨å¤±è´¥å¹¶è¿½è¸ª
                    is_tool_error = (
                        "å¤±è´¥" in observation or 
                        "é”™è¯¯" in observation or 
                        "ä¸å­˜åœ¨" in observation or
                        "æ–‡ä»¶è¿‡å¤§" in observation or
                        "Error" in observation
                    )
                    
                    if is_tool_error:
                        self._failed_tool_calls[tool_call_key] = self._failed_tool_calls.get(tool_call_key, 0) + 1
                        fail_count = self._failed_tool_calls[tool_call_key]
                        
                        # ğŸ”¥ å¦‚æœåŒä¸€è°ƒç”¨è¿ç»­å¤±è´¥3æ¬¡ï¼Œæ·»åŠ å¼ºåˆ¶è·³è¿‡æç¤º
                        if fail_count >= 3:
                            logger.warning(f"[{self.name}] Tool call failed {fail_count} times: {tool_call_key}")
                            observation += f"\n\nâš ï¸ **ç³»ç»Ÿæç¤º**: æ­¤å·¥å…·è°ƒç”¨å·²è¿ç»­å¤±è´¥ {fail_count} æ¬¡ã€‚è¯·ï¼š\n"
                            observation += "1. å°è¯•ä½¿ç”¨ä¸åŒçš„å‚æ•°ï¼ˆå¦‚æŒ‡å®šè¾ƒå°çš„è¡ŒèŒƒå›´ï¼‰\n"
                            observation += "2. ä½¿ç”¨ search_code å·¥å…·å®šä½å…³é”®ä»£ç ç‰‡æ®µ\n"
                            observation += "3. è·³è¿‡æ­¤å‘ç°çš„éªŒè¯ï¼Œç»§ç»­éªŒè¯å…¶ä»–å‘ç°\n"
                            observation += "4. å¦‚æœå·²æœ‰è¶³å¤ŸéªŒè¯ç»“æœï¼Œç›´æ¥è¾“å‡º Final Answer"
                            
                            # é‡ç½®è®¡æ•°å™¨
                            self._failed_tool_calls[tool_call_key] = 0
                    else:
                        # æˆåŠŸè°ƒç”¨ï¼Œé‡ç½®å¤±è´¥è®¡æ•°
                        if tool_call_key in self._failed_tool_calls:
                            del self._failed_tool_calls[tool_call_key]

                    # ğŸ”¥ å·¥å…·æ‰§è¡Œåæ£€æŸ¥å–æ¶ˆçŠ¶æ€
                    if self.is_cancelled:
                        logger.info(f"[{self.name}] Cancelled after tool execution")
                        break

                    step.observation = observation
                    
                    # ğŸ”¥ å‘å°„ LLM è§‚å¯Ÿäº‹ä»¶
                    await self.emit_llm_observation(observation)
                    
                    # æ·»åŠ è§‚å¯Ÿç»“æœåˆ°å†å²
                    self._conversation_history.append({
                        "role": "user",
                        "content": f"Observation:\n{observation}",
                    })
                else:
                    # LLM æ²¡æœ‰é€‰æ‹©å·¥å…·ï¼Œæç¤ºå®ƒç»§ç»­
                    await self.emit_llm_decision("ç»§ç»­éªŒè¯", "LLM éœ€è¦æ›´å¤šéªŒè¯")
                    self._conversation_history.append({
                        "role": "user",
                        "content": "è¯·ç»§ç»­éªŒè¯ã€‚ä½ è¾“å‡ºäº† Thought ä½†æ²¡æœ‰è¾“å‡º Actionã€‚è¯·**ç«‹å³**é€‰æ‹©ä¸€ä¸ªå·¥å…·æ‰§è¡Œï¼Œæˆ–è€…å¦‚æœéªŒè¯å®Œæˆï¼Œè¾“å‡º Final Answer æ±‡æ€»æ‰€æœ‰éªŒè¯ç»“æœã€‚",
                    })
            
            # å¤„ç†ç»“æœ
            duration_ms = int((time.time() - start_time) * 1000)
            
            # ğŸ”¥ å¦‚æœè¢«å–æ¶ˆï¼Œè¿”å›å–æ¶ˆç»“æœ
            if self.is_cancelled:
                await self.emit_event(
                    "info",
                    f"ğŸ›‘ Verification Agent å·²å–æ¶ˆ: {self._iteration} è½®è¿­ä»£"
                )
                return AgentResult(
                    success=False,
                    error="ä»»åŠ¡å·²å–æ¶ˆ",
                    data={"findings": findings_to_verify},
                    iterations=self._iteration,
                    tool_calls=self._tool_calls,
                    tokens_used=self._total_tokens,
                    duration_ms=duration_ms,
                )
            
            # å¤„ç†æœ€ç»ˆç»“æœ
            verified_findings = []

            # ğŸ”¥ Robustness: If LLM returns empty findings but we had input, fallback to original
            llm_findings = []
            if final_result and "findings" in final_result:
                llm_findings = final_result["findings"]

            if not llm_findings and findings_to_verify:
                logger.warning(f"[{self.name}] LLM returned empty findings despite {len(findings_to_verify)} inputs. Falling back to originals.")
                # Fallback to logic below (else branch)
                final_result = None

            if final_result and "findings" in final_result:
                # ğŸ”¥ DEBUG: Log what LLM returned for verdict diagnosis
                verdicts_debug = [(f.get("file_path", "?"), f.get("verdict"), f.get("confidence")) for f in final_result["findings"]]
                logger.info(f"[{self.name}] LLM returned verdicts: {verdicts_debug}")

                for f in final_result["findings"]:
                    # ğŸ”¥ FIX: Normalize verdict - handle missing/empty verdict
                    verdict = f.get("verdict")
                    if not verdict or verdict not in ["confirmed", "likely", "uncertain", "false_positive"]:
                        # Try to infer verdict from other fields
                        if f.get("is_verified") is True:
                            verdict = "confirmed"
                        elif f.get("confidence", 0) >= 0.8:
                            verdict = "likely"
                        elif f.get("confidence", 0) <= 0.3:
                            verdict = "false_positive"
                        else:
                            verdict = "uncertain"
                        logger.warning(f"[{self.name}] Missing/invalid verdict for {f.get('file_path', '?')}, inferred as: {verdict}")

                    verified = {
                        **f,
                        "verdict": verdict,  # ğŸ”¥ Ensure verdict is set
                        "is_verified": verdict == "confirmed" or (
                            verdict == "likely" and f.get("confidence", 0) >= 0.8
                        ),
                        "verified_at": datetime.now(timezone.utc).isoformat() if verdict in ["confirmed", "likely"] else None,
                    }

                    # æ·»åŠ ä¿®å¤å»ºè®®
                    if not verified.get("recommendation"):
                        verified["recommendation"] = self._get_recommendation(f.get("vulnerability_type", ""))

                    verified_findings.append(verified)
            else:
                # å¦‚æœæ²¡æœ‰æœ€ç»ˆç»“æœï¼Œä½¿ç”¨åŸå§‹å‘ç°
                for f in findings_to_verify:
                    verified_findings.append({
                        **f,
                        "verdict": "uncertain",
                        "confidence": 0.5,
                        "is_verified": False,
                    })
            
            # ç»Ÿè®¡
            confirmed_count = len([f for f in verified_findings if f.get("verdict") == "confirmed"])
            likely_count = len([f for f in verified_findings if f.get("verdict") == "likely"])
            false_positive_count = len([f for f in verified_findings if f.get("verdict") == "false_positive"])
            
            await self.emit_event(
                "info",
                f"Verification Agent å®Œæˆ: {confirmed_count} ç¡®è®¤, {likely_count} å¯èƒ½, {false_positive_count} è¯¯æŠ¥"
            )

            # ğŸ”¥ CRITICAL: Log final findings count before returning
            logger.info(f"[{self.name}] Returning {len(verified_findings)} verified findings")

            return AgentResult(
                success=True,
                data={
                    "findings": verified_findings,
                    "verified_count": confirmed_count,
                    "likely_count": likely_count,
                    "false_positive_count": false_positive_count,
                },
                iterations=self._iteration,
                tool_calls=self._tool_calls,
                tokens_used=self._total_tokens,
                duration_ms=duration_ms,
            )
            
        except Exception as e:
            logger.error(f"Verification Agent failed: {e}", exc_info=True)
            return AgentResult(success=False, error=str(e))
    
    def _get_recommendation(self, vuln_type: str) -> str:
        """è·å–ä¿®å¤å»ºè®®"""
        recommendations = {
            "sql_injection": "ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢æˆ– ORMï¼Œé¿å…å­—ç¬¦ä¸²æ‹¼æ¥æ„é€  SQL",
            "xss": "å¯¹ç”¨æˆ·è¾“å…¥è¿›è¡Œ HTML è½¬ä¹‰ï¼Œä½¿ç”¨ CSPï¼Œé¿å… innerHTML",
            "command_injection": "é¿å…ä½¿ç”¨ shell=Trueï¼Œä½¿ç”¨å‚æ•°åˆ—è¡¨ä¼ é€’å‘½ä»¤",
            "path_traversal": "éªŒè¯å’Œè§„èŒƒåŒ–è·¯å¾„ï¼Œä½¿ç”¨ç™½åå•ï¼Œé¿å…ç›´æ¥ä½¿ç”¨ç”¨æˆ·è¾“å…¥",
            "ssrf": "éªŒè¯å’Œé™åˆ¶ç›®æ ‡ URLï¼Œä½¿ç”¨ç™½åå•ï¼Œç¦æ­¢å†…ç½‘è®¿é—®",
            "deserialization": "é¿å…ååºåˆ—åŒ–ä¸å¯ä¿¡æ•°æ®ï¼Œä½¿ç”¨ JSON æ›¿ä»£ pickle/yaml",
            "hardcoded_secret": "ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–å¯†é’¥ç®¡ç†æœåŠ¡å­˜å‚¨æ•æ„Ÿä¿¡æ¯",
            "weak_crypto": "ä½¿ç”¨å¼ºåŠ å¯†ç®—æ³•ï¼ˆAES-256, SHA-256+ï¼‰ï¼Œé¿å… MD5/SHA1",
        }
        return recommendations.get(vuln_type, "è¯·æ ¹æ®å…·ä½“æƒ…å†µä¿®å¤æ­¤å®‰å…¨é—®é¢˜")
    
    def _deduplicate(self, findings: List[Dict]) -> List[Dict]:
        """å»é‡"""
        seen = set()
        unique = []
        
        for f in findings:
            key = (
                f.get("file_path", ""),
                f.get("line_start", 0),
                f.get("vulnerability_type", ""),
            )
            
            if key not in seen:
                seen.add(key)
                unique.append(f)
        
        return unique
    
    def get_conversation_history(self) -> List[Dict[str, str]]:
        """è·å–å¯¹è¯å†å²"""
        return self._conversation_history
    
    def get_steps(self) -> List[VerificationStep]:
        """è·å–æ‰§è¡Œæ­¥éª¤"""
        return self._steps
