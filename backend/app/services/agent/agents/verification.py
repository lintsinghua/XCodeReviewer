"""
Verification Agent (æ¼æ´éªŒè¯å±‚) - LLM é©±åŠ¨ç‰ˆ

LLM æ˜¯éªŒè¯çš„å¤§è„‘ï¼
- LLM å†³å®šå¦‚ä½•éªŒè¯æ¯ä¸ªæ¼æ´
- LLM æ„é€ éªŒè¯ç­–ç•¥
- LLM åˆ†æéªŒè¯ç»“æœ
- LLM åˆ¤æ–­æ˜¯å¦ä¸ºçœŸå®æ¼æ´

ç±»å‹: ReAct (çœŸæ­£çš„!)
"""

import asyncio
import json
import logging
import re
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from datetime import datetime, timezone

from .base import BaseAgent, AgentConfig, AgentResult, AgentType, AgentPattern
from ..json_parser import AgentJsonParser
from ..prompts import CORE_SECURITY_PRINCIPLES, VULNERABILITY_PRIORITIES

logger = logging.getLogger(__name__)



VERIFICATION_SYSTEM_PROMPT = """ä½ æ˜¯ DeepAudit çš„æ¼æ´éªŒè¯ Agentï¼Œä¸€ä¸ª**è‡ªä¸»**çš„å®‰å…¨éªŒè¯ä¸“å®¶ã€‚

## ä½ çš„è§’è‰²
ä½ æ˜¯æ¼æ´éªŒè¯çš„**å¤§è„‘**ï¼Œä¸æ˜¯æœºæ¢°éªŒè¯å™¨ã€‚ä½ éœ€è¦ï¼š
1. ç†è§£æ¯ä¸ªæ¼æ´çš„ä¸Šä¸‹æ–‡
2. è®¾è®¡åˆé€‚çš„éªŒè¯ç­–ç•¥
3. ä½¿ç”¨å·¥å…·è·å–æ›´å¤šä¿¡æ¯
4. åˆ¤æ–­æ¼æ´æ˜¯å¦çœŸå®å­˜åœ¨
5. è¯„ä¼°å®é™…å½±å“

## ä½ å¯ä»¥ä½¿ç”¨çš„å·¥å…·

### æ–‡ä»¶æ“ä½œ
- **read_file**: è¯»å–æ›´å¤šä»£ç ä¸Šä¸‹æ–‡
  å‚æ•°: file_path (str), start_line (int), end_line (int)
- **list_files**: åˆ—å‡ºç›®å½•æ–‡ä»¶
  å‚æ•°: directory (str), pattern (str)

### æ²™ç®±æ ¸å¿ƒå·¥å…·
- **sandbox_exec**: åœ¨æ²™ç®±ä¸­æ‰§è¡Œå‘½ä»¤
  å‚æ•°: command (str), timeout (int)
- **sandbox_http**: å‘é€ HTTP è¯·æ±‚æµ‹è¯•
  å‚æ•°: method (str), url (str), data (dict), headers (dict)
- **verify_vulnerability**: è‡ªåŠ¨åŒ–æ¼æ´éªŒè¯
  å‚æ•°: vulnerability_type (str), target_url (str), payload (str), expected_pattern (str)

### ğŸ”¥ å¤šè¯­è¨€ä»£ç æµ‹è¯•å·¥å…· (æŒ‰è¯­è¨€é€‰æ‹©)
- **php_test**: æµ‹è¯• PHP ä»£ç ï¼Œæ”¯æŒæ¨¡æ‹Ÿ GET/POST å‚æ•°
  å‚æ•°: file_path (str), php_code (str), get_params (dict), post_params (dict), timeout (int)
  ç¤ºä¾‹: {"file_path": "vuln.php", "get_params": {"cmd": "whoami"}}

- **python_test**: æµ‹è¯• Python ä»£ç ï¼Œæ”¯æŒæ¨¡æ‹Ÿ Flask/Django è¯·æ±‚
  å‚æ•°: file_path (str), code (str), request_params (dict), form_data (dict), timeout (int)
  ç¤ºä¾‹: {"code": "import os; os.system(params['cmd'])", "request_params": {"cmd": "id"}}

- **javascript_test**: æµ‹è¯• JavaScript/Node.js ä»£ç 
  å‚æ•°: file_path (str), code (str), req_query (dict), req_body (dict), timeout (int)
  ç¤ºä¾‹: {"code": "exec(req.query.cmd)", "req_query": {"cmd": "id"}}

- **java_test**: æµ‹è¯• Java ä»£ç ï¼Œæ”¯æŒæ¨¡æ‹Ÿ Servlet è¯·æ±‚
  å‚æ•°: file_path (str), code (str), request_params (dict), timeout (int)

- **go_test**: æµ‹è¯• Go ä»£ç 
  å‚æ•°: file_path (str), code (str), args (list), timeout (int)

- **ruby_test**: æµ‹è¯• Ruby ä»£ç ï¼Œæ”¯æŒæ¨¡æ‹Ÿ Rails è¯·æ±‚
  å‚æ•°: file_path (str), code (str), params (dict), timeout (int)

- **shell_test**: æµ‹è¯• Shell/Bash è„šæœ¬
  å‚æ•°: file_path (str), code (str), args (list), env (dict), timeout (int)

- **universal_code_test**: é€šç”¨å¤šè¯­è¨€æµ‹è¯•å·¥å…· (è‡ªåŠ¨æ£€æµ‹è¯­è¨€)
  å‚æ•°: language (str), file_path (str), code (str), params (dict), timeout (int)

### ğŸ”¥ æ¼æ´éªŒè¯ä¸“ç”¨å·¥å…· (æŒ‰æ¼æ´ç±»å‹é€‰æ‹©ï¼Œæ¨èä½¿ç”¨)
- **test_command_injection**: ä¸“é—¨æµ‹è¯•å‘½ä»¤æ³¨å…¥æ¼æ´
  å‚æ•°: target_file (str), param_name (str), test_command (str), language (str)
  ç¤ºä¾‹: {"target_file": "vuln.php", "param_name": "cmd", "test_command": "whoami"}

- **test_sql_injection**: ä¸“é—¨æµ‹è¯• SQL æ³¨å…¥æ¼æ´
  å‚æ•°: target_file (str), param_name (str), db_type (str), injection_type (str)
  ç¤ºä¾‹: {"target_file": "login.php", "param_name": "username", "db_type": "mysql"}

- **test_xss**: ä¸“é—¨æµ‹è¯• XSS æ¼æ´
  å‚æ•°: target_file (str), param_name (str), xss_type (str), context (str)
  ç¤ºä¾‹: {"target_file": "search.php", "param_name": "q", "xss_type": "reflected"}

- **test_path_traversal**: ä¸“é—¨æµ‹è¯•è·¯å¾„éå†æ¼æ´
  å‚æ•°: target_file (str), param_name (str), target_path (str)
  ç¤ºä¾‹: {"target_file": "download.php", "param_name": "file", "target_path": "/etc/passwd"}

- **test_ssti**: ä¸“é—¨æµ‹è¯•æ¨¡æ¿æ³¨å…¥æ¼æ´
  å‚æ•°: target_file (str), param_name (str), template_engine (str)
  ç¤ºä¾‹: {"target_file": "render.py", "param_name": "name", "template_engine": "jinja2"}

- **test_deserialization**: ä¸“é—¨æµ‹è¯•ååºåˆ—åŒ–æ¼æ´
  å‚æ•°: target_file (str), language (str), serialization_format (str)
  ç¤ºä¾‹: {"target_file": "api.php", "language": "php", "serialization_format": "php_serialize"}

- **universal_vuln_test**: é€šç”¨æ¼æ´æµ‹è¯•å·¥å…· (è‡ªåŠ¨é€‰æ‹©æµ‹è¯•ç­–ç•¥)
  å‚æ•°: vuln_type (str), target_file (str), param_name (str), additional_params (dict)
  æ”¯æŒ: command_injection, sql_injection, xss, path_traversal, ssti, deserialization

## å·¥ä½œæ–¹å¼
ä½ å°†æ”¶åˆ°ä¸€æ‰¹å¾…éªŒè¯çš„æ¼æ´å‘ç°ã€‚å¯¹äºæ¯ä¸ªå‘ç°ï¼Œä½ éœ€è¦ï¼š

```
Thought: [åˆ†æè¿™ä¸ªæ¼æ´ï¼Œæ€è€ƒå¦‚ä½•éªŒè¯]
Action: [å·¥å…·åç§°]
Action Input: [JSON æ ¼å¼çš„å‚æ•°]
```

éªŒè¯å®Œæ‰€æœ‰å‘ç°åï¼Œè¾“å‡ºï¼š

```
Thought: [æ€»ç»“éªŒè¯ç»“æœ]
Final Answer: [JSON æ ¼å¼çš„éªŒè¯æŠ¥å‘Š]
```

## Final Answer æ ¼å¼
```json
{
    "findings": [
        {
            ...åŸå§‹å‘ç°å­—æ®µ...,
            "verdict": "confirmed/likely/uncertain/false_positive",
            "confidence": 0.0-1.0,
            "is_verified": true/false,
            "verification_method": "æè¿°éªŒè¯æ–¹æ³•",
            "verification_details": "éªŒè¯è¿‡ç¨‹å’Œç»“æœè¯¦æƒ…",
            "poc": {
                "description": "PoC æè¿°",
                "steps": ["æ­¥éª¤1", "æ­¥éª¤2"],
                "payload": "curl 'http://target/vuln.php?cmd=id' æˆ–å®Œæ•´åˆ©ç”¨ä»£ç "
            },
            "impact": "å®é™…å½±å“åˆ†æ",
            "recommendation": "ä¿®å¤å»ºè®®"
        }
    ],
    "summary": {
        "total": æ•°é‡,
        "confirmed": æ•°é‡,
        "likely": æ•°é‡,
        "false_positive": æ•°é‡
    }
}
```

## éªŒè¯åˆ¤å®šæ ‡å‡†
- **confirmed**: æ¼æ´ç¡®è®¤å­˜åœ¨ä¸”å¯åˆ©ç”¨ï¼Œæœ‰æ˜ç¡®è¯æ®
- **likely**: é«˜åº¦å¯èƒ½å­˜åœ¨æ¼æ´ï¼Œä½†æ— æ³•å®Œå…¨ç¡®è®¤
- **uncertain**: éœ€è¦æ›´å¤šä¿¡æ¯æ‰èƒ½åˆ¤æ–­
- **false_positive**: ç¡®è®¤æ˜¯è¯¯æŠ¥ï¼Œæœ‰æ˜ç¡®ç†ç”±

## éªŒè¯ç­–ç•¥å»ºè®®

### å¯¹äºå‘½ä»¤æ³¨å…¥æ¼æ´
1. ä½¿ç”¨ **test_command_injection** å·¥å…·ï¼Œå®ƒä¼šè‡ªåŠ¨æ„å»ºæµ‹è¯•ç¯å¢ƒ
2. æˆ–ä½¿ç”¨å¯¹åº”è¯­è¨€çš„æµ‹è¯•å·¥å…· (php_test, python_test ç­‰)
3. æ£€æŸ¥å‘½ä»¤è¾“å‡ºæ˜¯å¦åŒ…å« uid=, root, www-data ç­‰ç‰¹å¾

### å¯¹äº SQL æ³¨å…¥æ¼æ´
1. ä½¿ç”¨ **test_sql_injection** å·¥å…·
2. æä¾›æ•°æ®åº“ç±»å‹ (mysql, postgresql, sqlite)
3. æ£€æŸ¥æ˜¯å¦èƒ½æ‰§è¡Œ UNION æŸ¥è¯¢æˆ–æå–æ•°æ®

### å¯¹äº XSS æ¼æ´
1. ä½¿ç”¨ **test_xss** å·¥å…·
2. æŒ‡å®š XSS ç±»å‹ (reflected, stored, dom)
3. æ£€æŸ¥ payload æ˜¯å¦åœ¨è¾“å‡ºä¸­æœªè½¬ä¹‰

### å¯¹äºè·¯å¾„éå†æ¼æ´
1. ä½¿ç”¨ **test_path_traversal** å·¥å…·
2. å°è¯•è¯»å– /etc/passwd æˆ–å…¶ä»–å·²çŸ¥æ–‡ä»¶
3. æ£€æŸ¥æ˜¯å¦èƒ½è®¿é—®ç›®æ ‡æ–‡ä»¶

### å¯¹äºæ¨¡æ¿æ³¨å…¥ (SSTI) æ¼æ´
1. ä½¿ç”¨ **test_ssti** å·¥å…·
2. æŒ‡å®šæ¨¡æ¿å¼•æ“ (jinja2, twig, freemarker ç­‰)
3. æ£€æŸ¥æ•°å­¦è¡¨è¾¾å¼æ˜¯å¦è¢«æ‰§è¡Œ

### å¯¹äºååºåˆ—åŒ–æ¼æ´
1. ä½¿ç”¨ **test_deserialization** å·¥å…·
2. æŒ‡å®šè¯­è¨€å’Œåºåˆ—åŒ–æ ¼å¼
3. æ£€æŸ¥æ˜¯å¦èƒ½æ‰§è¡Œä»»æ„ä»£ç 

### å¯¹äºå…¶ä»–æ¼æ´
1. **ä¸Šä¸‹æ–‡åˆ†æ**: ç”¨ read_file è·å–æ›´å¤šä»£ç ä¸Šä¸‹æ–‡
2. **é€šç”¨æµ‹è¯•**: ä½¿ç”¨ universal_vuln_test æˆ– universal_code_test
3. **æ²™ç®±æµ‹è¯•**: å¯¹é«˜å±æ¼æ´ç”¨æ²™ç®±è¿›è¡Œå®‰å…¨æµ‹è¯•

## é‡è¦åŸåˆ™
1. **è´¨é‡ä¼˜å…ˆ** - å®å¯æ¼æŠ¥ä¹Ÿä¸è¦è¯¯æŠ¥å¤ªå¤š
2. **æ·±å…¥ç†è§£** - ç†è§£ä»£ç é€»è¾‘ï¼Œä¸è¦è¡¨é¢åˆ¤æ–­
3. **è¯æ®æ”¯æ’‘** - åˆ¤å®šè¦æœ‰ä¾æ®
4. **å®‰å…¨ç¬¬ä¸€** - æ²™ç®±æµ‹è¯•è¦è°¨æ…
5. **ğŸ”¥ PoC ç”Ÿæˆ** - å¯¹äº confirmed å’Œ likely çš„æ¼æ´ï¼Œ**å¿…é¡»**ç”Ÿæˆå®Œæ•´çš„ PoC:
   - poc.description: ç®€è¦æè¿°è¿™ä¸ª PoC çš„ä½œç”¨
   - poc.steps: è¯¦ç»†çš„å¤ç°æ­¥éª¤åˆ—è¡¨
   - poc.payload: **å®Œæ•´çš„**åˆ©ç”¨ä»£ç æˆ–å‘½ä»¤ï¼Œä¾‹å¦‚:
     - Webæ¼æ´: å®Œæ•´URLå¦‚ `http://target/path?param=<payload>`
     - å‘½ä»¤æ³¨å…¥: å®Œæ•´çš„ curl å‘½ä»¤æˆ– HTTP è¯·æ±‚
     - SQLæ³¨å…¥: å®Œæ•´çš„åˆ©ç”¨è¯­å¥æˆ–è¯·æ±‚
     - ä»£ç æ‰§è¡Œ: å¯ç›´æ¥è¿è¡Œçš„åˆ©ç”¨è„šæœ¬
   - âš ï¸ payload å­—æ®µå¿…é¡»æ˜¯**å¯ç›´æ¥å¤åˆ¶æ‰§è¡Œ**çš„å®Œæ•´åˆ©ç”¨ä»£ç ï¼Œä¸è¦åªå†™å‚æ•°å€¼

ç°åœ¨å¼€å§‹éªŒè¯æ¼æ´å‘ç°ï¼"""


@dataclass
class VerificationStep:
    """éªŒè¯æ­¥éª¤"""
    thought: str
    action: Optional[str] = None
    action_input: Optional[Dict] = None
    observation: Optional[str] = None
    is_final: bool = False
    final_answer: Optional[Dict] = None


class VerificationAgent(BaseAgent):
    """
    æ¼æ´éªŒè¯ Agent - LLM é©±åŠ¨ç‰ˆ
    
    LLM å…¨ç¨‹å‚ä¸ï¼Œè‡ªä¸»å†³å®šï¼š
    1. å¦‚ä½•éªŒè¯æ¯ä¸ªæ¼æ´
    2. ä½¿ç”¨ä»€ä¹ˆå·¥å…·
    3. åˆ¤æ–­çœŸå‡
    """
    
    def __init__(
        self,
        llm_service,
        tools: Dict[str, Any],
        event_emitter=None,
    ):
        # ç»„åˆå¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯
        full_system_prompt = f"{VERIFICATION_SYSTEM_PROMPT}\n\n{CORE_SECURITY_PRINCIPLES}\n\n{VULNERABILITY_PRIORITIES}"
        
        config = AgentConfig(
            name="Verification",
            agent_type=AgentType.VERIFICATION,
            pattern=AgentPattern.REACT,
            max_iterations=25,
            system_prompt=full_system_prompt,
        )
        super().__init__(config, llm_service, tools, event_emitter)
        
        self._conversation_history: List[Dict[str, str]] = []
        self._steps: List[VerificationStep] = []



    
    def _parse_llm_response(self, response: str) -> VerificationStep:
        """è§£æ LLM å“åº” - å¢å¼ºç‰ˆï¼Œæ›´å¥å£®åœ°æå–æ€è€ƒå†…å®¹"""
        step = VerificationStep(thought="")

        # ğŸ”¥ é¦–å…ˆå°è¯•æå–æ˜ç¡®çš„ Thought æ ‡è®°
        thought_match = re.search(r'Thought:\s*(.*?)(?=Action:|Final Answer:|$)', response, re.DOTALL)
        if thought_match:
            step.thought = thought_match.group(1).strip()

        # ğŸ”¥ æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ç»ˆç­”æ¡ˆ
        final_match = re.search(r'Final Answer:\s*(.*?)$', response, re.DOTALL)
        if final_match:
            step.is_final = True
            answer_text = final_match.group(1).strip()
            answer_text = re.sub(r'```json\s*', '', answer_text)
            answer_text = re.sub(r'```\s*', '', answer_text)
            # ä½¿ç”¨å¢å¼ºçš„ JSON è§£æå™¨
            step.final_answer = AgentJsonParser.parse(
                answer_text,
                default={"findings": [], "raw_answer": answer_text}
            )
            # ç¡®ä¿ findings æ ¼å¼æ­£ç¡®
            if "findings" in step.final_answer:
                step.final_answer["findings"] = [
                    f for f in step.final_answer["findings"]
                    if isinstance(f, dict)
                ]

            # ğŸ”¥ å¦‚æœæ²¡æœ‰æå–åˆ° thoughtï¼Œä½¿ç”¨ Final Answer å‰çš„å†…å®¹ä½œä¸ºæ€è€ƒ
            if not step.thought:
                before_final = response[:response.find('Final Answer:')].strip()
                if before_final:
                    before_final = re.sub(r'^Thought:\s*', '', before_final)
                    step.thought = before_final[:500] if len(before_final) > 500 else before_final

            return step

        # ğŸ”¥ æå– Action
        action_match = re.search(r'Action:\s*(\w+)', response)
        if action_match:
            step.action = action_match.group(1).strip()

            # ğŸ”¥ å¦‚æœæ²¡æœ‰æå–åˆ° thoughtï¼Œæå– Action ä¹‹å‰çš„å†…å®¹ä½œä¸ºæ€è€ƒ
            if not step.thought:
                action_pos = response.find('Action:')
                if action_pos > 0:
                    before_action = response[:action_pos].strip()
                    before_action = re.sub(r'^Thought:\s*', '', before_action)
                    if before_action:
                        step.thought = before_action[:500] if len(before_action) > 500 else before_action

        # ğŸ”¥ æå– Action Input
        input_match = re.search(r'Action Input:\s*(.*?)(?=Thought:|Action:|Observation:|$)', response, re.DOTALL)
        if input_match:
            input_text = input_match.group(1).strip()
            input_text = re.sub(r'```json\s*', '', input_text)
            input_text = re.sub(r'```\s*', '', input_text)
            # ä½¿ç”¨å¢å¼ºçš„ JSON è§£æå™¨
            step.action_input = AgentJsonParser.parse(
                input_text,
                default={"raw_input": input_text}
            )

        # ğŸ”¥ æœ€åçš„ fallbackï¼šå¦‚æœæ•´ä¸ªå“åº”æ²¡æœ‰ä»»ä½•æ ‡è®°ï¼Œæ•´ä½“ä½œä¸ºæ€è€ƒ
        if not step.thought and not step.action and not step.is_final:
            if response.strip():
                step.thought = response.strip()[:500]

        return step
    
    async def run(self, input_data: Dict[str, Any]) -> AgentResult:
        """
        æ‰§è¡Œæ¼æ´éªŒè¯ - LLM å…¨ç¨‹å‚ä¸ï¼
        """
        import time
        start_time = time.time()
        
        previous_results = input_data.get("previous_results", {})
        config = input_data.get("config", {})
        task = input_data.get("task", "")
        task_context = input_data.get("task_context", "")
        
        # ğŸ”¥ å¤„ç†äº¤æ¥ä¿¡æ¯
        handoff = input_data.get("handoff")
        if handoff:
            from .base import TaskHandoff
            if isinstance(handoff, dict):
                handoff = TaskHandoff.from_dict(handoff)
            self.receive_handoff(handoff)
        
        # æ”¶é›†æ‰€æœ‰å¾…éªŒè¯çš„å‘ç°
        findings_to_verify = []
        
        # ğŸ”¥ ä¼˜å…ˆä»äº¤æ¥ä¿¡æ¯è·å–å‘ç°
        if self._incoming_handoff and self._incoming_handoff.key_findings:
            findings_to_verify = self._incoming_handoff.key_findings.copy()
            logger.info(f"[Verification] ä»äº¤æ¥ä¿¡æ¯è·å– {len(findings_to_verify)} ä¸ªå‘ç°")
        else:
            # ğŸ”¥ ä¿®å¤ï¼šå¤„ç† Orchestrator ä¼ é€’çš„å¤šç§æ•°æ®æ ¼å¼
            
            # æ ¼å¼1: Orchestrator ç›´æ¥ä¼ é€’ {"findings": [...]}
            if isinstance(previous_results, dict) and "findings" in previous_results:
                direct_findings = previous_results.get("findings", [])
                if isinstance(direct_findings, list):
                    for f in direct_findings:
                        if isinstance(f, dict):
                            # ğŸ”¥ Always verify Critical/High findings to generate PoC, even if Analysis sets needs_verification=False
                            severity = str(f.get("severity", "")).lower()
                            needs_verify = f.get("needs_verification", True)
                            
                            if needs_verify or severity in ["critical", "high"]:
                                findings_to_verify.append(f)
                    logger.info(f"[Verification] ä» previous_results.findings è·å– {len(findings_to_verify)} ä¸ªå‘ç°")
            
            # æ ¼å¼2: ä¼ ç»Ÿæ ¼å¼ {"phase_name": {"data": {"findings": [...]}}}
            if not findings_to_verify:
                for phase_name, result in previous_results.items():
                    if phase_name == "findings":
                        continue  # å·²å¤„ç†
                    
                    if isinstance(result, dict):
                        data = result.get("data", {})
                    else:
                        data = result.data if hasattr(result, 'data') else {}
                    
                    if isinstance(data, dict):
                        phase_findings = data.get("findings", [])
                        for f in phase_findings:
                            if isinstance(f, dict):
                                severity = str(f.get("severity", "")).lower()
                                needs_verify = f.get("needs_verification", True)
                                
                                if needs_verify or severity in ["critical", "high"]:
                                    findings_to_verify.append(f)
                
                if findings_to_verify:
                    logger.info(f"[Verification] ä»ä¼ ç»Ÿæ ¼å¼è·å– {len(findings_to_verify)} ä¸ªå‘ç°")
        
        # ğŸ”¥ å¦‚æœä»ç„¶æ²¡æœ‰å‘ç°ï¼Œå°è¯•ä» input_data çš„å…¶ä»–å­—æ®µæå–
        if not findings_to_verify:
            # å°è¯•ä» task æˆ– task_context ä¸­æå–æè¿°çš„æ¼æ´
            if task and ("å‘ç°" in task or "æ¼æ´" in task or "findings" in task.lower()):
                logger.warning(f"[Verification] æ— æ³•ä»ç»“æ„åŒ–æ•°æ®è·å–å‘ç°ï¼Œä»»åŠ¡æè¿°: {task[:200]}")
                # åˆ›å»ºä¸€ä¸ªæç¤º LLM ä»ä»»åŠ¡æè¿°ä¸­ç†è§£æ¼æ´çš„ç‰¹æ®Šå¤„ç†
                await self.emit_event("warning", f"æ— æ³•ä»ç»“æ„åŒ–æ•°æ®è·å–å‘ç°åˆ—è¡¨ï¼Œå°†åŸºäºä»»åŠ¡æè¿°è¿›è¡ŒéªŒè¯")
        
        # å»é‡
        findings_to_verify = self._deduplicate(findings_to_verify)

        # ğŸ”¥ FIX: ä¼˜å…ˆå¤„ç†æœ‰æ˜ç¡®æ–‡ä»¶è·¯å¾„çš„å‘ç°ï¼Œå°†æ²¡æœ‰æ–‡ä»¶è·¯å¾„çš„å‘ç°æ”¾åˆ°åé¢
        # è¿™ç¡®ä¿ Analysis çš„å…·ä½“å‘ç°ä¼˜å…ˆäº Recon çš„æ³›åŒ–æè¿°
        def has_valid_file_path(finding: Dict) -> bool:
            file_path = finding.get("file_path", "")
            return bool(file_path and file_path.strip() and file_path.lower() not in ["unknown", "n/a", ""])

        findings_with_path = [f for f in findings_to_verify if has_valid_file_path(f)]
        findings_without_path = [f for f in findings_to_verify if not has_valid_file_path(f)]

        # åˆå¹¶ï¼šæœ‰è·¯å¾„çš„åœ¨å‰ï¼Œæ²¡è·¯å¾„çš„åœ¨å
        findings_to_verify = findings_with_path + findings_without_path

        if findings_with_path:
            logger.info(f"[Verification] ä¼˜å…ˆå¤„ç† {len(findings_with_path)} ä¸ªæœ‰æ˜ç¡®æ–‡ä»¶è·¯å¾„çš„å‘ç°")
        if findings_without_path:
            logger.info(f"[Verification] è¿˜æœ‰ {len(findings_without_path)} ä¸ªå‘ç°éœ€è¦è‡ªè¡Œå®šä½æ–‡ä»¶")

        if not findings_to_verify:
            logger.warning(f"[Verification] æ²¡æœ‰éœ€è¦éªŒè¯çš„å‘ç°! previous_results keys: {list(previous_results.keys()) if isinstance(previous_results, dict) else 'not dict'}")
            await self.emit_event("warning", "æ²¡æœ‰éœ€è¦éªŒè¯çš„å‘ç° - å¯èƒ½æ˜¯æ•°æ®æ ¼å¼é—®é¢˜")
            return AgentResult(
                success=True,
                data={"findings": [], "verified_count": 0, "note": "æœªæ”¶åˆ°å¾…éªŒè¯çš„å‘ç°"},
            )
        
        # é™åˆ¶æ•°é‡
        findings_to_verify = findings_to_verify[:20]
        
        await self.emit_event(
            "info",
            f"å¼€å§‹éªŒè¯ {len(findings_to_verify)} ä¸ªå‘ç°"
        )
        
        # ğŸ”¥ è®°å½•å·¥ä½œå¼€å§‹
        self.record_work(f"å¼€å§‹éªŒè¯ {len(findings_to_verify)} ä¸ªæ¼æ´å‘ç°")
        
        # ğŸ”¥ æ„å»ºåŒ…å«äº¤æ¥ä¸Šä¸‹æ–‡çš„åˆå§‹æ¶ˆæ¯
        handoff_context = self.get_handoff_context()
        
        findings_summary = []
        for i, f in enumerate(findings_to_verify):
            # ğŸ”¥ FIX: æ­£ç¡®å¤„ç† file_path æ ¼å¼ï¼Œå¯èƒ½åŒ…å«è¡Œå· (å¦‚ "app.py:36")
            file_path = f.get('file_path', 'unknown')
            line_start = f.get('line_start', 0)

            # å¦‚æœ file_path å·²åŒ…å«è¡Œå·ï¼Œæå–å‡ºæ¥
            if isinstance(file_path, str) and ':' in file_path:
                parts = file_path.split(':', 1)
                if len(parts) == 2 and parts[1].split()[0].isdigit():
                    file_path = parts[0]
                    try:
                        line_start = int(parts[1].split()[0])
                    except ValueError:
                        pass

            findings_summary.append(f"""
### å‘ç° {i+1}: {f.get('title', 'Unknown')}
- ç±»å‹: {f.get('vulnerability_type', 'unknown')}
- ä¸¥é‡åº¦: {f.get('severity', 'medium')}
- æ–‡ä»¶: {file_path} (è¡Œ {line_start})
- ä»£ç :
```
{f.get('code_snippet', 'N/A')[:500]}
```
- æè¿°: {f.get('description', 'N/A')[:300]}
""")
        
        initial_message = f"""è¯·éªŒè¯ä»¥ä¸‹ {len(findings_to_verify)} ä¸ªå®‰å…¨å‘ç°ã€‚

{handoff_context if handoff_context else ''}

## å¾…éªŒè¯å‘ç°
{''.join(findings_summary)}

## âš ï¸ é‡è¦éªŒè¯æŒ‡å—
1. **ç›´æ¥ä½¿ç”¨ä¸Šé¢åˆ—å‡ºçš„æ–‡ä»¶è·¯å¾„** - ä¸è¦çŒœæµ‹æˆ–æœç´¢å…¶ä»–è·¯å¾„
2. **å¦‚æœæ–‡ä»¶è·¯å¾„åŒ…å«å†’å·å’Œè¡Œå·** (å¦‚ "app.py:36"), è¯·æå–æ–‡ä»¶å "app.py" å¹¶ä½¿ç”¨ read_file è¯»å–
3. **å…ˆè¯»å–æ–‡ä»¶å†…å®¹ï¼Œå†åˆ¤æ–­æ¼æ´æ˜¯å¦å­˜åœ¨**
4. **ä¸è¦å‡è®¾æ–‡ä»¶åœ¨å­ç›®å½•ä¸­** - ä½¿ç”¨å‘ç°ä¸­æä¾›çš„ç²¾ç¡®è·¯å¾„

## éªŒè¯è¦æ±‚
- éªŒè¯çº§åˆ«: {config.get('verification_level', 'standard')}

## å¯ç”¨å·¥å…·
{self.get_tools_description()}

è¯·å¼€å§‹éªŒè¯ã€‚å¯¹äºæ¯ä¸ªå‘ç°ï¼š
1. é¦–å…ˆä½¿ç”¨ read_file è¯»å–å‘ç°ä¸­æŒ‡å®šçš„æ–‡ä»¶ï¼ˆä½¿ç”¨ç²¾ç¡®è·¯å¾„ï¼‰
2. åˆ†æä»£ç ä¸Šä¸‹æ–‡
3. åˆ¤æ–­æ˜¯å¦ä¸ºçœŸå®æ¼æ´
{f"ç‰¹åˆ«æ³¨æ„ Analysis Agent æåˆ°çš„å…³æ³¨ç‚¹ã€‚" if handoff_context else ""}"""

        # åˆå§‹åŒ–å¯¹è¯å†å²
        self._conversation_history = [
            {"role": "system", "content": self.config.system_prompt},
            {"role": "user", "content": initial_message},
        ]
        
        self._steps = []
        final_result = None
        
        await self.emit_thinking("ğŸ” Verification Agent å¯åŠ¨ï¼ŒLLM å¼€å§‹è‡ªä¸»éªŒè¯æ¼æ´...")
        
        try:
            for iteration in range(self.config.max_iterations):
                if self.is_cancelled:
                    break
                
                self._iteration = iteration + 1
                
                # ğŸ”¥ å†æ¬¡æ£€æŸ¥å–æ¶ˆæ ‡å¿—ï¼ˆåœ¨LLMè°ƒç”¨ä¹‹å‰ï¼‰
                if self.is_cancelled:
                    await self.emit_thinking("ğŸ›‘ ä»»åŠ¡å·²å–æ¶ˆï¼Œåœæ­¢æ‰§è¡Œ")
                    break
                
                # è°ƒç”¨ LLM è¿›è¡Œæ€è€ƒå’Œå†³ç­–ï¼ˆæµå¼è¾“å‡ºï¼‰
                try:
                    llm_output, tokens_this_round = await self.stream_llm_call(
                        self._conversation_history,
                        temperature=0.1,
                        max_tokens=4096,  # ğŸ”¥ å¢åŠ åˆ° 4096ï¼Œé¿å…æˆªæ–­
                    )
                except asyncio.CancelledError:
                    logger.info(f"[{self.name}] LLM call cancelled")
                    break
                
                self._total_tokens += tokens_this_round

                # ğŸ”¥ Handle empty LLM response to prevent loops
                if not llm_output or not llm_output.strip():
                    logger.warning(f"[{self.name}] Empty LLM response in iteration {self._iteration}")
                    await self.emit_llm_decision("æ”¶åˆ°ç©ºå“åº”", "LLM è¿”å›å†…å®¹ä¸ºç©ºï¼Œå°è¯•é‡è¯•é€šè¿‡æç¤º")
                    self._conversation_history.append({
                        "role": "user",
                        "content": "Received empty response. Please output your Thought and Action.",
                    })
                    continue

                # è§£æ LLM å“åº”
                step = self._parse_llm_response(llm_output)
                self._steps.append(step)
                
                # ğŸ”¥ å‘å°„ LLM æ€è€ƒå†…å®¹äº‹ä»¶ - å±•ç¤ºéªŒè¯çš„æ€è€ƒè¿‡ç¨‹
                if step.thought:
                    await self.emit_llm_thought(step.thought, iteration + 1)
                
                # æ·»åŠ  LLM å“åº”åˆ°å†å²
                self._conversation_history.append({
                    "role": "assistant",
                    "content": llm_output,
                })
                
                # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                if step.is_final:
                    await self.emit_llm_decision("å®Œæˆæ¼æ´éªŒè¯", "LLM åˆ¤æ–­éªŒè¯å·²å……åˆ†")
                    final_result = step.final_answer
                    
                    # ğŸ”¥ è®°å½•æ´å¯Ÿå’Œå·¥ä½œ
                    if final_result and "findings" in final_result:
                        verified_count = len([f for f in final_result["findings"] if f.get("is_verified")])
                        fp_count = len([f for f in final_result["findings"] if f.get("verdict") == "false_positive"])
                        self.add_insight(f"éªŒè¯äº† {len(final_result['findings'])} ä¸ªå‘ç°ï¼Œ{verified_count} ä¸ªç¡®è®¤ï¼Œ{fp_count} ä¸ªè¯¯æŠ¥")
                        self.record_work(f"å®Œæˆæ¼æ´éªŒè¯: {verified_count} ä¸ªç¡®è®¤, {fp_count} ä¸ªè¯¯æŠ¥")
                    
                    await self.emit_llm_complete(
                        f"éªŒè¯å®Œæˆ",
                        self._total_tokens
                    )
                    break
                
                # æ‰§è¡Œå·¥å…·
                if step.action:
                    # ğŸ”¥ å‘å°„ LLM åŠ¨ä½œå†³ç­–äº‹ä»¶
                    await self.emit_llm_action(step.action, step.action_input or {})
                    
                    # ğŸ”¥ å¾ªç¯æ£€æµ‹ï¼šè¿½è¸ªå·¥å…·è°ƒç”¨å¤±è´¥å†å²
                    tool_call_key = f"{step.action}:{json.dumps(step.action_input or {}, sort_keys=True)}"
                    if not hasattr(self, '_failed_tool_calls'):
                        self._failed_tool_calls = {}
                    
                    observation = await self.execute_tool(
                        step.action,
                        step.action_input or {}
                    )
                    
                    # ğŸ”¥ æ£€æµ‹å·¥å…·è°ƒç”¨å¤±è´¥å¹¶è¿½è¸ª
                    is_tool_error = (
                        "å¤±è´¥" in observation or 
                        "é”™è¯¯" in observation or 
                        "ä¸å­˜åœ¨" in observation or
                        "æ–‡ä»¶è¿‡å¤§" in observation or
                        "Error" in observation
                    )
                    
                    if is_tool_error:
                        self._failed_tool_calls[tool_call_key] = self._failed_tool_calls.get(tool_call_key, 0) + 1
                        fail_count = self._failed_tool_calls[tool_call_key]
                        
                        # ğŸ”¥ å¦‚æœåŒä¸€è°ƒç”¨è¿ç»­å¤±è´¥3æ¬¡ï¼Œæ·»åŠ å¼ºåˆ¶è·³è¿‡æç¤º
                        if fail_count >= 3:
                            logger.warning(f"[{self.name}] Tool call failed {fail_count} times: {tool_call_key}")
                            observation += f"\n\nâš ï¸ **ç³»ç»Ÿæç¤º**: æ­¤å·¥å…·è°ƒç”¨å·²è¿ç»­å¤±è´¥ {fail_count} æ¬¡ã€‚è¯·ï¼š\n"
                            observation += "1. å°è¯•ä½¿ç”¨ä¸åŒçš„å‚æ•°ï¼ˆå¦‚æŒ‡å®šè¾ƒå°çš„è¡ŒèŒƒå›´ï¼‰\n"
                            observation += "2. ä½¿ç”¨ search_code å·¥å…·å®šä½å…³é”®ä»£ç ç‰‡æ®µ\n"
                            observation += "3. è·³è¿‡æ­¤å‘ç°çš„éªŒè¯ï¼Œç»§ç»­éªŒè¯å…¶ä»–å‘ç°\n"
                            observation += "4. å¦‚æœå·²æœ‰è¶³å¤ŸéªŒè¯ç»“æœï¼Œç›´æ¥è¾“å‡º Final Answer"
                            
                            # é‡ç½®è®¡æ•°å™¨
                            self._failed_tool_calls[tool_call_key] = 0
                    else:
                        # æˆåŠŸè°ƒç”¨ï¼Œé‡ç½®å¤±è´¥è®¡æ•°
                        if tool_call_key in self._failed_tool_calls:
                            del self._failed_tool_calls[tool_call_key]

                    # ğŸ”¥ å·¥å…·æ‰§è¡Œåæ£€æŸ¥å–æ¶ˆçŠ¶æ€
                    if self.is_cancelled:
                        logger.info(f"[{self.name}] Cancelled after tool execution")
                        break

                    step.observation = observation
                    
                    # ğŸ”¥ å‘å°„ LLM è§‚å¯Ÿäº‹ä»¶
                    await self.emit_llm_observation(observation)
                    
                    # æ·»åŠ è§‚å¯Ÿç»“æœåˆ°å†å²
                    self._conversation_history.append({
                        "role": "user",
                        "content": f"Observation:\n{observation}",
                    })
                else:
                    # LLM æ²¡æœ‰é€‰æ‹©å·¥å…·ï¼Œæç¤ºå®ƒç»§ç»­
                    await self.emit_llm_decision("ç»§ç»­éªŒè¯", "LLM éœ€è¦æ›´å¤šéªŒè¯")
                    self._conversation_history.append({
                        "role": "user",
                        "content": "è¯·ç»§ç»­éªŒè¯ã€‚å¦‚æœéªŒè¯å®Œæˆï¼Œè¾“å‡º Final Answer æ±‡æ€»æ‰€æœ‰éªŒè¯ç»“æœã€‚",
                    })
            
            # å¤„ç†ç»“æœ
            duration_ms = int((time.time() - start_time) * 1000)
            
            # ğŸ”¥ å¦‚æœè¢«å–æ¶ˆï¼Œè¿”å›å–æ¶ˆç»“æœ
            if self.is_cancelled:
                await self.emit_event(
                    "info",
                    f"ğŸ›‘ Verification Agent å·²å–æ¶ˆ: {self._iteration} è½®è¿­ä»£"
                )
                return AgentResult(
                    success=False,
                    error="ä»»åŠ¡å·²å–æ¶ˆ",
                    data={"findings": findings_to_verify},
                    iterations=self._iteration,
                    tool_calls=self._tool_calls,
                    tokens_used=self._total_tokens,
                    duration_ms=duration_ms,
                )
            
            # å¤„ç†æœ€ç»ˆç»“æœ
            verified_findings = []
            
            # ğŸ”¥ Robustness: If LLM returns empty findings but we had input, fallback to original
            llm_findings = []
            if final_result and "findings" in final_result:
                llm_findings = final_result["findings"]
            
            if not llm_findings and findings_to_verify:
                logger.warning(f"[{self.name}] LLM returned empty findings despite {len(findings_to_verify)} inputs. Falling back to originals.")
                # Fallback to logic below (else branch)
                final_result = None 

            if final_result and "findings" in final_result:
                for f in final_result["findings"]:
                    verified = {
                        **f,
                        "is_verified": f.get("verdict") == "confirmed" or (
                            f.get("verdict") == "likely" and f.get("confidence", 0) >= 0.8
                        ),
                        "verified_at": datetime.now(timezone.utc).isoformat() if f.get("verdict") in ["confirmed", "likely"] else None,
                    }
                    
                    # æ·»åŠ ä¿®å¤å»ºè®®
                    if not verified.get("recommendation"):
                        verified["recommendation"] = self._get_recommendation(f.get("vulnerability_type", ""))
                    
                    verified_findings.append(verified)
            else:
                # å¦‚æœæ²¡æœ‰æœ€ç»ˆç»“æœï¼Œä½¿ç”¨åŸå§‹å‘ç°
                for f in findings_to_verify:
                    verified_findings.append({
                        **f,
                        "verdict": "uncertain",
                        "confidence": 0.5,
                        "is_verified": False,
                    })
            
            # ç»Ÿè®¡
            confirmed_count = len([f for f in verified_findings if f.get("verdict") == "confirmed"])
            likely_count = len([f for f in verified_findings if f.get("verdict") == "likely"])
            false_positive_count = len([f for f in verified_findings if f.get("verdict") == "false_positive"])
            
            await self.emit_event(
                "info",
                f"Verification Agent å®Œæˆ: {confirmed_count} ç¡®è®¤, {likely_count} å¯èƒ½, {false_positive_count} è¯¯æŠ¥"
            )

            # ğŸ”¥ CRITICAL: Log final findings count before returning
            logger.info(f"[{self.name}] Returning {len(verified_findings)} verified findings")

            return AgentResult(
                success=True,
                data={
                    "findings": verified_findings,
                    "verified_count": confirmed_count,
                    "likely_count": likely_count,
                    "false_positive_count": false_positive_count,
                },
                iterations=self._iteration,
                tool_calls=self._tool_calls,
                tokens_used=self._total_tokens,
                duration_ms=duration_ms,
            )
            
        except Exception as e:
            logger.error(f"Verification Agent failed: {e}", exc_info=True)
            return AgentResult(success=False, error=str(e))
    
    def _get_recommendation(self, vuln_type: str) -> str:
        """è·å–ä¿®å¤å»ºè®®"""
        recommendations = {
            "sql_injection": "ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢æˆ– ORMï¼Œé¿å…å­—ç¬¦ä¸²æ‹¼æ¥æ„é€  SQL",
            "xss": "å¯¹ç”¨æˆ·è¾“å…¥è¿›è¡Œ HTML è½¬ä¹‰ï¼Œä½¿ç”¨ CSPï¼Œé¿å… innerHTML",
            "command_injection": "é¿å…ä½¿ç”¨ shell=Trueï¼Œä½¿ç”¨å‚æ•°åˆ—è¡¨ä¼ é€’å‘½ä»¤",
            "path_traversal": "éªŒè¯å’Œè§„èŒƒåŒ–è·¯å¾„ï¼Œä½¿ç”¨ç™½åå•ï¼Œé¿å…ç›´æ¥ä½¿ç”¨ç”¨æˆ·è¾“å…¥",
            "ssrf": "éªŒè¯å’Œé™åˆ¶ç›®æ ‡ URLï¼Œä½¿ç”¨ç™½åå•ï¼Œç¦æ­¢å†…ç½‘è®¿é—®",
            "deserialization": "é¿å…ååºåˆ—åŒ–ä¸å¯ä¿¡æ•°æ®ï¼Œä½¿ç”¨ JSON æ›¿ä»£ pickle/yaml",
            "hardcoded_secret": "ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–å¯†é’¥ç®¡ç†æœåŠ¡å­˜å‚¨æ•æ„Ÿä¿¡æ¯",
            "weak_crypto": "ä½¿ç”¨å¼ºåŠ å¯†ç®—æ³•ï¼ˆAES-256, SHA-256+ï¼‰ï¼Œé¿å… MD5/SHA1",
        }
        return recommendations.get(vuln_type, "è¯·æ ¹æ®å…·ä½“æƒ…å†µä¿®å¤æ­¤å®‰å…¨é—®é¢˜")
    
    def _deduplicate(self, findings: List[Dict]) -> List[Dict]:
        """å»é‡"""
        seen = set()
        unique = []
        
        for f in findings:
            key = (
                f.get("file_path", ""),
                f.get("line_start", 0),
                f.get("vulnerability_type", ""),
            )
            
            if key not in seen:
                seen.add(key)
                unique.append(f)
        
        return unique
    
    def get_conversation_history(self) -> List[Dict[str, str]]:
        """è·å–å¯¹è¯å†å²"""
        return self._conversation_history
    
    def get_steps(self) -> List[VerificationStep]:
        """è·å–æ‰§è¡Œæ­¥éª¤"""
        return self._steps
