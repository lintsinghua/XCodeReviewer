"""
Verification Agent (æ¼æ´éªŒè¯å±‚) - LLM é©±åŠ¨ç‰ˆ

LLM æ˜¯éªŒè¯çš„å¤§è„‘ï¼
- LLM å†³å®šå¦‚ä½•éªŒè¯æ¯ä¸ªæ¼æ´
- LLM æ„é€ éªŒè¯ç­–ç•¥
- LLM åˆ†æéªŒè¯ç»“æœ
- LLM åˆ¤æ–­æ˜¯å¦ä¸ºçœŸå®æ¼æ´

ç±»å‹: ReAct (çœŸæ­£çš„!)
"""

import asyncio
import json
import logging
import re
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from datetime import datetime, timezone

from .base import BaseAgent, AgentConfig, AgentResult, AgentType, AgentPattern
from ..json_parser import AgentJsonParser

logger = logging.getLogger(__name__)


VERIFICATION_SYSTEM_PROMPT = """ä½ æ˜¯ DeepAudit çš„æ¼æ´éªŒè¯ Agentï¼Œä¸€ä¸ª**è‡ªä¸»**çš„å®‰å…¨éªŒè¯ä¸“å®¶ã€‚

## ä½ çš„è§’è‰²
ä½ æ˜¯æ¼æ´éªŒè¯çš„**å¤§è„‘**ï¼Œä¸æ˜¯æœºæ¢°éªŒè¯å™¨ã€‚ä½ éœ€è¦ï¼š
1. ç†è§£æ¯ä¸ªæ¼æ´çš„ä¸Šä¸‹æ–‡
2. è®¾è®¡åˆé€‚çš„éªŒè¯ç­–ç•¥
3. ä½¿ç”¨å·¥å…·è·å–æ›´å¤šä¿¡æ¯
4. åˆ¤æ–­æ¼æ´æ˜¯å¦çœŸå®å­˜åœ¨
5. è¯„ä¼°å®é™…å½±å“

## ä½ å¯ä»¥ä½¿ç”¨çš„å·¥å…·

### æ–‡ä»¶æ“ä½œ
- **read_file**: è¯»å–æ›´å¤šä»£ç ä¸Šä¸‹æ–‡
  å‚æ•°: file_path (str), start_line (int), end_line (int)
- **list_files**: åˆ—å‡ºç›®å½•æ–‡ä»¶
  å‚æ•°: directory (str), pattern (str)

### éªŒè¯åˆ†æ
- **vulnerability_validation**: LLM æ·±åº¦éªŒè¯ â­
  å‚æ•°: code (str), vulnerability_type (str), context (str)
- **dataflow_analysis**: è¿½è¸ªæ•°æ®æµ
  å‚æ•°: source (str), sink (str), file_path (str)

### æ²™ç®±éªŒè¯
- **sandbox_exec**: åœ¨æ²™ç®±ä¸­æ‰§è¡Œå‘½ä»¤
  å‚æ•°: command (str), timeout (int)
- **sandbox_http**: å‘é€ HTTP è¯·æ±‚æµ‹è¯•
  å‚æ•°: method (str), url (str), data (dict), headers (dict)
- **verify_vulnerability**: è‡ªåŠ¨åŒ–æ¼æ´éªŒè¯
  å‚æ•°: vulnerability_type (str), target (str), payload (str)

## å·¥ä½œæ–¹å¼
ä½ å°†æ”¶åˆ°ä¸€æ‰¹å¾…éªŒè¯çš„æ¼æ´å‘ç°ã€‚å¯¹äºæ¯ä¸ªå‘ç°ï¼Œä½ éœ€è¦ï¼š

```
Thought: [åˆ†æè¿™ä¸ªæ¼æ´ï¼Œæ€è€ƒå¦‚ä½•éªŒè¯]
Action: [å·¥å…·åç§°]
Action Input: [JSON æ ¼å¼çš„å‚æ•°]
```

éªŒè¯å®Œæ‰€æœ‰å‘ç°åï¼Œè¾“å‡ºï¼š

```
Thought: [æ€»ç»“éªŒè¯ç»“æœ]
Final Answer: [JSON æ ¼å¼çš„éªŒè¯æŠ¥å‘Š]
```

## Final Answer æ ¼å¼
```json
{
    "findings": [
        {
            ...åŸå§‹å‘ç°å­—æ®µ...,
            "verdict": "confirmed/likely/uncertain/false_positive",
            "confidence": 0.0-1.0,
            "is_verified": true/false,
            "verification_method": "æè¿°éªŒè¯æ–¹æ³•",
            "verification_details": "éªŒè¯è¿‡ç¨‹å’Œç»“æœè¯¦æƒ…",
            "poc": {
                "description": "PoC æè¿°",
                "steps": ["æ­¥éª¤1", "æ­¥éª¤2"],
                "payload": "æµ‹è¯• payload"
            },
            "impact": "å®é™…å½±å“åˆ†æ",
            "recommendation": "ä¿®å¤å»ºè®®"
        }
    ],
    "summary": {
        "total": æ•°é‡,
        "confirmed": æ•°é‡,
        "likely": æ•°é‡,
        "false_positive": æ•°é‡
    }
}
```

## éªŒè¯åˆ¤å®šæ ‡å‡†
- **confirmed**: æ¼æ´ç¡®è®¤å­˜åœ¨ä¸”å¯åˆ©ç”¨ï¼Œæœ‰æ˜ç¡®è¯æ®
- **likely**: é«˜åº¦å¯èƒ½å­˜åœ¨æ¼æ´ï¼Œä½†æ— æ³•å®Œå…¨ç¡®è®¤
- **uncertain**: éœ€è¦æ›´å¤šä¿¡æ¯æ‰èƒ½åˆ¤æ–­
- **false_positive**: ç¡®è®¤æ˜¯è¯¯æŠ¥ï¼Œæœ‰æ˜ç¡®ç†ç”±

## éªŒè¯ç­–ç•¥å»ºè®®
1. **ä¸Šä¸‹æ–‡åˆ†æ**: ç”¨ read_file è·å–æ›´å¤šä»£ç ä¸Šä¸‹æ–‡
2. **æ•°æ®æµè¿½è¸ª**: ç”¨ dataflow_analysis ç¡®è®¤æ±¡ç‚¹ä¼ æ’­
3. **LLM æ·±åº¦åˆ†æ**: ç”¨ vulnerability_validation è¿›è¡Œä¸“ä¸šåˆ†æ
4. **æ²™ç®±æµ‹è¯•**: å¯¹é«˜å±æ¼æ´ç”¨æ²™ç®±è¿›è¡Œå®‰å…¨æµ‹è¯•

## é‡è¦åŸåˆ™
1. **è´¨é‡ä¼˜å…ˆ** - å®å¯æ¼æŠ¥ä¹Ÿä¸è¦è¯¯æŠ¥å¤ªå¤š
2. **æ·±å…¥ç†è§£** - ç†è§£ä»£ç é€»è¾‘ï¼Œä¸è¦è¡¨é¢åˆ¤æ–­
3. **è¯æ®æ”¯æ’‘** - åˆ¤å®šè¦æœ‰ä¾æ®
4. **å®‰å…¨ç¬¬ä¸€** - æ²™ç®±æµ‹è¯•è¦è°¨æ…

ç°åœ¨å¼€å§‹éªŒè¯æ¼æ´å‘ç°ï¼"""


@dataclass
class VerificationStep:
    """éªŒè¯æ­¥éª¤"""
    thought: str
    action: Optional[str] = None
    action_input: Optional[Dict] = None
    observation: Optional[str] = None
    is_final: bool = False
    final_answer: Optional[Dict] = None


class VerificationAgent(BaseAgent):
    """
    æ¼æ´éªŒè¯ Agent - LLM é©±åŠ¨ç‰ˆ
    
    LLM å…¨ç¨‹å‚ä¸ï¼Œè‡ªä¸»å†³å®šï¼š
    1. å¦‚ä½•éªŒè¯æ¯ä¸ªæ¼æ´
    2. ä½¿ç”¨ä»€ä¹ˆå·¥å…·
    3. åˆ¤æ–­çœŸå‡
    """
    
    def __init__(
        self,
        llm_service,
        tools: Dict[str, Any],
        event_emitter=None,
    ):
        config = AgentConfig(
            name="Verification",
            agent_type=AgentType.VERIFICATION,
            pattern=AgentPattern.REACT,
            max_iterations=25,
            system_prompt=VERIFICATION_SYSTEM_PROMPT,
        )
        super().__init__(config, llm_service, tools, event_emitter)
        
        self._conversation_history: List[Dict[str, str]] = []
        self._steps: List[VerificationStep] = []
    
    def _parse_llm_response(self, response: str) -> VerificationStep:
        """è§£æ LLM å“åº”"""
        step = VerificationStep(thought="")
        
        # æå– Thought
        thought_match = re.search(r'Thought:\s*(.*?)(?=Action:|Final Answer:|$)', response, re.DOTALL)
        if thought_match:
            step.thought = thought_match.group(1).strip()
        elif not re.search(r'Action:|Final Answer:', response):
             # ğŸ”¥ Fallback: If no markers found, treat the whole response as Thought
             if response.strip():
                 step.thought = response.strip()
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ç»ˆç­”æ¡ˆ
        final_match = re.search(r'Final Answer:\s*(.*?)$', response, re.DOTALL)
        if final_match:
            step.is_final = True
            answer_text = final_match.group(1).strip()
            answer_text = re.sub(r'```json\s*', '', answer_text)
            answer_text = re.sub(r'```\s*', '', answer_text)
            # ä½¿ç”¨å¢å¼ºçš„ JSON è§£æå™¨
            step.final_answer = AgentJsonParser.parse(
                answer_text, 
                default={"findings": [], "raw_answer": answer_text}
            )
            # ç¡®ä¿ findings æ ¼å¼æ­£ç¡®
            if "findings" in step.final_answer:
                step.final_answer["findings"] = [
                    f for f in step.final_answer["findings"] 
                    if isinstance(f, dict)
                ]
            return step
        
        # æå– Action
        action_match = re.search(r'Action:\s*(\w+)', response)
        if action_match:
            step.action = action_match.group(1).strip()
        
        # æå– Action Input
        input_match = re.search(r'Action Input:\s*(.*?)(?=Thought:|Action:|Observation:|$)', response, re.DOTALL)
        if input_match:
            input_text = input_match.group(1).strip()
            input_text = re.sub(r'```json\s*', '', input_text)
            input_text = re.sub(r'```\s*', '', input_text)
            # ä½¿ç”¨å¢å¼ºçš„ JSON è§£æå™¨
            step.action_input = AgentJsonParser.parse(
                input_text,
                default={"raw_input": input_text}
            )
        
        return step
    
    async def run(self, input_data: Dict[str, Any]) -> AgentResult:
        """
        æ‰§è¡Œæ¼æ´éªŒè¯ - LLM å…¨ç¨‹å‚ä¸ï¼
        """
        import time
        start_time = time.time()
        
        previous_results = input_data.get("previous_results", {})
        config = input_data.get("config", {})
        task = input_data.get("task", "")
        task_context = input_data.get("task_context", "")
        
        # ğŸ”¥ å¤„ç†äº¤æ¥ä¿¡æ¯
        handoff = input_data.get("handoff")
        if handoff:
            from .base import TaskHandoff
            if isinstance(handoff, dict):
                handoff = TaskHandoff.from_dict(handoff)
            self.receive_handoff(handoff)
        
        # æ”¶é›†æ‰€æœ‰å¾…éªŒè¯çš„å‘ç°
        findings_to_verify = []
        
        # ğŸ”¥ ä¼˜å…ˆä»äº¤æ¥ä¿¡æ¯è·å–å‘ç°
        if self._incoming_handoff and self._incoming_handoff.key_findings:
            findings_to_verify = self._incoming_handoff.key_findings.copy()
        else:
            for phase_name, result in previous_results.items():
                if isinstance(result, dict):
                    data = result.get("data", {})
                else:
                    data = result.data if hasattr(result, 'data') else {}
                
                if isinstance(data, dict):
                    phase_findings = data.get("findings", [])
                    for f in phase_findings:
                        if f.get("needs_verification", True):
                            findings_to_verify.append(f)
        
        # å»é‡
        findings_to_verify = self._deduplicate(findings_to_verify)
        
        if not findings_to_verify:
            await self.emit_event("info", "æ²¡æœ‰éœ€è¦éªŒè¯çš„å‘ç°")
            return AgentResult(
                success=True,
                data={"findings": [], "verified_count": 0},
            )
        
        # é™åˆ¶æ•°é‡
        findings_to_verify = findings_to_verify[:20]
        
        await self.emit_event(
            "info",
            f"å¼€å§‹éªŒè¯ {len(findings_to_verify)} ä¸ªå‘ç°"
        )
        
        # ğŸ”¥ è®°å½•å·¥ä½œå¼€å§‹
        self.record_work(f"å¼€å§‹éªŒè¯ {len(findings_to_verify)} ä¸ªæ¼æ´å‘ç°")
        
        # ğŸ”¥ æ„å»ºåŒ…å«äº¤æ¥ä¸Šä¸‹æ–‡çš„åˆå§‹æ¶ˆæ¯
        handoff_context = self.get_handoff_context()
        
        findings_summary = []
        for i, f in enumerate(findings_to_verify):
            findings_summary.append(f"""
### å‘ç° {i+1}: {f.get('title', 'Unknown')}
- ç±»å‹: {f.get('vulnerability_type', 'unknown')}
- ä¸¥é‡åº¦: {f.get('severity', 'medium')}
- æ–‡ä»¶: {f.get('file_path', 'unknown')}:{f.get('line_start', 0)}
- ä»£ç :
```
{f.get('code_snippet', 'N/A')[:500]}
```
- æè¿°: {f.get('description', 'N/A')[:300]}
""")
        
        initial_message = f"""è¯·éªŒè¯ä»¥ä¸‹ {len(findings_to_verify)} ä¸ªå®‰å…¨å‘ç°ã€‚

{handoff_context if handoff_context else ''}

## å¾…éªŒè¯å‘ç°
{''.join(findings_summary)}

## éªŒè¯è¦æ±‚
- éªŒè¯çº§åˆ«: {config.get('verification_level', 'standard')}

## å¯ç”¨å·¥å…·
{self.get_tools_description()}

è¯·å¼€å§‹éªŒè¯ã€‚å¯¹äºæ¯ä¸ªå‘ç°ï¼Œæ€è€ƒå¦‚ä½•éªŒè¯å®ƒï¼Œä½¿ç”¨åˆé€‚çš„å·¥å…·è·å–æ›´å¤šä¿¡æ¯ï¼Œç„¶ååˆ¤æ–­æ˜¯å¦ä¸ºçœŸå®æ¼æ´ã€‚
{f"ç‰¹åˆ«æ³¨æ„ Analysis Agent æåˆ°çš„å…³æ³¨ç‚¹ã€‚" if handoff_context else ""}"""

        # åˆå§‹åŒ–å¯¹è¯å†å²
        self._conversation_history = [
            {"role": "system", "content": self.config.system_prompt},
            {"role": "user", "content": initial_message},
        ]
        
        self._steps = []
        final_result = None
        
        await self.emit_thinking("ğŸ” Verification Agent å¯åŠ¨ï¼ŒLLM å¼€å§‹è‡ªä¸»éªŒè¯æ¼æ´...")
        
        try:
            for iteration in range(self.config.max_iterations):
                if self.is_cancelled:
                    break
                
                self._iteration = iteration + 1
                
                # ğŸ”¥ å†æ¬¡æ£€æŸ¥å–æ¶ˆæ ‡å¿—ï¼ˆåœ¨LLMè°ƒç”¨ä¹‹å‰ï¼‰
                if self.is_cancelled:
                    await self.emit_thinking("ğŸ›‘ ä»»åŠ¡å·²å–æ¶ˆï¼Œåœæ­¢æ‰§è¡Œ")
                    break
                
                # è°ƒç”¨ LLM è¿›è¡Œæ€è€ƒå’Œå†³ç­–ï¼ˆæµå¼è¾“å‡ºï¼‰
                try:
                    llm_output, tokens_this_round = await self.stream_llm_call(
                        self._conversation_history,
                        temperature=0.1,
                        max_tokens=4096,  # ğŸ”¥ å¢åŠ åˆ° 4096ï¼Œé¿å…æˆªæ–­
                    )
                except asyncio.CancelledError:
                    logger.info(f"[{self.name}] LLM call cancelled")
                    break
                
                self._total_tokens += tokens_this_round

                # ğŸ”¥ Handle empty LLM response to prevent loops
                if not llm_output or not llm_output.strip():
                    logger.warning(f"[{self.name}] Empty LLM response in iteration {self._iteration}")
                    await self.emit_llm_decision("æ”¶åˆ°ç©ºå“åº”", "LLM è¿”å›å†…å®¹ä¸ºç©ºï¼Œå°è¯•é‡è¯•é€šè¿‡æç¤º")
                    self._conversation_history.append({
                        "role": "user",
                        "content": "Received empty response. Please output your Thought and Action.",
                    })
                    continue

                # è§£æ LLM å“åº”
                step = self._parse_llm_response(llm_output)
                self._steps.append(step)
                
                # ğŸ”¥ å‘å°„ LLM æ€è€ƒå†…å®¹äº‹ä»¶ - å±•ç¤ºéªŒè¯çš„æ€è€ƒè¿‡ç¨‹
                if step.thought:
                    await self.emit_llm_thought(step.thought, iteration + 1)
                
                # æ·»åŠ  LLM å“åº”åˆ°å†å²
                self._conversation_history.append({
                    "role": "assistant",
                    "content": llm_output,
                })
                
                # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                if step.is_final:
                    await self.emit_llm_decision("å®Œæˆæ¼æ´éªŒè¯", "LLM åˆ¤æ–­éªŒè¯å·²å……åˆ†")
                    final_result = step.final_answer
                    
                    # ğŸ”¥ è®°å½•æ´å¯Ÿå’Œå·¥ä½œ
                    if final_result and "findings" in final_result:
                        verified_count = len([f for f in final_result["findings"] if f.get("is_verified")])
                        fp_count = len([f for f in final_result["findings"] if f.get("verdict") == "false_positive"])
                        self.add_insight(f"éªŒè¯äº† {len(final_result['findings'])} ä¸ªå‘ç°ï¼Œ{verified_count} ä¸ªç¡®è®¤ï¼Œ{fp_count} ä¸ªè¯¯æŠ¥")
                        self.record_work(f"å®Œæˆæ¼æ´éªŒè¯: {verified_count} ä¸ªç¡®è®¤, {fp_count} ä¸ªè¯¯æŠ¥")
                    
                    await self.emit_llm_complete(
                        f"éªŒè¯å®Œæˆ",
                        self._total_tokens
                    )
                    break
                
                # æ‰§è¡Œå·¥å…·
                if step.action:
                    # ğŸ”¥ å‘å°„ LLM åŠ¨ä½œå†³ç­–äº‹ä»¶
                    await self.emit_llm_action(step.action, step.action_input or {})
                    
                    observation = await self.execute_tool(
                        step.action,
                        step.action_input or {}
                    )
                    
                    step.observation = observation
                    
                    # ğŸ”¥ å‘å°„ LLM è§‚å¯Ÿäº‹ä»¶
                    await self.emit_llm_observation(observation)
                    
                    # æ·»åŠ è§‚å¯Ÿç»“æœåˆ°å†å²
                    self._conversation_history.append({
                        "role": "user",
                        "content": f"Observation:\n{observation}",
                    })
                else:
                    # LLM æ²¡æœ‰é€‰æ‹©å·¥å…·ï¼Œæç¤ºå®ƒç»§ç»­
                    await self.emit_llm_decision("ç»§ç»­éªŒè¯", "LLM éœ€è¦æ›´å¤šéªŒè¯")
                    self._conversation_history.append({
                        "role": "user",
                        "content": "è¯·ç»§ç»­éªŒè¯ã€‚å¦‚æœéªŒè¯å®Œæˆï¼Œè¾“å‡º Final Answer æ±‡æ€»æ‰€æœ‰éªŒè¯ç»“æœã€‚",
                    })
            
            # å¤„ç†ç»“æœ
            duration_ms = int((time.time() - start_time) * 1000)
            
            # ğŸ”¥ å¦‚æœè¢«å–æ¶ˆï¼Œè¿”å›å–æ¶ˆç»“æœ
            if self.is_cancelled:
                await self.emit_event(
                    "info",
                    f"ğŸ›‘ Verification Agent å·²å–æ¶ˆ: {self._iteration} è½®è¿­ä»£"
                )
                return AgentResult(
                    success=False,
                    error="ä»»åŠ¡å·²å–æ¶ˆ",
                    data={"findings": findings_to_verify},
                    iterations=self._iteration,
                    tool_calls=self._tool_calls,
                    tokens_used=self._total_tokens,
                    duration_ms=duration_ms,
                )
            
            # å¤„ç†æœ€ç»ˆç»“æœ
            verified_findings = []
            if final_result and "findings" in final_result:
                for f in final_result["findings"]:
                    verified = {
                        **f,
                        "is_verified": f.get("verdict") == "confirmed" or (
                            f.get("verdict") == "likely" and f.get("confidence", 0) >= 0.8
                        ),
                        "verified_at": datetime.now(timezone.utc).isoformat() if f.get("verdict") in ["confirmed", "likely"] else None,
                    }
                    
                    # æ·»åŠ ä¿®å¤å»ºè®®
                    if not verified.get("recommendation"):
                        verified["recommendation"] = self._get_recommendation(f.get("vulnerability_type", ""))
                    
                    verified_findings.append(verified)
            else:
                # å¦‚æœæ²¡æœ‰æœ€ç»ˆç»“æœï¼Œä½¿ç”¨åŸå§‹å‘ç°
                for f in findings_to_verify:
                    verified_findings.append({
                        **f,
                        "verdict": "uncertain",
                        "confidence": 0.5,
                        "is_verified": False,
                    })
            
            # ç»Ÿè®¡
            confirmed_count = len([f for f in verified_findings if f.get("verdict") == "confirmed"])
            likely_count = len([f for f in verified_findings if f.get("verdict") == "likely"])
            false_positive_count = len([f for f in verified_findings if f.get("verdict") == "false_positive"])
            
            await self.emit_event(
                "info",
                f"Verification Agent å®Œæˆ: {confirmed_count} ç¡®è®¤, {likely_count} å¯èƒ½, {false_positive_count} è¯¯æŠ¥"
            )
            
            return AgentResult(
                success=True,
                data={
                    "findings": verified_findings,
                    "verified_count": confirmed_count,
                    "likely_count": likely_count,
                    "false_positive_count": false_positive_count,
                },
                iterations=self._iteration,
                tool_calls=self._tool_calls,
                tokens_used=self._total_tokens,
                duration_ms=duration_ms,
            )
            
        except Exception as e:
            logger.error(f"Verification Agent failed: {e}", exc_info=True)
            return AgentResult(success=False, error=str(e))
    
    def _get_recommendation(self, vuln_type: str) -> str:
        """è·å–ä¿®å¤å»ºè®®"""
        recommendations = {
            "sql_injection": "ä½¿ç”¨å‚æ•°åŒ–æŸ¥è¯¢æˆ– ORMï¼Œé¿å…å­—ç¬¦ä¸²æ‹¼æ¥æ„é€  SQL",
            "xss": "å¯¹ç”¨æˆ·è¾“å…¥è¿›è¡Œ HTML è½¬ä¹‰ï¼Œä½¿ç”¨ CSPï¼Œé¿å… innerHTML",
            "command_injection": "é¿å…ä½¿ç”¨ shell=Trueï¼Œä½¿ç”¨å‚æ•°åˆ—è¡¨ä¼ é€’å‘½ä»¤",
            "path_traversal": "éªŒè¯å’Œè§„èŒƒåŒ–è·¯å¾„ï¼Œä½¿ç”¨ç™½åå•ï¼Œé¿å…ç›´æ¥ä½¿ç”¨ç”¨æˆ·è¾“å…¥",
            "ssrf": "éªŒè¯å’Œé™åˆ¶ç›®æ ‡ URLï¼Œä½¿ç”¨ç™½åå•ï¼Œç¦æ­¢å†…ç½‘è®¿é—®",
            "deserialization": "é¿å…ååºåˆ—åŒ–ä¸å¯ä¿¡æ•°æ®ï¼Œä½¿ç”¨ JSON æ›¿ä»£ pickle/yaml",
            "hardcoded_secret": "ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–å¯†é’¥ç®¡ç†æœåŠ¡å­˜å‚¨æ•æ„Ÿä¿¡æ¯",
            "weak_crypto": "ä½¿ç”¨å¼ºåŠ å¯†ç®—æ³•ï¼ˆAES-256, SHA-256+ï¼‰ï¼Œé¿å… MD5/SHA1",
        }
        return recommendations.get(vuln_type, "è¯·æ ¹æ®å…·ä½“æƒ…å†µä¿®å¤æ­¤å®‰å…¨é—®é¢˜")
    
    def _deduplicate(self, findings: List[Dict]) -> List[Dict]:
        """å»é‡"""
        seen = set()
        unique = []
        
        for f in findings:
            key = (
                f.get("file_path", ""),
                f.get("line_start", 0),
                f.get("vulnerability_type", ""),
            )
            
            if key not in seen:
                seen.add(key)
                unique.append(f)
        
        return unique
    
    def get_conversation_history(self) -> List[Dict[str, str]]:
        """è·å–å¯¹è¯å†å²"""
        return self._conversation_history
    
    def get_steps(self) -> List[VerificationStep]:
        """è·å–æ‰§è¡Œæ­¥éª¤"""
        return self._steps
