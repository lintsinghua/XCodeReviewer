"""
DeepAudit LangGraph Runner
åŸºäº LangGraph çš„ Agent å®¡è®¡æ‰§è¡Œå™¨
"""

import asyncio
import logging
import os
import uuid
from datetime import datetime, timezone
from typing import Dict, List, Optional, Any, AsyncGenerator

from sqlalchemy.ext.asyncio import AsyncSession

from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

from app.services.agent.streaming import StreamHandler, StreamEvent, StreamEventType
from app.models.agent_task import (
    AgentTask, AgentEvent, AgentFinding,
    AgentTaskStatus, AgentTaskPhase, AgentEventType,
    VulnerabilitySeverity, VulnerabilityType, FindingStatus,
)
from app.services.agent.event_manager import EventManager, AgentEventEmitter
from app.services.agent.tools import (
    RAGQueryTool, SecurityCodeSearchTool, FunctionContextTool,
    PatternMatchTool, CodeAnalysisTool, DataFlowAnalysisTool, VulnerabilityValidationTool,
    FileReadTool, FileSearchTool, ListFilesTool,
    SandboxTool, SandboxHttpTool, VulnerabilityVerifyTool, SandboxManager,
    SemgrepTool, BanditTool, GitleaksTool, NpmAuditTool, SafetyTool,
    TruffleHogTool, OSVScannerTool,
)
from app.services.rag import CodeIndexer, CodeRetriever, EmbeddingService
from app.core.config import settings

from .audit_graph import AuditState, create_audit_graph
from .nodes import ReconNode, AnalysisNode, VerificationNode, ReportNode

logger = logging.getLogger(__name__)


class LLMService:
    """
    LLM æœåŠ¡å°è£…
    æä¾›ä»£ç åˆ†æã€æ¼æ´æ£€æµ‹ç­‰ AI åŠŸèƒ½
    """
    
    def __init__(self, model: Optional[str] = None, api_key: Optional[str] = None):
        self.model = model or settings.LLM_MODEL or "gpt-4o-mini"
        self.api_key = api_key or settings.LLM_API_KEY
        self.base_url = settings.LLM_BASE_URL
    
    async def chat_completion_raw(
        self,
        messages: List[Dict[str, str]],
        temperature: float = 0.1,
        max_tokens: int = 4096,
    ) -> Dict[str, Any]:
        """è°ƒç”¨ LLM ç”Ÿæˆå“åº”"""
        try:
            import litellm
            
            response = await litellm.acompletion(
                model=self.model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens,
                api_key=self.api_key,
                base_url=self.base_url,
            )
            
            return {
                "content": response.choices[0].message.content,
                "usage": {
                    "prompt_tokens": response.usage.prompt_tokens,
                    "completion_tokens": response.usage.completion_tokens,
                    "total_tokens": response.usage.total_tokens,
                } if response.usage else {},
            }
            
        except Exception as e:
            logger.error(f"LLM call failed: {e}")
            raise
    
    async def analyze_code(self, code: str, language: str) -> Dict[str, Any]:
        """
        åˆ†æä»£ç å®‰å…¨é—®é¢˜
        
        Args:
            code: ä»£ç å†…å®¹
            language: ç¼–ç¨‹è¯­è¨€
            
        Returns:
            åˆ†æç»“æœï¼ŒåŒ…å« issues åˆ—è¡¨
        """
        prompt = f"""è¯·åˆ†æä»¥ä¸‹ {language} ä»£ç çš„å®‰å…¨é—®é¢˜ã€‚

ä»£ç :
```{language}
{code[:8000]}
```

è¯·è¯†åˆ«æ‰€æœ‰æ½œåœ¨çš„å®‰å…¨æ¼æ´ï¼ŒåŒ…æ‹¬ä½†ä¸é™äº:
- SQL æ³¨å…¥
- XSS (è·¨ç«™è„šæœ¬)
- å‘½ä»¤æ³¨å…¥
- è·¯å¾„éå†
- ä¸å®‰å…¨çš„ååºåˆ—åŒ–
- ç¡¬ç¼–ç å¯†é’¥/å¯†ç 
- ä¸å®‰å…¨çš„åŠ å¯†
- SSRF
- è®¤è¯/æˆæƒé—®é¢˜

å¯¹äºæ¯ä¸ªå‘ç°çš„é—®é¢˜ï¼Œè¯·æä¾›:
1. æ¼æ´ç±»å‹
2. ä¸¥é‡ç¨‹åº¦ (critical/high/medium/low)
3. é—®é¢˜æè¿°
4. å…·ä½“è¡Œå·
5. ä¿®å¤å»ºè®®

è¯·ä»¥ JSON æ ¼å¼è¿”å›ç»“æœ:
{{
    "issues": [
        {{
            "type": "æ¼æ´ç±»å‹",
            "severity": "ä¸¥é‡ç¨‹åº¦",
            "title": "é—®é¢˜æ ‡é¢˜",
            "description": "è¯¦ç»†æè¿°",
            "line": è¡Œå·,
            "code_snippet": "ç›¸å…³ä»£ç ç‰‡æ®µ",
            "suggestion": "ä¿®å¤å»ºè®®"
        }}
    ],
    "quality_score": 0-100
}}

å¦‚æœæ²¡æœ‰å‘ç°å®‰å…¨é—®é¢˜ï¼Œè¿”å›ç©ºçš„ issues æ•°ç»„å’Œè¾ƒé«˜çš„ quality_scoreã€‚"""

        try:
            result = await self.chat_completion_raw(
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ä»£ç å®‰å…¨å®¡è®¡ä¸“å®¶ï¼Œæ“…é•¿å‘ç°ä»£ç ä¸­çš„å®‰å…¨æ¼æ´ã€‚è¯·åªè¿”å› JSON æ ¼å¼çš„ç»“æœï¼Œä¸è¦åŒ…å«å…¶ä»–å†…å®¹ã€‚"},
                    {"role": "user", "content": prompt},
                ],
                temperature=0.1,
                max_tokens=4096,
            )
            
            content = result.get("content", "{}")
            
            # å°è¯•æå– JSON
            import json
            import re
            
            # å°è¯•ç›´æ¥è§£æ
            try:
                return json.loads(content)
            except json.JSONDecodeError:
                pass
            
            # å°è¯•ä» markdown ä»£ç å—æå–
            json_match = re.search(r'```(?:json)?\s*([\s\S]*?)\s*```', content)
            if json_match:
                try:
                    return json.loads(json_match.group(1))
                except json.JSONDecodeError:
                    pass
            
            # è¿”å›ç©ºç»“æœ
            return {"issues": [], "quality_score": 80}
            
        except Exception as e:
            logger.error(f"Code analysis failed: {e}")
            return {"issues": [], "quality_score": 0, "error": str(e)}
    
    async def analyze_code_with_custom_prompt(
        self,
        code: str,
        language: str,
        prompt: str,
        **kwargs
    ) -> Dict[str, Any]:
        """ä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯åˆ†æä»£ç """
        full_prompt = prompt.replace("{code}", code).replace("{language}", language)
        
        try:
            result = await self.chat_completion_raw(
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ä»£ç å®‰å…¨å®¡è®¡ä¸“å®¶ã€‚"},
                    {"role": "user", "content": full_prompt},
                ],
                temperature=0.1,
            )
            
            return {
                "analysis": result.get("content", ""),
                "usage": result.get("usage", {}),
            }
            
        except Exception as e:
            logger.error(f"Custom analysis failed: {e}")
            return {"analysis": "", "error": str(e)}


class AgentRunner:
    """
    DeepAudit LangGraph Agent Runner
    
    åŸºäº LangGraph çŠ¶æ€å›¾çš„å®¡è®¡æ‰§è¡Œå™¨
    
    å·¥ä½œæµ:
        START â†’ Recon â†’ Analysis âŸ² â†’ Verification â†’ Report â†’ END
    """
    
    def __init__(
        self,
        db: AsyncSession,
        task: AgentTask,
        project_root: str,
    ):
        self.db = db
        self.task = task
        self.project_root = project_root
        
        # äº‹ä»¶ç®¡ç† - ä¼ å…¥ db_session_factory ä»¥æŒä¹…åŒ–äº‹ä»¶
        from app.db.session import async_session_factory
        self.event_manager = EventManager(db_session_factory=async_session_factory)
        self.event_emitter = AgentEventEmitter(task.id, self.event_manager)
        
        # LLM æœåŠ¡
        self.llm_service = LLMService()
        
        # å·¥å…·é›†
        self.tools: Dict[str, Any] = {}
        
        # RAG ç»„ä»¶
        self.retriever: Optional[CodeRetriever] = None
        self.indexer: Optional[CodeIndexer] = None
        
        # æ²™ç®±
        self.sandbox_manager: Optional[SandboxManager] = None
        
        # LangGraph
        self.graph: Optional[StateGraph] = None
        self.checkpointer = MemorySaver()
        
        # çŠ¶æ€
        self._cancelled = False
        self._running_task: Optional[asyncio.Task] = None
        
        # æµå¼å¤„ç†å™¨
        self.stream_handler = StreamHandler(task.id)
    
    def cancel(self):
        """å–æ¶ˆä»»åŠ¡"""
        self._cancelled = True
        if self._running_task and not self._running_task.done():
            self._running_task.cancel()
        logger.info(f"Task {self.task.id} cancellation requested")
    
    @property
    def is_cancelled(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å·²å–æ¶ˆ"""
        return self._cancelled
    
    async def initialize(self):
        """åˆå§‹åŒ– Runner"""
        await self.event_emitter.emit_info("ğŸš€ æ­£åœ¨åˆå§‹åŒ– DeepAudit LangGraph Agent...")
        
        # 1. åˆå§‹åŒ– RAG ç³»ç»Ÿ
        await self._initialize_rag()
        
        # 2. åˆå§‹åŒ–å·¥å…·
        await self._initialize_tools()
        
        # 3. æ„å»º LangGraph
        await self._build_graph()
        
        await self.event_emitter.emit_info("âœ… LangGraph ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    async def _initialize_rag(self):
        """åˆå§‹åŒ– RAG ç³»ç»Ÿ"""
        await self.event_emitter.emit_info("ğŸ“š åˆå§‹åŒ– RAG ä»£ç æ£€ç´¢ç³»ç»Ÿ...")
        
        try:
            embedding_service = EmbeddingService(
                provider=settings.EMBEDDING_PROVIDER,
                model=settings.EMBEDDING_MODEL,
                api_key=settings.LLM_API_KEY,
                base_url=settings.LLM_BASE_URL,
            )
            
            self.indexer = CodeIndexer(
                collection_name=f"project_{self.task.project_id}",
                embedding_service=embedding_service,
                persist_directory=settings.VECTOR_DB_PATH,
            )
            
            self.retriever = CodeRetriever(
                collection_name=f"project_{self.task.project_id}",
                embedding_service=embedding_service,
                persist_directory=settings.VECTOR_DB_PATH,
            )
            
        except Exception as e:
            logger.warning(f"RAG initialization failed: {e}")
            await self.event_emitter.emit_warning(f"RAG ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
    
    async def _initialize_tools(self):
        """åˆå§‹åŒ–å·¥å…·é›†"""
        await self.event_emitter.emit_info("ğŸ”§ åˆå§‹åŒ– Agent å·¥å…·é›†...")
        
        # æ–‡ä»¶å·¥å…·
        self.tools["read_file"] = FileReadTool(self.project_root)
        self.tools["search_code"] = FileSearchTool(self.project_root)
        self.tools["list_files"] = ListFilesTool(self.project_root)
        
        # RAG å·¥å…·
        if self.retriever:
            self.tools["rag_query"] = RAGQueryTool(self.retriever)
            self.tools["security_search"] = SecurityCodeSearchTool(self.retriever)
            self.tools["function_context"] = FunctionContextTool(self.retriever)
        
        # åˆ†æå·¥å…·
        self.tools["pattern_match"] = PatternMatchTool(self.project_root)
        self.tools["code_analysis"] = CodeAnalysisTool(self.llm_service)
        self.tools["dataflow_analysis"] = DataFlowAnalysisTool(self.llm_service)
        self.tools["vulnerability_validation"] = VulnerabilityValidationTool(self.llm_service)
        
        # å¤–éƒ¨å®‰å…¨å·¥å…·
        self.tools["semgrep_scan"] = SemgrepTool(self.project_root)
        self.tools["bandit_scan"] = BanditTool(self.project_root)
        self.tools["gitleaks_scan"] = GitleaksTool(self.project_root)
        self.tools["trufflehog_scan"] = TruffleHogTool(self.project_root)
        self.tools["npm_audit"] = NpmAuditTool(self.project_root)
        self.tools["safety_scan"] = SafetyTool(self.project_root)
        self.tools["osv_scan"] = OSVScannerTool(self.project_root)
        
        # æ²™ç®±å·¥å…·
        try:
            self.sandbox_manager = SandboxManager(
                image=settings.SANDBOX_IMAGE,
                memory_limit=settings.SANDBOX_MEMORY_LIMIT,
                cpu_limit=settings.SANDBOX_CPU_LIMIT,
            )
            
            self.tools["sandbox_exec"] = SandboxTool(self.sandbox_manager)
            self.tools["sandbox_http"] = SandboxHttpTool(self.sandbox_manager)
            self.tools["verify_vulnerability"] = VulnerabilityVerifyTool(self.sandbox_manager)
            
        except Exception as e:
            logger.warning(f"Sandbox initialization failed: {e}")
        
        await self.event_emitter.emit_info(f"âœ… å·²åŠ è½½ {len(self.tools)} ä¸ªå·¥å…·")
    
    async def _build_graph(self):
        """æ„å»º LangGraph å®¡è®¡å›¾"""
        await self.event_emitter.emit_info("ğŸ“Š æ„å»º LangGraph å®¡è®¡å·¥ä½œæµ...")
        
        # å¯¼å…¥ Agent
        from app.services.agent.agents import ReconAgent, AnalysisAgent, VerificationAgent
        
        # åˆ›å»º Agent å®ä¾‹
        recon_agent = ReconAgent(
            llm_service=self.llm_service,
            tools=self.tools,
            event_emitter=self.event_emitter,
        )
        
        analysis_agent = AnalysisAgent(
            llm_service=self.llm_service,
            tools=self.tools,
            event_emitter=self.event_emitter,
        )
        
        verification_agent = VerificationAgent(
            llm_service=self.llm_service,
            tools=self.tools,
            event_emitter=self.event_emitter,
        )
        
        # åˆ›å»ºèŠ‚ç‚¹
        recon_node = ReconNode(recon_agent, self.event_emitter)
        analysis_node = AnalysisNode(analysis_agent, self.event_emitter)
        verification_node = VerificationNode(verification_agent, self.event_emitter)
        report_node = ReportNode(None, self.event_emitter)
        
        # æ„å»ºå›¾
        self.graph = create_audit_graph(
            recon_node=recon_node,
            analysis_node=analysis_node,
            verification_node=verification_node,
            report_node=report_node,
            checkpointer=self.checkpointer,
        )
        
        await self.event_emitter.emit_info("âœ… LangGraph å·¥ä½œæµæ„å»ºå®Œæˆ")
    
    async def run(self) -> Dict[str, Any]:
        """
        æ‰§è¡Œ LangGraph å®¡è®¡
        
        Returns:
            æœ€ç»ˆçŠ¶æ€
        """
        result = {}
        async for _ in self.run_with_streaming():
            pass  # æ¶ˆè´¹æ‰€æœ‰äº‹ä»¶
        return result
    
    async def run_with_streaming(self) -> AsyncGenerator[StreamEvent, None]:
        """
        å¸¦æµå¼è¾“å‡ºçš„å®¡è®¡æ‰§è¡Œ
        
        Yields:
            StreamEvent: æµå¼äº‹ä»¶ï¼ˆåŒ…å« LLM æ€è€ƒã€å·¥å…·è°ƒç”¨ç­‰ï¼‰
        """
        import time
        start_time = time.time()
        
        try:
            # åˆå§‹åŒ–
            await self.initialize()
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            await self._update_task_status(AgentTaskStatus.RUNNING)
            
            # å‘å°„ä»»åŠ¡å¼€å§‹äº‹ä»¶
            yield StreamEvent(
                event_type=StreamEventType.TASK_START,
                sequence=self.stream_handler._next_sequence(),
                data={"task_id": self.task.id, "message": "ğŸš€ å®¡è®¡ä»»åŠ¡å¼€å§‹"},
            )
            
            # 1. ç´¢å¼•ä»£ç 
            await self._index_code()
            
            if self._cancelled:
                yield StreamEvent(
                    event_type=StreamEventType.TASK_CANCEL,
                    sequence=self.stream_handler._next_sequence(),
                    data={"message": "ä»»åŠ¡å·²å–æ¶ˆ"},
                )
                return
            
            # 2. æ”¶é›†é¡¹ç›®ä¿¡æ¯
            project_info = await self._collect_project_info()
            
            # 3. æ„å»ºåˆå§‹çŠ¶æ€
            task_config = {
                "target_vulnerabilities": self.task.target_vulnerabilities or [],
                "verification_level": self.task.verification_level or "sandbox",
                "exclude_patterns": self.task.exclude_patterns or [],
                "target_files": self.task.target_files or [],
                "max_iterations": self.task.max_iterations or 50,
                "timeout_seconds": self.task.timeout_seconds or 1800,
            }
            
            initial_state: AuditState = {
                "project_root": self.project_root,
                "project_info": project_info,
                "config": task_config,
                "task_id": self.task.id,
                "tech_stack": {},
                "entry_points": [],
                "high_risk_areas": [],
                "dependencies": {},
                "findings": [],
                "verified_findings": [],
                "false_positives": [],
                "current_phase": "start",
                "iteration": 0,
                "max_iterations": self.task.max_iterations or 50,
                "should_continue_analysis": False,
                "messages": [],
                "events": [],
                "summary": None,
                "security_score": None,
                "error": None,
            }
            
            # 4. æ‰§è¡Œ LangGraph with astream_events
            await self.event_emitter.emit_phase_start("langgraph", "ğŸ”„ å¯åŠ¨ LangGraph å·¥ä½œæµ")
            
            run_config = {
                "configurable": {
                    "thread_id": self.task.id,
                }
            }
            
            final_state = None
            
            # ä½¿ç”¨ astream_events è·å–è¯¦ç»†äº‹ä»¶æµ
            try:
                async for event in self.graph.astream_events(
                    initial_state,
                    config=run_config,
                    version="v2",
                ):
                    if self._cancelled:
                        break
                    
                    # å¤„ç† LangGraph äº‹ä»¶
                    stream_event = await self.stream_handler.process_langgraph_event(event)
                    if stream_event:
                        # åŒæ­¥åˆ° event_emitter ä»¥æŒä¹…åŒ–
                        await self._sync_stream_event_to_db(stream_event)
                        yield stream_event
                    
                    # æ›´æ–°æœ€ç»ˆçŠ¶æ€
                    if event.get("event") == "on_chain_end":
                        output = event.get("data", {}).get("output")
                        if isinstance(output, dict):
                            final_state = output
                            
            except Exception as e:
                # å¦‚æœ astream_events ä¸å¯ç”¨ï¼Œå›é€€åˆ° astream
                logger.warning(f"astream_events not available, falling back to astream: {e}")
                async for event in self.graph.astream(initial_state, config=run_config):
                    if self._cancelled:
                        break
                    
                    for node_name, node_output in event.items():
                        await self._handle_node_output(node_name, node_output)
                        
                        # å‘å°„èŠ‚ç‚¹äº‹ä»¶
                        yield StreamEvent(
                            event_type=StreamEventType.NODE_END,
                            sequence=self.stream_handler._next_sequence(),
                            node_name=node_name,
                            data={"message": f"èŠ‚ç‚¹ {node_name} å®Œæˆ"},
                        )
                        
                        phase_map = {
                            "recon": AgentTaskPhase.RECONNAISSANCE,
                            "analysis": AgentTaskPhase.ANALYSIS,
                            "verification": AgentTaskPhase.VERIFICATION,
                            "report": AgentTaskPhase.REPORTING,
                        }
                        if node_name in phase_map:
                            await self._update_task_phase(phase_map[node_name])
                        
                        final_state = node_output
            
            # 5. è·å–æœ€ç»ˆçŠ¶æ€
            if not final_state:
                graph_state = self.graph.get_state(run_config)
                final_state = graph_state.values if graph_state else {}
            
            # 6. ä¿å­˜å‘ç°
            findings = final_state.get("findings", [])
            await self._save_findings(findings)
            
            # å‘å°„å‘ç°äº‹ä»¶
            for finding in findings[:10]:  # é™åˆ¶æ•°é‡
                yield self.stream_handler.create_finding_event(
                    finding,
                    is_verified=finding.get("is_verified", False),
                )
            
            # 7. æ›´æ–°ä»»åŠ¡æ‘˜è¦
            summary = final_state.get("summary", {})
            security_score = final_state.get("security_score", 100)
            
            await self._update_task_summary(
                total_findings=len(findings),
                verified_count=len(final_state.get("verified_findings", [])),
                security_score=security_score,
            )
            
            # 8. å®Œæˆ
            duration_ms = int((time.time() - start_time) * 1000)
            
            await self._update_task_status(AgentTaskStatus.COMPLETED)
            await self.event_emitter.emit_task_complete(
                findings_count=len(findings),
                duration_ms=duration_ms,
            )
            
            yield StreamEvent(
                event_type=StreamEventType.TASK_COMPLETE,
                sequence=self.stream_handler._next_sequence(),
                data={
                    "findings_count": len(findings),
                    "verified_count": len(final_state.get("verified_findings", [])),
                    "security_score": security_score,
                    "duration_ms": duration_ms,
                    "message": f"âœ… å®¡è®¡å®Œæˆï¼å‘ç° {len(findings)} ä¸ªæ¼æ´",
                },
            )
            
        except asyncio.CancelledError:
            await self._update_task_status(AgentTaskStatus.CANCELLED)
            yield StreamEvent(
                event_type=StreamEventType.TASK_CANCEL,
                sequence=self.stream_handler._next_sequence(),
                data={"message": "ä»»åŠ¡å·²å–æ¶ˆ"},
            )
            
        except Exception as e:
            logger.error(f"LangGraph run failed: {e}", exc_info=True)
            await self._update_task_status(AgentTaskStatus.FAILED, str(e))
            await self.event_emitter.emit_error(str(e))
            
            yield StreamEvent(
                event_type=StreamEventType.TASK_ERROR,
                sequence=self.stream_handler._next_sequence(),
                data={"error": str(e), "message": f"âŒ å®¡è®¡å¤±è´¥: {e}"},
            )
            
        finally:
            await self._cleanup()
    
    async def _sync_stream_event_to_db(self, event: StreamEvent):
        """åŒæ­¥æµå¼äº‹ä»¶åˆ°æ•°æ®åº“"""
        try:
            # å°† StreamEvent è½¬æ¢ä¸º AgentEventData
            await self.event_manager.add_event(
                task_id=self.task.id,
                event_type=event.event_type.value,
                sequence=event.sequence,
                phase=event.phase,
                message=event.data.get("message"),
                tool_name=event.tool_name,
                tool_input=event.data.get("input") or event.data.get("input_params"),
                tool_output=event.data.get("output") or event.data.get("output_data"),
                tool_duration_ms=event.data.get("duration_ms"),
                metadata=event.data,
            )
        except Exception as e:
            logger.warning(f"Failed to sync stream event to db: {e}")
    
    async def _handle_node_output(self, node_name: str, output: Dict[str, Any]):
        """å¤„ç†èŠ‚ç‚¹è¾“å‡º"""
        # å‘å°„èŠ‚ç‚¹äº‹ä»¶
        events = output.get("events", [])
        for evt in events:
            await self.event_emitter.emit_info(
                f"[{node_name}] {evt.get('type', 'event')}: {evt.get('data', {})}"
            )
        
        # å¤„ç†æ–°å‘ç°
        if node_name == "analysis":
            new_findings = output.get("findings", [])
            if new_findings:
                for finding in new_findings[:5]:  # é™åˆ¶äº‹ä»¶æ•°é‡
                    await self.event_emitter.emit_finding(
                        title=finding.get("title", "Unknown"),
                        severity=finding.get("severity", "medium"),
                        file_path=finding.get("file_path"),
                    )
        
        # å¤„ç†éªŒè¯ç»“æœ
        if node_name == "verification":
            verified = output.get("verified_findings", [])
            for v in verified[:5]:
                await self.event_emitter.emit_info(
                    f"âœ… å·²éªŒè¯: {v.get('title', 'Unknown')}"
                )
        
        # å¤„ç†é”™è¯¯
        if output.get("error"):
            await self.event_emitter.emit_error(output["error"])
    
    async def _index_code(self):
        """ç´¢å¼•ä»£ç """
        if not self.indexer:
            await self.event_emitter.emit_warning("RAG æœªåˆå§‹åŒ–ï¼Œè·³è¿‡ä»£ç ç´¢å¼•")
            return
        
        await self._update_task_phase(AgentTaskPhase.INDEXING)
        await self.event_emitter.emit_phase_start("indexing", "ğŸ“ å¼€å§‹ä»£ç ç´¢å¼•")
        
        try:
            async for progress in self.indexer.index_directory(self.project_root):
                if self._cancelled:
                    return
                
                await self.event_emitter.emit_progress(
                    progress.processed_files,
                    progress.total_files,
                    f"æ­£åœ¨ç´¢å¼•: {progress.current_file or 'N/A'}"
                )
            
            await self.event_emitter.emit_phase_complete("indexing", "âœ… ä»£ç ç´¢å¼•å®Œæˆ")
            
        except Exception as e:
            logger.warning(f"Code indexing failed: {e}")
            await self.event_emitter.emit_warning(f"ä»£ç ç´¢å¼•å¤±è´¥: {e}")
    
    async def _collect_project_info(self) -> Dict[str, Any]:
        """æ”¶é›†é¡¹ç›®ä¿¡æ¯"""
        info = {
            "name": self.task.project.name if self.task.project else "unknown",
            "root": self.project_root,
            "languages": [],
            "file_count": 0,
        }
        
        try:
            exclude_dirs = {
                "node_modules", "__pycache__", ".git", "venv", ".venv",
                "build", "dist", "target", ".idea", ".vscode",
            }
            
            for root, dirs, files in os.walk(self.project_root):
                dirs[:] = [d for d in dirs if d not in exclude_dirs]
                info["file_count"] += len(files)
                
                lang_map = {
                    ".py": "Python", ".js": "JavaScript", ".ts": "TypeScript",
                    ".java": "Java", ".go": "Go", ".php": "PHP",
                    ".rb": "Ruby", ".rs": "Rust", ".c": "C", ".cpp": "C++",
                }
                
                for f in files:
                    ext = os.path.splitext(f)[1].lower()
                    if ext in lang_map and lang_map[ext] not in info["languages"]:
                        info["languages"].append(lang_map[ext])
                        
        except Exception as e:
            logger.warning(f"Failed to collect project info: {e}")
        
        return info
    
    async def _save_findings(self, findings: List[Dict]):
        """ä¿å­˜å‘ç°åˆ°æ•°æ®åº“"""
        severity_map = {
            "critical": VulnerabilitySeverity.CRITICAL,
            "high": VulnerabilitySeverity.HIGH,
            "medium": VulnerabilitySeverity.MEDIUM,
            "low": VulnerabilitySeverity.LOW,
            "info": VulnerabilitySeverity.INFO,
        }
        
        type_map = {
            "sql_injection": VulnerabilityType.SQL_INJECTION,
            "nosql_injection": VulnerabilityType.NOSQL_INJECTION,
            "xss": VulnerabilityType.XSS,
            "command_injection": VulnerabilityType.COMMAND_INJECTION,
            "code_injection": VulnerabilityType.CODE_INJECTION,
            "path_traversal": VulnerabilityType.PATH_TRAVERSAL,
            "file_inclusion": VulnerabilityType.FILE_INCLUSION,
            "ssrf": VulnerabilityType.SSRF,
            "xxe": VulnerabilityType.XXE,
            "deserialization": VulnerabilityType.DESERIALIZATION,
            "auth_bypass": VulnerabilityType.AUTH_BYPASS,
            "idor": VulnerabilityType.IDOR,
            "sensitive_data_exposure": VulnerabilityType.SENSITIVE_DATA_EXPOSURE,
            "hardcoded_secret": VulnerabilityType.HARDCODED_SECRET,
            "weak_crypto": VulnerabilityType.WEAK_CRYPTO,
            "race_condition": VulnerabilityType.RACE_CONDITION,
            "business_logic": VulnerabilityType.BUSINESS_LOGIC,
            "memory_corruption": VulnerabilityType.MEMORY_CORRUPTION,
        }
        
        for finding in findings:
            try:
                db_finding = AgentFinding(
                    id=str(uuid.uuid4()),
                    task_id=self.task.id,
                    vulnerability_type=type_map.get(
                        finding.get("vulnerability_type", "other"),
                        VulnerabilityType.OTHER
                    ),
                    severity=severity_map.get(
                        finding.get("severity", "medium"),
                        VulnerabilitySeverity.MEDIUM
                    ),
                    title=finding.get("title", "Unknown"),
                    description=finding.get("description", ""),
                    file_path=finding.get("file_path"),
                    line_start=finding.get("line_start"),
                    line_end=finding.get("line_end"),
                    code_snippet=finding.get("code_snippet"),
                    source=finding.get("source"),
                    sink=finding.get("sink"),
                    suggestion=finding.get("suggestion") or finding.get("recommendation"),
                    is_verified=finding.get("is_verified", False),
                    confidence=finding.get("confidence", 0.5),
                    poc=finding.get("poc"),
                    status=FindingStatus.VERIFIED if finding.get("is_verified") else FindingStatus.NEW,
                )
                
                self.db.add(db_finding)
                
            except Exception as e:
                logger.warning(f"Failed to save finding: {e}")
        
        try:
            await self.db.commit()
        except Exception as e:
            logger.error(f"Failed to commit findings: {e}")
            await self.db.rollback()
    
    async def _update_task_status(
        self,
        status: AgentTaskStatus,
        error: Optional[str] = None
    ):
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        self.task.status = status
        
        if status == AgentTaskStatus.RUNNING:
            self.task.started_at = datetime.now(timezone.utc)
        elif status in [AgentTaskStatus.COMPLETED, AgentTaskStatus.FAILED, AgentTaskStatus.CANCELLED]:
            self.task.finished_at = datetime.now(timezone.utc)
        
        if error:
            self.task.error_message = error
        
        try:
            await self.db.commit()
        except Exception as e:
            logger.error(f"Failed to update task status: {e}")
    
    async def _update_task_phase(self, phase: AgentTaskPhase):
        """æ›´æ–°ä»»åŠ¡é˜¶æ®µ"""
        self.task.current_phase = phase
        try:
            await self.db.commit()
        except Exception as e:
            logger.error(f"Failed to update task phase: {e}")
    
    async def _update_task_summary(
        self,
        total_findings: int,
        verified_count: int,
        security_score: int,
    ):
        """æ›´æ–°ä»»åŠ¡æ‘˜è¦"""
        self.task.total_findings = total_findings
        self.task.verified_findings = verified_count
        self.task.security_score = security_score
        
        try:
            await self.db.commit()
        except Exception as e:
            logger.error(f"Failed to update task summary: {e}")
    
    async def _cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            if self.sandbox_manager:
                await self.sandbox_manager.cleanup()
            await self.event_manager.close()
        except Exception as e:
            logger.warning(f"Cleanup error: {e}")


# ä¾¿æ·å‡½æ•°
async def run_agent_task(
    db: AsyncSession,
    task: AgentTask,
    project_root: str,
) -> Dict[str, Any]:
    """
    è¿è¡Œ Agent å®¡è®¡ä»»åŠ¡
    
    Args:
        db: æ•°æ®åº“ä¼šè¯
        task: Agent ä»»åŠ¡
        project_root: é¡¹ç›®æ ¹ç›®å½•
        
    Returns:
        å®¡è®¡ç»“æœ
    """
    runner = AgentRunner(db, task, project_root)
    return await runner.run()

