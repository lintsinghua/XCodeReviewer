"""
DeepAudit LangGraph Runner
åŸºäº LangGraph çš„ Agent å®¡è®¡æ‰§è¡Œå™¨
"""

import asyncio
import logging
import os
import uuid
from datetime import datetime, timezone
from typing import Dict, List, Optional, Any, AsyncGenerator

from sqlalchemy.ext.asyncio import AsyncSession

from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

from app.services.agent.streaming import StreamHandler, StreamEvent, StreamEventType
from app.models.agent_task import (
    AgentTask, AgentEvent, AgentFinding,
    AgentTaskStatus, AgentTaskPhase, AgentEventType,
    VulnerabilitySeverity, VulnerabilityType, FindingStatus,
)
from app.services.agent.event_manager import EventManager, AgentEventEmitter
from app.services.agent.tools import (
    RAGQueryTool, SecurityCodeSearchTool, FunctionContextTool,
    PatternMatchTool, CodeAnalysisTool, DataFlowAnalysisTool, VulnerabilityValidationTool,
    FileReadTool, FileSearchTool, ListFilesTool,
    SandboxTool, SandboxHttpTool, VulnerabilityVerifyTool, SandboxManager,
    SemgrepTool, BanditTool, GitleaksTool, NpmAuditTool, SafetyTool,
    TruffleHogTool, OSVScannerTool,
)
from app.services.rag import CodeIndexer, CodeRetriever, EmbeddingService
from app.core.config import settings

from .audit_graph import AuditState, create_audit_graph
from .nodes import ReconNode, AnalysisNode, VerificationNode, ReportNode

logger = logging.getLogger(__name__)


# ğŸ”¥ ä½¿ç”¨ç³»ç»Ÿç»Ÿä¸€çš„ LLMServiceï¼ˆæ”¯æŒç”¨æˆ·é…ç½®ï¼‰
from app.services.llm.service import LLMService


class AgentRunner:
    """
    DeepAudit LangGraph Agent Runner
    
    åŸºäº LangGraph çŠ¶æ€å›¾çš„å®¡è®¡æ‰§è¡Œå™¨
    
    å·¥ä½œæµ:
        START â†’ Recon â†’ Analysis âŸ² â†’ Verification â†’ Report â†’ END
    """
    
    def __init__(
        self,
        db: AsyncSession,
        task: AgentTask,
        project_root: str,
        user_config: Optional[Dict[str, Any]] = None,
    ):
        self.db = db
        self.task = task
        self.project_root = project_root
        
        # ğŸ”¥ ä¿å­˜ç”¨æˆ·é…ç½®ï¼Œä¾› RAG åˆå§‹åŒ–ä½¿ç”¨
        self.user_config = user_config or {}
        
        # äº‹ä»¶ç®¡ç† - ä¼ å…¥ db_session_factory ä»¥æŒä¹…åŒ–äº‹ä»¶
        from app.db.session import async_session_factory
        self.event_manager = EventManager(db_session_factory=async_session_factory)
        self.event_emitter = AgentEventEmitter(task.id, self.event_manager)
        
        # ğŸ”¥ LLM æœåŠ¡ - ä½¿ç”¨ç”¨æˆ·é…ç½®ï¼ˆä»ç³»ç»Ÿé…ç½®é¡µé¢è·å–ï¼‰
        self.llm_service = LLMService(user_config=self.user_config)
        
        # å·¥å…·é›†
        self.tools: Dict[str, Any] = {}
        
        # RAG ç»„ä»¶
        self.retriever: Optional[CodeRetriever] = None
        self.indexer: Optional[CodeIndexer] = None
        
        # æ²™ç®±
        self.sandbox_manager: Optional[SandboxManager] = None
        
        # LangGraph
        self.graph: Optional[StateGraph] = None
        self.checkpointer = MemorySaver()
        
        # çŠ¶æ€
        self._cancelled = False
        self._running_task: Optional[asyncio.Task] = None
        
        # Agent å¼•ç”¨ï¼ˆç”¨äºå–æ¶ˆä¼ æ’­ï¼‰
        self._agents: List[Any] = []
        
        # æµå¼å¤„ç†å™¨
        self.stream_handler = StreamHandler(task.id)
    
    def cancel(self):
        """å–æ¶ˆä»»åŠ¡"""
        self._cancelled = True
        
        # ğŸ”¥ å–æ¶ˆæ‰€æœ‰ Agent
        for agent in self._agents:
            if hasattr(agent, 'cancel'):
                agent.cancel()
                logger.debug(f"Cancelled agent: {agent.name if hasattr(agent, 'name') else 'unknown'}")
        
        # å–æ¶ˆè¿è¡Œä¸­çš„ä»»åŠ¡
        if self._running_task and not self._running_task.done():
            self._running_task.cancel()
        
        logger.info(f"Task {self.task.id} cancellation requested")
    
    @property
    def is_cancelled(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å·²å–æ¶ˆ"""
        return self._cancelled
    
    async def initialize(self):
        """åˆå§‹åŒ– Runner"""
        await self.event_emitter.emit_info("ğŸš€ æ­£åœ¨åˆå§‹åŒ– DeepAudit LangGraph Agent...")
        
        # 1. åˆå§‹åŒ– RAG ç³»ç»Ÿ
        await self._initialize_rag()
        
        # 2. åˆå§‹åŒ–å·¥å…·
        await self._initialize_tools()
        
        # 3. æ„å»º LangGraph
        await self._build_graph()
        
        await self.event_emitter.emit_info("âœ… LangGraph ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    async def _initialize_rag(self):
        """åˆå§‹åŒ– RAG ç³»ç»Ÿ"""
        await self.event_emitter.emit_info("ğŸ“š åˆå§‹åŒ– RAG ä»£ç æ£€ç´¢ç³»ç»Ÿ...")
        
        try:
            # ğŸ”¥ ä»ç”¨æˆ·é…ç½®ä¸­è·å– LLM é…ç½®ï¼ˆç”¨äº Embedding API Keyï¼‰
            # ä¼˜å…ˆçº§ï¼šç”¨æˆ·é…ç½® > ç¯å¢ƒå˜é‡
            user_llm_config = self.user_config.get('llmConfig', {})
            
            # è·å– Embedding é…ç½®ï¼ˆä¼˜å…ˆä½¿ç”¨ç”¨æˆ·é…ç½®çš„ LLM API Keyï¼‰
            embedding_provider = getattr(settings, 'EMBEDDING_PROVIDER', 'openai')
            embedding_model = getattr(settings, 'EMBEDDING_MODEL', 'text-embedding-3-small')
            
            # ğŸ”¥ API Key ä¼˜å…ˆçº§ï¼šç”¨æˆ·é…ç½® > ç¯å¢ƒå˜é‡
            embedding_api_key = (
                user_llm_config.get('llmApiKey') or
                getattr(settings, 'LLM_API_KEY', '') or
                ''
            )
            
            # ğŸ”¥ Base URL ä¼˜å…ˆçº§ï¼šç”¨æˆ·é…ç½® > ç¯å¢ƒå˜é‡
            embedding_base_url = (
                user_llm_config.get('llmBaseUrl') or
                getattr(settings, 'LLM_BASE_URL', None) or
                None
            )
            
            embedding_service = EmbeddingService(
                provider=embedding_provider,
                model=embedding_model,
                api_key=embedding_api_key,
                base_url=embedding_base_url,
            )
            
            self.indexer = CodeIndexer(
                collection_name=f"project_{self.task.project_id}",
                embedding_service=embedding_service,
                persist_directory=settings.VECTOR_DB_PATH,
            )
            
            self.retriever = CodeRetriever(
                collection_name=f"project_{self.task.project_id}",
                embedding_service=embedding_service,
                persist_directory=settings.VECTOR_DB_PATH,
            )
            
        except Exception as e:
            logger.warning(f"RAG initialization failed: {e}")
            await self.event_emitter.emit_warning(f"RAG ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
    
    async def _initialize_tools(self):
        """åˆå§‹åŒ–å·¥å…·é›†"""
        await self.event_emitter.emit_info("åˆå§‹åŒ– Agent å·¥å…·é›†...")
        
        # ============ åŸºç¡€å·¥å…·ï¼ˆæ‰€æœ‰ Agent å…±äº«ï¼‰============
        base_tools = {
            "read_file": FileReadTool(self.project_root),
            "list_files": ListFilesTool(self.project_root),
        }
        
        # ============ Recon Agent ä¸“å±å·¥å…· ============
        # èŒè´£ï¼šä¿¡æ¯æ”¶é›†ã€é¡¹ç›®ç»“æ„åˆ†æã€æŠ€æœ¯æ ˆè¯†åˆ«
        self.recon_tools = {
            **base_tools,
            "search_code": FileSearchTool(self.project_root),
        }
        
        # RAG å·¥å…·ï¼ˆRecon ç”¨äºè¯­ä¹‰æœç´¢ï¼‰
        if self.retriever:
            self.recon_tools["rag_query"] = RAGQueryTool(self.retriever)
        
        # ============ Analysis Agent ä¸“å±å·¥å…· ============
        # èŒè´£ï¼šæ¼æ´åˆ†æã€ä»£ç å®¡è®¡ã€æ¨¡å¼åŒ¹é…
        self.analysis_tools = {
            **base_tools,
            "search_code": FileSearchTool(self.project_root),
            # æ¨¡å¼åŒ¹é…å’Œä»£ç åˆ†æ
            "pattern_match": PatternMatchTool(self.project_root),
            "code_analysis": CodeAnalysisTool(self.llm_service),
            "dataflow_analysis": DataFlowAnalysisTool(self.llm_service),
            # å¤–éƒ¨é™æ€åˆ†æå·¥å…·
            "semgrep_scan": SemgrepTool(self.project_root),
            "bandit_scan": BanditTool(self.project_root),
            "gitleaks_scan": GitleaksTool(self.project_root),
            "trufflehog_scan": TruffleHogTool(self.project_root),
            "npm_audit": NpmAuditTool(self.project_root),
            "safety_scan": SafetyTool(self.project_root),
            "osv_scan": OSVScannerTool(self.project_root),
        }
        
        # RAG å·¥å…·ï¼ˆAnalysis ç”¨äºå®‰å…¨ç›¸å…³ä»£ç æœç´¢ï¼‰
        if self.retriever:
            self.analysis_tools["security_search"] = SecurityCodeSearchTool(self.retriever)
            self.analysis_tools["function_context"] = FunctionContextTool(self.retriever)
        
        # ============ Verification Agent ä¸“å±å·¥å…· ============
        # èŒè´£ï¼šæ¼æ´éªŒè¯ã€PoC æ‰§è¡Œã€è¯¯æŠ¥æ’é™¤
        self.verification_tools = {
            **base_tools,
            # éªŒè¯å·¥å…·
            "vulnerability_validation": VulnerabilityValidationTool(self.llm_service),
            "dataflow_analysis": DataFlowAnalysisTool(self.llm_service),
        }
        
        # æ²™ç®±å·¥å…·ï¼ˆä»… Verification Agent å¯ç”¨ï¼‰
        try:
            self.sandbox_manager = SandboxManager(
                image=settings.SANDBOX_IMAGE,
                memory_limit=settings.SANDBOX_MEMORY_LIMIT,
                cpu_limit=settings.SANDBOX_CPU_LIMIT,
            )
            
            self.verification_tools["sandbox_exec"] = SandboxTool(self.sandbox_manager)
            self.verification_tools["sandbox_http"] = SandboxHttpTool(self.sandbox_manager)
            self.verification_tools["verify_vulnerability"] = VulnerabilityVerifyTool(self.sandbox_manager)
            
        except Exception as e:
            logger.warning(f"Sandbox initialization failed: {e}")
        
        # ç»Ÿè®¡æ€»å·¥å…·æ•°
        total_tools = len(set(
            list(self.recon_tools.keys()) + 
            list(self.analysis_tools.keys()) + 
            list(self.verification_tools.keys())
        ))
        await self.event_emitter.emit_info(f"å·²åŠ è½½ {total_tools} ä¸ªå·¥å…·")
    
    async def _build_graph(self):
        """æ„å»º LangGraph å®¡è®¡å›¾"""
        await self.event_emitter.emit_info("ğŸ“Š æ„å»º LangGraph å®¡è®¡å·¥ä½œæµ...")
        
        # å¯¼å…¥ Agent
        from app.services.agent.agents import ReconAgent, AnalysisAgent, VerificationAgent
        
        # åˆ›å»º Agent å®ä¾‹ï¼ˆæ¯ä¸ª Agent ä½¿ç”¨ä¸“å±å·¥å…·é›†ï¼‰
        recon_agent = ReconAgent(
            llm_service=self.llm_service,
            tools=self.recon_tools,  # Recon ä¸“å±å·¥å…·
            event_emitter=self.event_emitter,
        )
        
        analysis_agent = AnalysisAgent(
            llm_service=self.llm_service,
            tools=self.analysis_tools,  # Analysis ä¸“å±å·¥å…·
            event_emitter=self.event_emitter,
        )
        
        verification_agent = VerificationAgent(
            llm_service=self.llm_service,
            tools=self.verification_tools,  # Verification ä¸“å±å·¥å…·
            event_emitter=self.event_emitter,
        )
        
        # ğŸ”¥ ä¿å­˜ Agent å¼•ç”¨ä»¥ä¾¿å–æ¶ˆæ—¶ä¼ æ’­ä¿¡å·
        self._agents = [recon_agent, analysis_agent, verification_agent]
        
        # åˆ›å»ºèŠ‚ç‚¹
        recon_node = ReconNode(recon_agent, self.event_emitter)
        analysis_node = AnalysisNode(analysis_agent, self.event_emitter)
        verification_node = VerificationNode(verification_agent, self.event_emitter)
        report_node = ReportNode(None, self.event_emitter)
        
        # æ„å»ºå›¾
        self.graph = create_audit_graph(
            recon_node=recon_node,
            analysis_node=analysis_node,
            verification_node=verification_node,
            report_node=report_node,
            checkpointer=self.checkpointer,
        )
        
        await self.event_emitter.emit_info("âœ… LangGraph å·¥ä½œæµæ„å»ºå®Œæˆ")
    
    async def run(self) -> Dict[str, Any]:
        """
        æ‰§è¡Œ LangGraph å®¡è®¡
        
        Returns:
            æœ€ç»ˆçŠ¶æ€
        """
        final_state = {}
        try:
            async for event in self.run_with_streaming():
                # æ”¶é›†æœ€ç»ˆçŠ¶æ€
                if event.event_type == StreamEventType.TASK_COMPLETE:
                    final_state = event.data
                elif event.event_type == StreamEventType.TASK_ERROR:
                    final_state = {"success": False, "error": event.data.get("error")}
        except Exception as e:
            logger.error(f"Agent run failed: {e}", exc_info=True)
            final_state = {"success": False, "error": str(e)}
        
        return final_state
    
    async def run_with_streaming(self) -> AsyncGenerator[StreamEvent, None]:
        """
        å¸¦æµå¼è¾“å‡ºçš„å®¡è®¡æ‰§è¡Œ
        
        Yields:
            StreamEvent: æµå¼äº‹ä»¶ï¼ˆåŒ…å« LLM æ€è€ƒã€å·¥å…·è°ƒç”¨ç­‰ï¼‰
        """
        import time
        start_time = time.time()
        
        try:
            # åˆå§‹åŒ–
            await self.initialize()
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            await self._update_task_status(AgentTaskStatus.RUNNING)
            
            # å‘å°„ä»»åŠ¡å¼€å§‹äº‹ä»¶
            yield StreamEvent(
                event_type=StreamEventType.TASK_START,
                sequence=self.stream_handler._next_sequence(),
                data={"task_id": self.task.id, "message": "ğŸš€ å®¡è®¡ä»»åŠ¡å¼€å§‹"},
            )
            
            # 1. ç´¢å¼•ä»£ç 
            await self._index_code()
            
            if self._cancelled:
                yield StreamEvent(
                    event_type=StreamEventType.TASK_CANCEL,
                    sequence=self.stream_handler._next_sequence(),
                    data={"message": "ä»»åŠ¡å·²å–æ¶ˆ"},
                )
                return
            
            # 2. æ”¶é›†é¡¹ç›®ä¿¡æ¯
            project_info = await self._collect_project_info()
            
            # 3. æ„å»ºåˆå§‹çŠ¶æ€
            task_config = {
                "target_vulnerabilities": self.task.target_vulnerabilities or [],
                "verification_level": self.task.verification_level or "sandbox",
                "exclude_patterns": self.task.exclude_patterns or [],
                "target_files": self.task.target_files or [],
                "max_iterations": self.task.max_iterations or 50,
                "timeout_seconds": self.task.timeout_seconds or 1800,
            }
            
            initial_state: AuditState = {
                "project_root": self.project_root,
                "project_info": project_info,
                "config": task_config,
                "task_id": self.task.id,
                "tech_stack": {},
                "entry_points": [],
                "high_risk_areas": [],
                "dependencies": {},
                "findings": [],
                "verified_findings": [],
                "false_positives": [],
                "current_phase": "start",
                "iteration": 0,
                "max_iterations": self.task.max_iterations or 50,
                "should_continue_analysis": False,
                # ğŸ”¥ Agent åä½œäº¤æ¥ä¿¡æ¯
                "recon_handoff": None,
                "analysis_handoff": None,
                "verification_handoff": None,
                "messages": [],
                "events": [],
                "summary": None,
                "security_score": None,
                "error": None,
            }
            
            # 4. æ‰§è¡Œ LangGraph with astream_events
            await self.event_emitter.emit_phase_start("langgraph", "ğŸ”„ å¯åŠ¨ LangGraph å·¥ä½œæµ")
            
            run_config = {
                "configurable": {
                    "thread_id": self.task.id,
                }
            }
            
            final_state = None
            
            # ä½¿ç”¨ astream_events è·å–è¯¦ç»†äº‹ä»¶æµ
            try:
                async for event in self.graph.astream_events(
                    initial_state,
                    config=run_config,
                    version="v2",
                ):
                    if self._cancelled:
                        break
                    
                    # å¤„ç† LangGraph äº‹ä»¶
                    stream_event = await self.stream_handler.process_langgraph_event(event)
                    if stream_event:
                        # åŒæ­¥åˆ° event_emitter ä»¥æŒä¹…åŒ–
                        await self._sync_stream_event_to_db(stream_event)
                        yield stream_event
                    
                    # æ›´æ–°æœ€ç»ˆçŠ¶æ€
                    if event.get("event") == "on_chain_end":
                        output = event.get("data", {}).get("output")
                        if isinstance(output, dict):
                            final_state = output
                            
            except Exception as e:
                # å¦‚æœ astream_events ä¸å¯ç”¨ï¼Œå›é€€åˆ° astream
                logger.warning(f"astream_events not available, falling back to astream: {e}")
                async for event in self.graph.astream(initial_state, config=run_config):
                    if self._cancelled:
                        break
                    
                    for node_name, node_output in event.items():
                        await self._handle_node_output(node_name, node_output)
                        
                        # å‘å°„èŠ‚ç‚¹äº‹ä»¶
                        yield StreamEvent(
                            event_type=StreamEventType.NODE_END,
                            sequence=self.stream_handler._next_sequence(),
                            node_name=node_name,
                            data={"message": f"èŠ‚ç‚¹ {node_name} å®Œæˆ"},
                        )
                        
                        phase_map = {
                            "recon": AgentTaskPhase.RECONNAISSANCE,
                            "analysis": AgentTaskPhase.ANALYSIS,
                            "verification": AgentTaskPhase.VERIFICATION,
                            "report": AgentTaskPhase.REPORTING,
                        }
                        if node_name in phase_map:
                            await self._update_task_phase(phase_map[node_name])
                        
                        final_state = node_output
            
            # 5. è·å–æœ€ç»ˆçŠ¶æ€
            if not final_state:
                graph_state = self.graph.get_state(run_config)
                final_state = graph_state.values if graph_state else {}
            
            # ğŸ”¥ æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
            error = final_state.get("error")
            if error:
                # æ£€æŸ¥æ˜¯å¦æ˜¯ LLM è®¤è¯é”™è¯¯
                error_str = str(error)
                if "AuthenticationError" in error_str or "API key" in error_str or "invalid_api_key" in error_str:
                    error_message = "LLM API å¯†é’¥é…ç½®é”™è¯¯ã€‚è¯·æ£€æŸ¥ç¯å¢ƒå˜é‡ LLM_API_KEY æˆ–é…ç½®ä¸­çš„ API å¯†é’¥æ˜¯å¦æ­£ç¡®ã€‚"
                    logger.error(f"LLM authentication error: {error}")
                else:
                    error_message = error_str
                
                duration_ms = int((time.time() - start_time) * 1000)
                
                # æ ‡è®°ä»»åŠ¡ä¸ºå¤±è´¥
                await self._update_task_status(AgentTaskStatus.FAILED, error_message)
                await self.event_emitter.emit_task_error(error_message)
                
                yield StreamEvent(
                    event_type=StreamEventType.TASK_ERROR,
                    sequence=self.stream_handler._next_sequence(),
                    data={
                        "error": error_message,
                        "message": f"âŒ ä»»åŠ¡å¤±è´¥: {error_message}",
                    },
                )
                return
            
            # 6. ä¿å­˜å‘ç°
            findings = final_state.get("findings", [])
            await self._save_findings(findings)
            
            # å‘å°„å‘ç°äº‹ä»¶
            for finding in findings[:10]:  # é™åˆ¶æ•°é‡
                yield self.stream_handler.create_finding_event(
                    finding,
                    is_verified=finding.get("is_verified", False),
                )
            
            # 7. æ›´æ–°ä»»åŠ¡æ‘˜è¦
            summary = final_state.get("summary", {})
            security_score = final_state.get("security_score", 100)
            
            await self._update_task_summary(
                total_findings=len(findings),
                verified_count=len(final_state.get("verified_findings", [])),
                security_score=security_score,
            )
            
            # 8. å®Œæˆ
            duration_ms = int((time.time() - start_time) * 1000)
            
            await self._update_task_status(AgentTaskStatus.COMPLETED)
            await self.event_emitter.emit_task_complete(
                findings_count=len(findings),
                duration_ms=duration_ms,
            )
            
            yield StreamEvent(
                event_type=StreamEventType.TASK_COMPLETE,
                sequence=self.stream_handler._next_sequence(),
                data={
                    "findings_count": len(findings),
                    "verified_count": len(final_state.get("verified_findings", [])),
                    "security_score": security_score,
                    "duration_ms": duration_ms,
                    "message": f"âœ… å®¡è®¡å®Œæˆï¼å‘ç° {len(findings)} ä¸ªæ¼æ´",
                },
            )
            
        except asyncio.CancelledError:
            await self._update_task_status(AgentTaskStatus.CANCELLED)
            yield StreamEvent(
                event_type=StreamEventType.TASK_CANCEL,
                sequence=self.stream_handler._next_sequence(),
                data={"message": "ä»»åŠ¡å·²å–æ¶ˆ"},
            )
            
        except Exception as e:
            logger.error(f"LangGraph run failed: {e}", exc_info=True)
            await self._update_task_status(AgentTaskStatus.FAILED, str(e))
            await self.event_emitter.emit_error(str(e))
            
            yield StreamEvent(
                event_type=StreamEventType.TASK_ERROR,
                sequence=self.stream_handler._next_sequence(),
                data={"error": str(e), "message": f"âŒ å®¡è®¡å¤±è´¥: {e}"},
            )
            
        finally:
            await self._cleanup()
    
    async def _sync_stream_event_to_db(self, event: StreamEvent):
        """åŒæ­¥æµå¼äº‹ä»¶åˆ°æ•°æ®åº“"""
        try:
            # å°† StreamEvent è½¬æ¢ä¸º AgentEventData
            await self.event_manager.add_event(
                task_id=self.task.id,
                event_type=event.event_type.value,
                sequence=event.sequence,
                phase=event.phase,
                message=event.data.get("message"),
                tool_name=event.tool_name,
                tool_input=event.data.get("input") or event.data.get("input_params"),
                tool_output=event.data.get("output") or event.data.get("output_data"),
                tool_duration_ms=event.data.get("duration_ms"),
                metadata=event.data,
            )
        except Exception as e:
            logger.warning(f"Failed to sync stream event to db: {e}")
    
    async def _handle_node_output(self, node_name: str, output: Dict[str, Any]):
        """å¤„ç†èŠ‚ç‚¹è¾“å‡º"""
        # å‘å°„èŠ‚ç‚¹äº‹ä»¶
        events = output.get("events", [])
        for evt in events:
            await self.event_emitter.emit_info(
                f"[{node_name}] {evt.get('type', 'event')}: {evt.get('data', {})}"
            )
        
        # å¤„ç†æ–°å‘ç°
        if node_name == "analysis":
            new_findings = output.get("findings", [])
            if new_findings:
                for finding in new_findings[:5]:  # é™åˆ¶äº‹ä»¶æ•°é‡
                    await self.event_emitter.emit_finding(
                        title=finding.get("title", "Unknown"),
                        severity=finding.get("severity", "medium"),
                        file_path=finding.get("file_path"),
                    )
        
        # å¤„ç†éªŒè¯ç»“æœ
        if node_name == "verification":
            verified = output.get("verified_findings", [])
            for v in verified[:5]:
                await self.event_emitter.emit_info(
                    f"âœ… å·²éªŒè¯: {v.get('title', 'Unknown')}"
                )
        
        # å¤„ç†é”™è¯¯
        if output.get("error"):
            await self.event_emitter.emit_error(output["error"])
    
    async def _index_code(self):
        """ç´¢å¼•ä»£ç """
        if not self.indexer:
            await self.event_emitter.emit_warning("RAG æœªåˆå§‹åŒ–ï¼Œè·³è¿‡ä»£ç ç´¢å¼•")
            return
        
        await self._update_task_phase(AgentTaskPhase.INDEXING)
        await self.event_emitter.emit_phase_start("indexing", "ğŸ“ å¼€å§‹ä»£ç ç´¢å¼•")
        
        try:
            async for progress in self.indexer.index_directory(self.project_root):
                if self._cancelled:
                    return
                
                await self.event_emitter.emit_progress(
                    progress.processed_files,
                    progress.total_files,
                    f"æ­£åœ¨ç´¢å¼•: {progress.current_file or 'N/A'}"
                )
            
            await self.event_emitter.emit_phase_complete("indexing", "âœ… ä»£ç ç´¢å¼•å®Œæˆ")
            
        except Exception as e:
            logger.warning(f"Code indexing failed: {e}")
            await self.event_emitter.emit_warning(f"ä»£ç ç´¢å¼•å¤±è´¥: {e}")
    
    async def _collect_project_info(self) -> Dict[str, Any]:
        """æ”¶é›†é¡¹ç›®ä¿¡æ¯"""
        info = {
            "name": self.task.project.name if self.task.project else "unknown",
            "root": self.project_root,
            "languages": [],
            "file_count": 0,
        }
        
        try:
            exclude_dirs = {
                "node_modules", "__pycache__", ".git", "venv", ".venv",
                "build", "dist", "target", ".idea", ".vscode",
            }
            
            for root, dirs, files in os.walk(self.project_root):
                dirs[:] = [d for d in dirs if d not in exclude_dirs]
                info["file_count"] += len(files)
                
                lang_map = {
                    ".py": "Python", ".js": "JavaScript", ".ts": "TypeScript",
                    ".java": "Java", ".go": "Go", ".php": "PHP",
                    ".rb": "Ruby", ".rs": "Rust", ".c": "C", ".cpp": "C++",
                }
                
                for f in files:
                    ext = os.path.splitext(f)[1].lower()
                    if ext in lang_map and lang_map[ext] not in info["languages"]:
                        info["languages"].append(lang_map[ext])
                        
        except Exception as e:
            logger.warning(f"Failed to collect project info: {e}")
        
        return info
    
    async def _save_findings(self, findings: List[Dict]):
        """ä¿å­˜å‘ç°åˆ°æ•°æ®åº“"""
        severity_map = {
            "critical": VulnerabilitySeverity.CRITICAL,
            "high": VulnerabilitySeverity.HIGH,
            "medium": VulnerabilitySeverity.MEDIUM,
            "low": VulnerabilitySeverity.LOW,
            "info": VulnerabilitySeverity.INFO,
        }
        
        type_map = {
            "sql_injection": VulnerabilityType.SQL_INJECTION,
            "nosql_injection": VulnerabilityType.NOSQL_INJECTION,
            "xss": VulnerabilityType.XSS,
            "command_injection": VulnerabilityType.COMMAND_INJECTION,
            "code_injection": VulnerabilityType.CODE_INJECTION,
            "path_traversal": VulnerabilityType.PATH_TRAVERSAL,
            "file_inclusion": VulnerabilityType.FILE_INCLUSION,
            "ssrf": VulnerabilityType.SSRF,
            "xxe": VulnerabilityType.XXE,
            "deserialization": VulnerabilityType.DESERIALIZATION,
            "auth_bypass": VulnerabilityType.AUTH_BYPASS,
            "idor": VulnerabilityType.IDOR,
            "sensitive_data_exposure": VulnerabilityType.SENSITIVE_DATA_EXPOSURE,
            "hardcoded_secret": VulnerabilityType.HARDCODED_SECRET,
            "weak_crypto": VulnerabilityType.WEAK_CRYPTO,
            "race_condition": VulnerabilityType.RACE_CONDITION,
            "business_logic": VulnerabilityType.BUSINESS_LOGIC,
            "memory_corruption": VulnerabilityType.MEMORY_CORRUPTION,
        }
        
        for finding in findings:
            try:
                db_finding = AgentFinding(
                    id=str(uuid.uuid4()),
                    task_id=self.task.id,
                    vulnerability_type=type_map.get(
                        finding.get("vulnerability_type", "other"),
                        VulnerabilityType.OTHER
                    ),
                    severity=severity_map.get(
                        finding.get("severity", "medium"),
                        VulnerabilitySeverity.MEDIUM
                    ),
                    title=finding.get("title", "Unknown"),
                    description=finding.get("description", ""),
                    file_path=finding.get("file_path"),
                    line_start=finding.get("line_start"),
                    line_end=finding.get("line_end"),
                    code_snippet=finding.get("code_snippet"),
                    source=finding.get("source"),
                    sink=finding.get("sink"),
                    suggestion=finding.get("suggestion") or finding.get("recommendation"),
                    is_verified=finding.get("is_verified", False),
                    confidence=finding.get("confidence", 0.5),
                    poc=finding.get("poc"),
                    status=FindingStatus.VERIFIED if finding.get("is_verified") else FindingStatus.NEW,
                )
                
                self.db.add(db_finding)
                
            except Exception as e:
                logger.warning(f"Failed to save finding: {e}")
        
        try:
            await self.db.commit()
        except Exception as e:
            logger.error(f"Failed to commit findings: {e}")
            await self.db.rollback()
    
    async def _update_task_status(
        self,
        status: AgentTaskStatus,
        error: Optional[str] = None
    ):
        """æ›´æ–°ä»»åŠ¡çŠ¶æ€"""
        self.task.status = status
        
        if status == AgentTaskStatus.RUNNING:
            self.task.started_at = datetime.now(timezone.utc)
        elif status in [AgentTaskStatus.COMPLETED, AgentTaskStatus.FAILED, AgentTaskStatus.CANCELLED]:
            self.task.finished_at = datetime.now(timezone.utc)
        
        if error:
            self.task.error_message = error
        
        try:
            await self.db.commit()
        except Exception as e:
            logger.error(f"Failed to update task status: {e}")
    
    async def _update_task_phase(self, phase: AgentTaskPhase):
        """æ›´æ–°ä»»åŠ¡é˜¶æ®µ"""
        self.task.current_phase = phase
        try:
            await self.db.commit()
        except Exception as e:
            logger.error(f"Failed to update task phase: {e}")
    
    async def _update_task_summary(
        self,
        total_findings: int,
        verified_count: int,
        security_score: int,
    ):
        """æ›´æ–°ä»»åŠ¡æ‘˜è¦"""
        self.task.total_findings = total_findings
        self.task.verified_findings = verified_count
        self.task.security_score = security_score
        
        try:
            await self.db.commit()
        except Exception as e:
            logger.error(f"Failed to update task summary: {e}")
    
    async def _cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            if self.sandbox_manager:
                await self.sandbox_manager.cleanup()
            await self.event_manager.close()
        except Exception as e:
            logger.warning(f"Cleanup error: {e}")


# ä¾¿æ·å‡½æ•°
async def run_agent_task(
    db: AsyncSession,
    task: AgentTask,
    project_root: str,
) -> Dict[str, Any]:
    """
    è¿è¡Œ Agent å®¡è®¡ä»»åŠ¡
    
    Args:
        db: æ•°æ®åº“ä¼šè¯
        task: Agent ä»»åŠ¡
        project_root: é¡¹ç›®æ ¹ç›®å½•
        
    Returns:
        å®¡è®¡ç»“æœ
    """
    runner = AgentRunner(db, task, project_root)
    return await runner.run()

