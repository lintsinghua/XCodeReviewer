"""
ä»“åº“æ‰«ææœåŠ¡ - æ”¯æŒGitHub, GitLab å’Œ Gitea ä»“åº“æ‰«æ
"""

import asyncio
import httpx
from typing import List, Dict, Any, Optional
from datetime import datetime, timezone
from urllib.parse import urlparse, quote
from sqlalchemy.ext.asyncio import AsyncSession

from app.utils.repo_utils import parse_repository_url
from app.models.audit import AuditTask, AuditIssue
from app.models.project import Project
from app.services.llm.service import LLMService
from app.core.config import settings


def get_analysis_config(user_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """
    è·å–åˆ†æé…ç½®å‚æ•°ï¼ˆä¼˜å…ˆä½¿ç”¨ç”¨æˆ·é…ç½®ï¼Œç„¶åä½¿ç”¨ç³»ç»Ÿé…ç½®ï¼‰

    Returns:
        åŒ…å«ä»¥ä¸‹å­—æ®µçš„å­—å…¸:
        - max_analyze_files: æœ€å¤§åˆ†ææ–‡ä»¶æ•°
        - llm_concurrency: LLM å¹¶å‘æ•°
        - llm_gap_ms: LLM è¯·æ±‚é—´éš”ï¼ˆæ¯«ç§’ï¼‰
    """
    other_config = (user_config or {}).get('otherConfig', {})

    return {
        'max_analyze_files': other_config.get('maxAnalyzeFiles') or settings.MAX_ANALYZE_FILES,
        'llm_concurrency': other_config.get('llmConcurrency') or settings.LLM_CONCURRENCY,
        'llm_gap_ms': other_config.get('llmGapMs') or settings.LLM_GAP_MS,
    }


# æ”¯æŒçš„æ–‡æœ¬æ–‡ä»¶æ‰©å±•å
TEXT_EXTENSIONS = [
    ".js", ".ts", ".tsx", ".jsx", ".py", ".java", ".go", ".rs", 
    ".cpp", ".c", ".h", ".cc", ".hh", ".cs", ".php", ".rb", 
    ".kt", ".swift", ".sql", ".sh", ".json", ".yml", ".yaml"
]

# æ’é™¤çš„ç›®å½•å’Œæ–‡ä»¶æ¨¡å¼
EXCLUDE_PATTERNS = [
    "node_modules/", "vendor/", "dist/", "build/", ".git/",
    "__pycache__/", ".pytest_cache/", "coverage/", ".nyc_output/",
    ".vscode/", ".idea/", ".vs/", "target/", "out/",
    "__MACOSX/", ".DS_Store", "package-lock.json", "yarn.lock",
    "pnpm-lock.yaml", ".min.js", ".min.css", ".map"
]


def is_text_file(path: str) -> bool:
    """æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡æœ¬æ–‡ä»¶"""
    return any(path.lower().endswith(ext) for ext in TEXT_EXTENSIONS)


def should_exclude(path: str, exclude_patterns: List[str] = None) -> bool:
    """æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤è¯¥æ–‡ä»¶"""
    all_patterns = EXCLUDE_PATTERNS + (exclude_patterns or [])
    return any(pattern in path for pattern in all_patterns)


def get_language_from_path(path: str) -> str:
    """ä»æ–‡ä»¶è·¯å¾„è·å–è¯­è¨€ç±»å‹"""
    ext = path.split('.')[-1].lower() if '.' in path else ''
    language_map = {
        'js': 'javascript', 'jsx': 'javascript',
        'ts': 'typescript', 'tsx': 'typescript',
        'py': 'python', 'java': 'java', 'go': 'go',
        'rs': 'rust', 'cpp': 'cpp', 'c': 'cpp',
        'cc': 'cpp', 'h': 'cpp', 'hh': 'cpp',
        'cs': 'csharp', 'php': 'php', 'rb': 'ruby',
        'kt': 'kotlin', 'swift': 'swift'
    }
    return language_map.get(ext, 'text')


class TaskControlManager:
    """ä»»åŠ¡æ§åˆ¶ç®¡ç†å™¨ - ç”¨äºå–æ¶ˆè¿è¡Œä¸­çš„ä»»åŠ¡"""
    
    def __init__(self):
        self._cancelled_tasks: set = set()
    
    def cancel_task(self, task_id: str):
        """å–æ¶ˆä»»åŠ¡"""
        self._cancelled_tasks.add(task_id)
        print(f"ğŸ›‘ ä»»åŠ¡ {task_id} å·²æ ‡è®°ä¸ºå–æ¶ˆ")
    
    def is_cancelled(self, task_id: str) -> bool:
        """æ£€æŸ¥ä»»åŠ¡æ˜¯å¦è¢«å–æ¶ˆ"""
        return task_id in self._cancelled_tasks
    
    def cleanup_task(self, task_id: str):
        """æ¸…ç†å·²å®Œæˆä»»åŠ¡çš„æ§åˆ¶çŠ¶æ€"""
        self._cancelled_tasks.discard(task_id)


# å…¨å±€ä»»åŠ¡æ§åˆ¶å™¨
task_control = TaskControlManager()


async def github_api(url: str, token: str = None) -> Any:
    """è°ƒç”¨GitHub API"""
    headers = {"Accept": "application/vnd.github+json"}
    t = token or settings.GITHUB_TOKEN
    if t:
        headers["Authorization"] = f"Bearer {t}"
    
    async with httpx.AsyncClient(timeout=30) as client:
        response = await client.get(url, headers=headers)
        if response.status_code == 403:
            raise Exception("GitHub API 403ï¼šè¯·é…ç½® GITHUB_TOKEN æˆ–ç¡®è®¤ä»“åº“æƒé™/é¢‘ç‡é™åˆ¶")
        if response.status_code != 200:
            raise Exception(f"GitHub API {response.status_code}: {url}")
        return response.json()



async def gitea_api(url: str, token: str = None) -> Any:
    """è°ƒç”¨Gitea API"""
    headers = {"Content-Type": "application/json"}
    t = token or settings.GITEA_TOKEN
    if t:
        headers["Authorization"] = f"token {t}"
    
    async with httpx.AsyncClient(timeout=30) as client:
        response = await client.get(url, headers=headers)
        if response.status_code == 401:
            raise Exception("Gitea API 401ï¼šè¯·é…ç½® GITEA_TOKEN æˆ–ç¡®è®¤ä»“åº“æƒé™")
        if response.status_code == 403:
            raise Exception("Gitea API 403ï¼šè¯·ç¡®è®¤ä»“åº“æƒé™/é¢‘ç‡é™åˆ¶")
        if response.status_code != 200:
            raise Exception(f"Gitea API {response.status_code}: {url}")
        return response.json()


async def gitlab_api(url: str, token: str = None) -> Any:
    """è°ƒç”¨GitLab API"""
    headers = {"Content-Type": "application/json"}
    t = token or settings.GITLAB_TOKEN
    if t:
        headers["PRIVATE-TOKEN"] = t
    
    async with httpx.AsyncClient(timeout=30) as client:
        response = await client.get(url, headers=headers)
        if response.status_code == 401:
            raise Exception("GitLab API 401ï¼šè¯·é…ç½® GITLAB_TOKEN æˆ–ç¡®è®¤ä»“åº“æƒé™")
        if response.status_code == 403:
            raise Exception("GitLab API 403ï¼šè¯·ç¡®è®¤ä»“åº“æƒé™/é¢‘ç‡é™åˆ¶")
        if response.status_code != 200:
            raise Exception(f"GitLab API {response.status_code}: {url}")
        return response.json()


async def fetch_file_content(url: str, headers: Dict[str, str] = None) -> Optional[str]:
    """è·å–æ–‡ä»¶å†…å®¹"""
    async with httpx.AsyncClient(timeout=30) as client:
        try:
            response = await client.get(url, headers=headers or {})
            if response.status_code == 200:
                return response.text
        except Exception as e:
            print(f"è·å–æ–‡ä»¶å†…å®¹å¤±è´¥: {url}, é”™è¯¯: {e}")
    return None


async def get_github_branches(repo_url: str, token: str = None) -> List[str]:
    """è·å–GitHubä»“åº“åˆ†æ”¯åˆ—è¡¨"""
    repo_info = parse_repository_url(repo_url, "github")
    owner, repo = repo_info['owner'], repo_info['repo']
    
    branches_url = f"https://api.github.com/repos/{owner}/{repo}/branches?per_page=100"
    branches_data = await github_api(branches_url, token)
    
    return [b["name"] for b in branches_data]





async def get_gitea_branches(repo_url: str, token: str = None) -> List[str]:
    """è·å–Giteaä»“åº“åˆ†æ”¯åˆ—è¡¨"""
    repo_info = parse_repository_url(repo_url, "gitea")
    base_url = repo_info['base_url'] # This is {base}/api/v1
    owner, repo = repo_info['owner'], repo_info['repo']
    
    branches_url = f"{base_url}/repos/{owner}/{repo}/branches"
    branches_data = await gitea_api(branches_url, token)
    
    return [b["name"] for b in branches_data]


async def get_gitlab_branches(repo_url: str, token: str = None) -> List[str]:
    """è·å–GitLabä»“åº“åˆ†æ”¯åˆ—è¡¨"""
    parsed = urlparse(repo_url)
    
    extracted_token = token
    if parsed.username:
        if parsed.username == 'oauth2' and parsed.password:
            extracted_token = parsed.password
        elif parsed.username and not parsed.password:
            extracted_token = parsed.username
    
    repo_info = parse_repository_url(repo_url, "gitlab")
    base_url = repo_info['base_url']
    project_path = quote(repo_info['project_path'], safe='')
    
    branches_url = f"{base_url}/projects/{project_path}/repository/branches?per_page=100"
    branches_data = await gitlab_api(branches_url, extracted_token)
    
    return [b["name"] for b in branches_data]


async def get_github_files(repo_url: str, branch: str, token: str = None, exclude_patterns: List[str] = None) -> List[Dict[str, str]]:
    """è·å–GitHubä»“åº“æ–‡ä»¶åˆ—è¡¨"""
    # è§£æä»“åº“URL
    repo_info = parse_repository_url(repo_url, "github")
    owner, repo = repo_info['owner'], repo_info['repo']
    
    # è·å–ä»“åº“æ–‡ä»¶æ ‘
    tree_url = f"https://api.github.com/repos/{owner}/{repo}/git/trees/{quote(branch)}?recursive=1"
    tree_data = await github_api(tree_url, token)
    
    files = []
    for item in tree_data.get("tree", []):
        if item.get("type") == "blob" and is_text_file(item["path"]) and not should_exclude(item["path"], exclude_patterns):
            size = item.get("size", 0)
            if size <= settings.MAX_FILE_SIZE_BYTES:
                files.append({
                    "path": item["path"],
                    "url": f"https://raw.githubusercontent.com/{owner}/{repo}/{quote(branch)}/{item['path']}"
                })
    
    return files


async def get_gitlab_files(repo_url: str, branch: str, token: str = None, exclude_patterns: List[str] = None) -> List[Dict[str, str]]:
    """è·å–GitLabä»“åº“æ–‡ä»¶åˆ—è¡¨"""
    parsed = urlparse(repo_url)
    
    # ä»URLä¸­æå–tokenï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    extracted_token = token
    if parsed.username:
        if parsed.username == 'oauth2' and parsed.password:
            extracted_token = parsed.password
        elif parsed.username and not parsed.password:
            extracted_token = parsed.username
    
    # è§£æé¡¹ç›®è·¯å¾„
    repo_info = parse_repository_url(repo_url, "gitlab")
    base_url = repo_info['base_url'] # {base}/api/v4
    project_path = quote(repo_info['project_path'], safe='')
    
    # è·å–ä»“åº“æ–‡ä»¶æ ‘
    tree_url = f"{base_url}/projects/{project_path}/repository/tree?ref={quote(branch)}&recursive=true&per_page=100"
    tree_data = await gitlab_api(tree_url, extracted_token)
    
    files = []
    for item in tree_data:
        if item.get("type") == "blob" and is_text_file(item["path"]) and not should_exclude(item["path"], exclude_patterns):
            files.append({
                "path": item["path"],
                "url": f"{base_url}/projects/{project_path}/repository/files/{quote(item['path'], safe='')}/raw?ref={quote(branch)}",
                "token": extracted_token
            })
    
    return files



async def get_gitea_files(repo_url: str, branch: str, token: str = None, exclude_patterns: List[str] = None) -> List[Dict[str, str]]:
    """è·å–Giteaä»“åº“æ–‡ä»¶åˆ—è¡¨"""
    repo_info = parse_repository_url(repo_url, "gitea")
    base_url = repo_info['base_url']
    owner, repo = repo_info['owner'], repo_info['repo']
    
    # Gitea tree API: GET /repos/{owner}/{repo}/git/trees/{sha}?recursive=1
    # å¯ä»¥ç›´æ¥ä½¿ç”¨åˆ†æ”¯åä½œä¸ºsha
    tree_url = f"{base_url}/repos/{owner}/{repo}/git/trees/{quote(branch)}?recursive=1"
    tree_data = await gitea_api(tree_url, token)
    
    files = []
    for item in tree_data.get("tree", []):
         # Gitea API returns 'type': 'blob' for files
        if item.get("type") == "blob" and is_text_file(item["path"]) and not should_exclude(item["path"], exclude_patterns):
            # ä½¿ç”¨API raw endpoint: GET /repos/{owner}/{repo}/raw/{filepath}?ref={branch}
             files.append({
                "path": item["path"],
                "url": f"{base_url}/repos/{owner}/{repo}/raw/{quote(item['path'])}?ref={quote(branch)}",
                "token": token # ä¼ é€’tokenä»¥ä¾¿fetch_file_contentä½¿ç”¨
            })
    
    return files
async def scan_repo_task(task_id: str, db_session_factory, user_config: dict = None):
    """
    åå°ä»“åº“æ‰«æä»»åŠ¡
    
    Args:
        task_id: ä»»åŠ¡ID
        db_session_factory: æ•°æ®åº“ä¼šè¯å·¥å‚
        user_config: ç”¨æˆ·é…ç½®å­—å…¸ï¼ˆåŒ…å«llmConfigå’ŒotherConfigï¼‰
    """
    async with db_session_factory() as db:
        task = await db.get(AuditTask, task_id)
        if not task:
            return

        try:
            # 1. æ›´æ–°çŠ¶æ€ä¸ºè¿è¡Œä¸­
            task.status = "running"
            task.started_at = datetime.now(timezone.utc)
            await db.commit()
            
            # åˆ›å»ºä½¿ç”¨ç”¨æˆ·é…ç½®çš„LLMæœåŠ¡å®ä¾‹
            llm_service = LLMService(user_config=user_config or {})

            # 2. è·å–é¡¹ç›®ä¿¡æ¯
            project = await db.get(Project, task.project_id)
            if not project:
                raise Exception("é¡¹ç›®ä¸å­˜åœ¨")
            
            # æ£€æŸ¥é¡¹ç›®ç±»å‹ - ä»…æ”¯æŒä»“åº“ç±»å‹é¡¹ç›®
            source_type = getattr(project, 'source_type', 'repository')
            if source_type == 'zip':
                raise Exception("ZIPç±»å‹é¡¹ç›®è¯·ä½¿ç”¨ZIPä¸Šä¼ æ‰«ææ¥å£")
            
            if not project.repository_url:
                raise Exception("ä»“åº“åœ°å€ä¸å­˜åœ¨")

            repo_url = project.repository_url
            branch = task.branch_name or project.default_branch or "main"
            repo_type = project.repository_type or "other"
            
            # è§£æä»»åŠ¡çš„æ’é™¤æ¨¡å¼
            import json as json_module
            task_exclude_patterns = []
            if task.exclude_patterns:
                try:
                    task_exclude_patterns = json_module.loads(task.exclude_patterns)
                except:
                    pass

            print(f"ğŸš€ å¼€å§‹æ‰«æä»“åº“: {repo_url}, åˆ†æ”¯: {branch}, ç±»å‹: {repo_type}, æ¥æº: {source_type}")
            if task_exclude_patterns:
                print(f"ğŸ“‹ æ’é™¤æ¨¡å¼: {task_exclude_patterns}")

            # 3. è·å–æ–‡ä»¶åˆ—è¡¨
            # ä»ç”¨æˆ·é…ç½®ä¸­è¯»å– GitHub/GitLab Tokenï¼ˆä¼˜å…ˆä½¿ç”¨ç”¨æˆ·é…ç½®ï¼Œç„¶åä½¿ç”¨ç³»ç»Ÿé…ç½®ï¼‰
            user_other_config = (user_config or {}).get('otherConfig', {})
            github_token = user_other_config.get('githubToken') or settings.GITHUB_TOKEN
            gitlab_token = user_other_config.get('gitlabToken') or settings.GITLAB_TOKEN
            gitea_token = user_other_config.get('giteaToken') or settings.GITEA_TOKEN

            

            # è·å–SSHç§é’¥ï¼ˆå¦‚æœé…ç½®äº†ï¼‰
            ssh_private_key = None
            if 'sshPrivateKey' in user_other_config:
                from app.core.encryption import decrypt_sensitive_data
                ssh_private_key = decrypt_sensitive_data(user_other_config['sshPrivateKey'])

            files: List[Dict[str, str]] = []
            extracted_gitlab_token = None

            # æ£€æŸ¥æ˜¯å¦ä¸ºSSH URL
            from app.services.git_ssh_service import GitSSHOperations
            is_ssh_url = GitSSHOperations.is_ssh_url(repo_url)

            if is_ssh_url:
                # ä½¿ç”¨SSHæ–¹å¼è·å–æ–‡ä»¶
                if not ssh_private_key:
                    raise Exception("ä»“åº“ä½¿ç”¨SSH URLï¼Œä½†æœªé…ç½®SSHå¯†é’¥ã€‚è¯·å…ˆç”Ÿæˆå¹¶é…ç½®SSHå¯†é’¥ã€‚")

                print(f"ğŸ” ä½¿ç”¨SSHæ–¹å¼è®¿é—®ä»“åº“: {repo_url}")
                try:
                    files_with_content = GitSSHOperations.get_repo_files_via_ssh(
                        repo_url, ssh_private_key, branch, task_exclude_patterns
                    )
                    # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
                    files = [{'path': f['path'], 'content': f['content']} for f in files_with_content]
                    actual_branch = branch
                    print(f"âœ… é€šè¿‡SSHæˆåŠŸè·å– {len(files)} ä¸ªæ–‡ä»¶")
                except Exception as e:
                    raise Exception(f"SSHæ–¹å¼è·å–ä»“åº“æ–‡ä»¶å¤±è´¥: {str(e)}")
            else:
                # ä½¿ç”¨APIæ–¹å¼è·å–æ–‡ä»¶ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
                # æ„å»ºåˆ†æ”¯å°è¯•é¡ºåºï¼ˆåˆ†æ”¯é™çº§æœºåˆ¶ï¼‰
                branches_to_try = [branch]
                if project.default_branch and project.default_branch != branch:
                    branches_to_try.append(project.default_branch)
                for common_branch in ["main", "master"]:
                    if common_branch not in branches_to_try:
                        branches_to_try.append(common_branch)

                actual_branch = branch  # å®é™…ä½¿ç”¨çš„åˆ†æ”¯
                last_error = None

                for try_branch in branches_to_try:
                    try:
                        print(f"ğŸ”„ å°è¯•è·å–åˆ†æ”¯ {try_branch} çš„æ–‡ä»¶åˆ—è¡¨...")
                        if repo_type == "github":
                            files = await get_github_files(repo_url, try_branch, github_token, task_exclude_patterns)
                        elif repo_type == "gitlab":
                            files = await get_gitlab_files(repo_url, try_branch, gitlab_token, task_exclude_patterns)
                            # GitLabæ–‡ä»¶å¯èƒ½å¸¦æœ‰token
                            if files and 'token' in files[0]:
                                extracted_gitlab_token = files[0].get('token')
                        elif repo_type == "gitea":
                            files = await get_gitea_files(repo_url, try_branch, gitea_token, task_exclude_patterns)
                        else:
                            raise Exception("ä¸æ”¯æŒçš„ä»“åº“ç±»å‹ï¼Œä»…æ”¯æŒ GitHub, GitLab å’Œ Gitea ä»“åº“")

                        if files:
                            actual_branch = try_branch
                            if try_branch != branch:
                                print(f"âš ï¸ åˆ†æ”¯ {branch} ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®ï¼Œå·²é™çº§åˆ°åˆ†æ”¯ {try_branch}")
                            break
                    except Exception as e:
                        last_error = str(e)
                        print(f"âš ï¸ è·å–åˆ†æ”¯ {try_branch} å¤±è´¥: {last_error[:100]}")
                        continue

                if not files:
                    error_msg = f"æ— æ³•è·å–ä»“åº“æ–‡ä»¶ï¼Œæ‰€æœ‰åˆ†æ”¯å°è¯•å‡å¤±è´¥"
                    if last_error:
                        if "404" in last_error or "Not Found" in last_error:
                            error_msg = f"ä»“åº“æˆ–åˆ†æ”¯ä¸å­˜åœ¨: {branch}"
                        elif "401" in last_error or "403" in last_error:
                            error_msg = "æ— è®¿é—®æƒé™ï¼Œè¯·æ£€æŸ¥ Token é…ç½®"
                        else:
                            error_msg = f"è·å–æ–‡ä»¶å¤±è´¥: {last_error[:100]}"
                    raise Exception(error_msg)

            print(f"âœ… æˆåŠŸè·å–åˆ†æ”¯ {actual_branch} çš„æ–‡ä»¶åˆ—è¡¨")

            # è·å–åˆ†æé…ç½®ï¼ˆä¼˜å…ˆä½¿ç”¨ç”¨æˆ·é…ç½®ï¼‰
            analysis_config = get_analysis_config(user_config)
            max_analyze_files = analysis_config['max_analyze_files']
            llm_gap_ms = analysis_config['llm_gap_ms']

            # é™åˆ¶æ–‡ä»¶æ•°é‡
            # å¦‚æœæŒ‡å®šäº†ç‰¹å®šæ–‡ä»¶ï¼Œåˆ™åªåˆ†æè¿™äº›æ–‡ä»¶
            target_files = (user_config or {}).get('scan_config', {}).get('file_paths', [])
            if target_files:
                print(f"ğŸ¯ æŒ‡å®šåˆ†æ {len(target_files)} ä¸ªæ–‡ä»¶")
                files = [f for f in files if f['path'] in target_files]
            elif max_analyze_files > 0:
                files = files[:max_analyze_files]

            task.total_files = len(files)
            await db.commit()

            print(f"ğŸ“Š è·å–åˆ° {len(files)} ä¸ªæ–‡ä»¶ï¼Œå¼€å§‹åˆ†æ (æœ€å¤§æ–‡ä»¶æ•°: {max_analyze_files}, è¯·æ±‚é—´éš”: {llm_gap_ms}ms)")

            # 4. åˆ†ææ–‡ä»¶
            total_issues = 0
            total_lines = 0
            quality_scores = []
            scanned_files = 0
            failed_files = 0
            skipped_files = 0  # è·³è¿‡çš„æ–‡ä»¶ï¼ˆç©ºæ–‡ä»¶ã€å¤ªå¤§ç­‰ï¼‰
            consecutive_failures = 0
            MAX_CONSECUTIVE_FAILURES = 5

            for file_info in files:
                # æ£€æŸ¥æ˜¯å¦å–æ¶ˆ
                if task_control.is_cancelled(task_id):
                    print(f"ğŸ›‘ ä»»åŠ¡ {task_id} å·²è¢«ç”¨æˆ·å–æ¶ˆ")
                    task.status = "cancelled"
                    task.completed_at = datetime.now(timezone.utc)
                    await db.commit()
                    task_control.cleanup_task(task_id)
                    return

                # æ£€æŸ¥è¿ç»­å¤±è´¥æ¬¡æ•°
                if consecutive_failures >= MAX_CONSECUTIVE_FAILURES:
                    print(f"âŒ ä»»åŠ¡ {task_id}: è¿ç»­å¤±è´¥ {consecutive_failures} æ¬¡ï¼Œåœæ­¢åˆ†æ")
                    raise Exception(f"è¿ç»­å¤±è´¥ {consecutive_failures} æ¬¡ï¼Œå¯èƒ½æ˜¯ LLM API æœåŠ¡å¼‚å¸¸")

                try:
                    # è·å–æ–‡ä»¶å†…å®¹

                    if is_ssh_url:
                        # SSHæ–¹å¼å·²ç»åŒ…å«äº†æ–‡ä»¶å†…å®¹
                        content = file_info.get('content', '')
                        print(f"ğŸ“¥ æ­£åœ¨å¤„ç†SSHæ–‡ä»¶: {file_info['path']}")
                    else:
                        headers = {}
                        # ä½¿ç”¨æå–çš„ token æˆ–ç”¨æˆ·é…ç½®çš„ token
                        
                        if repo_type == "gitlab":
                            token_to_use = file_info.get('token') or gitlab_token
                            if token_to_use:
                                headers["PRIVATE-TOKEN"] = token_to_use
                        elif repo_type == "gitea":
                            token_to_use = file_info.get('token') or gitea_token
                            if token_to_use:
                                headers["Authorization"] = f"token {token_to_use}"
                        elif repo_type == "github":
                            # GitHub raw URL ä¹Ÿæ˜¯ç›´æ¥ä¸‹è½½ï¼Œé€šå¸¸publicä¸éœ€è¦tokenï¼Œprivateéœ€è¦
                            # GitHub raw user content url: raw.githubusercontent.com
                            if github_token:
                                headers["Authorization"] = f"Bearer {github_token}"
                        
                        print(f"ğŸ“¥ æ­£åœ¨è·å–æ–‡ä»¶: {file_info['path']}")
                        content = await fetch_file_content(file_info["url"], headers)

                    if not content or not content.strip():
                        print(f"âš ï¸ æ–‡ä»¶å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡: {file_info['path']}")
                        skipped_files += 1
                        continue
                    
                    if len(content) > settings.MAX_FILE_SIZE_BYTES:
                        print(f"âš ï¸ æ–‡ä»¶å¤ªå¤§ï¼Œè·³è¿‡: {file_info['path']}")
                        skipped_files += 1
                        continue
                    
                    file_lines = content.split('\n')
                    total_lines = len(file_lines) + 1
                    language = get_language_from_path(file_info["path"])
                    
                    print(f"ğŸ¤– æ­£åœ¨è°ƒç”¨ LLM åˆ†æ: {file_info['path']} ({language}, {len(content)} bytes)")
                    # LLMåˆ†æ - æ”¯æŒè§„åˆ™é›†å’Œæç¤ºè¯æ¨¡æ¿
                    scan_config = (user_config or {}).get('scan_config', {})
                    rule_set_id = scan_config.get('rule_set_id')
                    prompt_template_id = scan_config.get('prompt_template_id')
                    
                    if rule_set_id or prompt_template_id:
                        analysis = await llm_service.analyze_code_with_rules(
                            content, language,
                            rule_set_id=rule_set_id,
                            prompt_template_id=prompt_template_id,
                            db_session=db
                        )
                    else:
                        analysis = await llm_service.analyze_code(content, language)
                    print(f"âœ… LLM åˆ†æå®Œæˆ: {file_info['path']}")
                    
                    # å†æ¬¡æ£€æŸ¥æ˜¯å¦å–æ¶ˆï¼ˆLLMåˆ†æåï¼‰
                    if task_control.is_cancelled(task_id):
                        print(f"ğŸ›‘ ä»»åŠ¡ {task_id} åœ¨LLMåˆ†æåè¢«å–æ¶ˆ")
                        task.status = "cancelled"
                        task.completed_at = datetime.now(timezone.utc)
                        await db.commit()
                        task_control.cleanup_task(task_id)
                        return
                    
                    # ä¿å­˜é—®é¢˜
                    issues = analysis.get("issues", [])
                    for issue in issues:
                        line_num = issue.get("line", 1)
                        
                        # å¥å£®çš„ä»£ç ç‰‡æ®µæå–é€»è¾‘
                        # ä¼˜å…ˆä½¿ç”¨ LLM è¿”å›çš„ç‰‡æ®µï¼Œå¦‚æœä¸ºç©ºåˆ™ä»æºç æå–
                        code_snippet = issue.get("code_snippet")
                        if not code_snippet or len(code_snippet.strip()) < 5:
                            # ä»æºç æå–ä¸Šä¸‹æ–‡ (å‰å2è¡Œ)
                            try:
                                # line_num æ˜¯ 1-based
                                idx = max(0, int(line_num) - 1)
                                start = max(0, idx - 2)
                                end = min(len(file_lines), idx + 3)
                                code_snippet = '\n'.join(file_lines[start:end])
                            except Exception:
                                code_snippet = ""

                        audit_issue = AuditIssue(
                            task_id=task.id,
                            file_path=file_info["path"],
                            line_number=line_num,
                            column_number=issue.get("column"),
                            issue_type=issue.get("type", "maintainability"),
                            severity=issue.get("severity", "low"),
                            title=issue.get("title", "Issue"),
                            message=issue.get("description") or issue.get("title", "Issue"),
                            suggestion=issue.get("suggestion"),
                            code_snippet=code_snippet,
                            ai_explanation=issue.get("ai_explanation"),
                            status="open"
                        )
                        db.add(audit_issue)
                        total_issues += 1
                    
                    if "quality_score" in analysis:
                        quality_scores.append(analysis["quality_score"])
                    
                    consecutive_failures = 0  # æˆåŠŸåé‡ç½®
                    scanned_files += 1
                    
                    # æ›´æ–°è¿›åº¦
                    task.scanned_files = scanned_files
                    task.total_lines = total_lines
                    task.issues_count = total_issues
                    await db.commit()
                    
                    print(f"ğŸ“ˆ ä»»åŠ¡ {task_id}: è¿›åº¦ {scanned_files}/{len(files)} ({int(scanned_files/len(files)*100)}%)")
                    
                    # è¯·æ±‚é—´éš”
                    await asyncio.sleep(llm_gap_ms / 1000)
                    
                except Exception as file_error:
                    failed_files += 1
                    consecutive_failures += 1
                    # æ‰“å°è¯¦ç»†é”™è¯¯ä¿¡æ¯
                    import traceback
                    print(f"âŒ åˆ†ææ–‡ä»¶å¤±è´¥ ({file_info['path']}): {file_error}")
                    print(f"   é”™è¯¯ç±»å‹: {type(file_error).__name__}")
                    print(f"   è¯¦ç»†ä¿¡æ¯: {traceback.format_exc()}")
                    await asyncio.sleep(llm_gap_ms / 1000)

            # 5. å®Œæˆä»»åŠ¡
            avg_quality_score = sum(quality_scores) / len(quality_scores) if quality_scores else 100.0
            
            # åˆ¤æ–­ä»»åŠ¡çŠ¶æ€
            # å¦‚æœæ‰€æœ‰æ–‡ä»¶éƒ½è¢«è·³è¿‡ï¼ˆç©ºæ–‡ä»¶ç­‰ï¼‰ï¼Œæ ‡è®°ä¸ºå®Œæˆä½†ç»™å‡ºæç¤º
            if len(files) > 0 and scanned_files == 0 and skipped_files == len(files):
                task.status = "completed"
                task.completed_at = datetime.now(timezone.utc)
                task.scanned_files = 0
                task.total_lines = 0
                task.issues_count = 0
                task.quality_score = 100.0
                await db.commit()
                print(f"âš ï¸ ä»»åŠ¡ {task_id} å®Œæˆ: æ‰€æœ‰ {len(files)} ä¸ªæ–‡ä»¶å‡ä¸ºç©ºæˆ–è¢«è·³è¿‡ï¼Œæ— éœ€åˆ†æ")
            # å¦‚æœæœ‰æ–‡ä»¶éœ€è¦åˆ†æä½†å…¨éƒ¨å¤±è´¥ï¼ˆLLMè°ƒç”¨å¤±è´¥ï¼‰ï¼Œæ ‡è®°ä¸ºå¤±è´¥
            elif len(files) > 0 and scanned_files == 0 and failed_files > 0:
                task.status = "failed"
                task.completed_at = datetime.now(timezone.utc)
                task.scanned_files = 0
                task.total_lines = total_lines
                task.issues_count = 0
                task.quality_score = 0
                await db.commit()
                print(f"âŒ ä»»åŠ¡ {task_id} å¤±è´¥: {failed_files} ä¸ªæ–‡ä»¶åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥ LLM API é…ç½®")
            else:
                task.status = "completed"
                task.completed_at = datetime.now(timezone.utc)
                task.scanned_files = scanned_files
                task.total_lines = total_lines
                task.issues_count = total_issues
                task.quality_score = avg_quality_score
                await db.commit()
                print(f"âœ… ä»»åŠ¡ {task_id} å®Œæˆ: æ‰«æ {scanned_files} ä¸ªæ–‡ä»¶, å‘ç° {total_issues} ä¸ªé—®é¢˜, è´¨é‡åˆ† {avg_quality_score:.1f}")
            task_control.cleanup_task(task_id)

        except Exception as e:
            print(f"âŒ æ‰«æå¤±è´¥: {e}")
            task.status = "failed"
            task.completed_at = datetime.now(timezone.utc)
            await db.commit()
            task_control.cleanup_task(task_id)
